\documentstyle[rhultechreport,11pt,twoside]{report}
\renewcommand{\today}{December 20, 1997}

\newcommand{\derive}{{\mathop{\Rightarrow}\limits^*}}
\newcommand{\mderive}[1]{{\mathop{\Rightarrow}\limits^{#1}}}
\newcommand{\mderives}[1]{{\ \mathop{\Rightarrow}\limits^{#1}\ }}
\newcommand{\pdn}{::=}

\newcommand{\miter}[4]{({#1})\kern 2pt_{#2}{\tt @}_{#3}\kern 2pt{{\tt #4}}}
\newcommand{\iter}[4]{({#1}){#2}{\tt @}{#3}{#4}}

\newcommand{\first}{\mbox{\sc first}}
\newcommand{\follow}{\mbox{\sc follow}}
\newcommand{\FIRST}{\mbox{\sc first}}
\newcommand{\FOLLOW}{\mbox{\sc follow}}

\newcommand{\rdpsupp}{{\mediumseries\tt rdp\_supp}}
\newcommand{\rdp}{{\mediumseries\tt rdp}}
\newcommand{\rdps}{{\mediumseries\tt rdp\ }}


\title{A tutorial guide to \rdp\ for new users}
\author{Adrian Johnstone \and Elizabeth Scott}
\reportnumber{\csnum{97}{24}} %Uncomment this line only when
\begin{document}


\makecstitle %make Adrian's title page
\thispagestyle{empty}
\vspace*{1cm}
\begin{center}\bf Abstract\end{center}

\rdp\ is a system for implementing language processors. It 
takes as input an EBNF-like specification
of a language together with a specification, written in C, of
behaviour which should result when fragments of the language are recognised.
\rdp\ produces as output a program written in C, which parses fragments
of the specified language 
and carries out the specified corresponding actions.
Thus \rdp\ can produce, for example, compilers (the actions specify the
corresponding target code), interpreters (the actions evaluate the
input fragments) and pretty printers (the actions reformat the input
fragments).

\vspace*{\fill}
\begin{center}
\fbox{\parbox{12cm}{This document is \copyright\,Adrian Johnstone
and Elizabeth Scott 1997.\\[1ex]
Permission is given to freely distribute this document
electronically and on paper. You may not change this document or
incorporate parts of it in other documents: it must be distributed intact.\\[1ex]
The \rdp\ system itself is \copyright\,Adrian Johnstone but may
be freely copied and modified on condition that details of the
modifications are sent to the copyright holder 
with permission to include
such modifications in future versions and to discuss them (with
acknowledgement) in future publications.\\[1ex]
The version of \rdp\ described here is version 1.50 dated 16 August
1997.\\[1ex] 
Please send bug reports and copies of modifications
to the authors at the address on the title page or electronically
to {\tt A.Johnstone@rhbnc.ac.uk}.
}}
\end{center}


\clearpage
\pagenumbering{roman}
\tableofcontents
\clearpage
\setcounter{page}{0}
\pagenumbering{arabic}

\chapter{An overview of translation}
Computer programs are often written in a so-called
`high level' language such as C or FORTRAN. Most human
programmers find high level languages easier to use than
the `low level' machine oriented languages.
However, in order for a machine to execute a program
it must  be translated from the high level language in
which it is written to the native language of that machine.
A {\em compiler} is a program which takes as input a program
written in one language and produces as output an
equivalent program written in another language.

Computer languages are very simple compared to the languages employed in everyday
human communication. This makes the task of writing a compiler
less intimidating\dash at
present computer programs that translate from one {\em human} language
to another are rather unsatisfactory because the subtle rules that
underpin human languages are not completely understood, and so
mis-translations are common.

Although computer languages are designed to be simple to understand and
translate, real computer languages still present significant problems. Sometimes,
especially with very old languages such as FORTRAN and COBOL, the
difficulties in translation arise from the imperfect understanding that
the early language designers had of the translation process. More modern
languages, such as Pascal and Ada are to a large extent designed to be
easy to translate. The discovery that it was possible to design a
language which could be translated in linear time (that is the
translation time is proportional to the length of the text to be
translated) and yet still appear readable to humans was an important
result of early work on the theory of programming language syntax. 

Other problems are not so easily circumvented. It turns out, for
instance, that the ability to directly modify machine addresses
provided by the C language's pointer arithmetic operations makes it very
difficult for a `smart' translator to produce efficient translations for
conventional computers, and the same facilities create even more serious
problems when attempting to produce code that will run on a parallel
computer. This kind of difficulty arises from a fundamental design
decision taken at the time the language is first specified, and cannot
easily be undone.




\section*{Subdividing the translation problem} 
Computer language translation is
traditionally viewed as a process with two main parts: the {\em front
end} conversion of a high level language text written in a language such
as C, Pascal or Ada into an {\em intermediate form}, and the {\em back end}
conversion of the intermediate form into the native language of a
computer.  This approach is useful because it turns out that the
challenges encountered in the design of a front end differ fundamentally
from the problems posed by back end code generation and separating out
the problems makes it easier to think about the overall task. 


The language to be translated forms the input to the front end and is
called the {\em source} language. The output of the back end is called
the {\em target} language. In the special (but very common) case of a
translator that outputs machine code for a particular computer, the
target language is usually called the {\em object code}.

\subsection*{Interpreters, compilers and in-between}
\label{frontback}
Sometimes the
subdivision of the translation problem into front and back ends is
explicit in the translator program, but not always. An {\em interpreter}
is a special kind of language translator that executes actions as it
translates. Most operating system command shells are of this form: each
command is executed as it is encountered. In such a system there is no
readily discernible back end or intermediate form although it can still
be useful to think of the program as performing front and back end
tasks. The macro languages found in most word processors, along
with simple programming languages such as BASIC are most often
implemented as interpreters. 

The intermediate form must provide enough generality to cope with the
various source and target languages. Fortunately, front end processors
for different languages sometimes display striking similarities. For
instance, at a very crude level the variable declaration constructs in
C and Pascal are quite similar. Their use of {\sc if-then-else}
selection is almost identical. It is perfectly possible to design an
intermediate form that can cope with both C- and
Pascal-like structures. 

 Using
this organisation, a compiler for a given language can be moved to a new
computer architecture by writing a new back end to take account of the
differing instruction sets.  More rarely, a new programming language
syntax can be quickly implemented on a given architecture by building a
new front end and using an existing back end. This saving in engineering
effort can be very important in commercial compiler systems, even though
it may
require an intermediate form that is more complex than that required for
a single source/target language pair.



\section*{Automated front end production} Many of the theoretical
issues surrounding front end translation were solved during the 1960's
and 1970's, and it is possible to reduce most of the implementation
effort for a new front end to a clerical exercise that may itself be
turned into a computer program. {\em Compiler-compilers} are programs
that take the description of a programming language,
and output the source code of a program that will
recognise, and possibly act upon, phrases written in that language. 
The availability of such tools has fed back into programming language
design. It is very hard to use such tools to generate translators for
languages such as FORTRAN, but more recent languages are usually
designed in such a way as to facilitate the use of compiler-compilers. 
The description of the programming language to be input to a
compiler-compiler is usually given in a variant of the {\em
generative grammar} formalism which was introduced in the
1950's by Chomsky. The formalism was first applied to the
specification of programming languages by John Backus and
Peter Naur and in recognition of this
the notation used is often called Backus-Naur Form (or BNF).
In this guide we shall give an introduction to BNF and the
particular version, IBNF, accepted by our compiler-compiler.
A full discussion of BNF can be found in standard texts
such as \cite{dragon} or \cite{AHO72}, 
and further discussion of our particular
IBNF can be found in the associated user manual
\cite{rdp:user:1.5}.

\section*{Back end design} Code generation, the primary task of the
back end, is much less well understood than front end translation. The
basic task is the selection of machine code sequences that correctly
represent the meaning of the source language phrases. In general we will
want to generate code which executes either as quickly as possible, or
requires as little space as possible, or both (these two aims may or may
not conflict). So far no single unifying theoretical model has appeared,
and many compilers use a `bag of tricks' in the back end that is hard to
systematise. As a result, books on compiler design often focus mainly on
the front end where the problems are more tractable and the tools more
useful. 


\section*{}
\rdp\ is a program which takes an IBNF specification of
a language and, provided the specification has certain
properties, generates a compiler which translates from the
specified language in to C. \rdp\ can be used to generate
both compilers, interpreters and simple parsers for languages.
In this tutorial document we give a low level introduction
to parser generation using \rdp. The associated case study
manual \cite{rdp:case:1.5} discusses larger examples in which
\rdp\ is used to generate a compiler for a small language.
Full details of the facilities available in \rdp\ can be
found in the associated users' manual \cite{rdp:user:1.5}.



\chapter{Basic parsing issues}\label{basic}
\rdp-generated parsers use a {\em recursive descent} parsing
technique with {\em one symbol of lookahead}. In order for such parsers
to work correctly the
specification (grammar) which is input to \rdp\
must have certain properties.
A full description of these properties will be given in
Chapter~\ref{LL1}.
In this chapter we review enough of the theory of grammars,
language specification, and parsing to understand the use of \rdp\ 
at a basic level. We also describe, in a step-by-step fashion,
the way in which \rdp\ can be used to generate a parser for a specified
language, using a language whose elements are arithmetic
expressions as an example.
At the end of the chapter we describe the built in \rdp\ scanner,
which is copied into all \rdp-generated parsers.

We assume that you have already got and unpacked the \rdp\ software
pack, and that you have built the standard modules (for example
by typing {\tt make}). Your main \rdp\ directory should contain
subdirectories \verb+rdp_doc+ and  \verb+rdp_supp+.
For instructions on how to get and install
the \rdp\ software pack see Appendix~\ref{distribution} at the end of this manual.

Throughout this guide we shall illustrate our discussion with example
grammars. The grammars which are given titles in the text
are included in the \rdp\ distribution pack in the subdirectory
\verb+tut_exs+ so you can use \rdp\ to generate the corresponding
parsers.

\section{Specifying a language}
It is standard practice to use formal grammars to specify languages.
For example,
\begin{quote}
\begin{verbatim}
S ::= S '+' S | S '*' S | E .
E ::= 'a' | 'b' .
\end{verbatim}
\end{quote}
is a set of grammar rules which generates a language of sums and
products, for example,
\verb£a+b*a+a£ or \verb£a£.

A grammar consists of a set {\bf N} of {\em non-terminals}, a set 
{\bf T} of {\em terminals}, and a set {$\bf\cal P$} of {\em
grammar rules} of the form
\begin{center}
\tt
A ::= $\alpha_1$ | $\alpha_2$ | $\ldots$ | $\alpha_n$ 
\end{center}
where $A$ is an element of {\bf N} and
each $\alpha_i$ is a string of elements from {\bf N} and {\bf T}.
One of the non-terminals, $S$ say, is singled out and called the
{\em start symbol}.

In the above grammar, the non-terminals are {\tt S}, {\tt E}, the terminals are 
{\tt +},{\tt *},{\tt a},{\tt b}, and the start symbol is {\tt S}.

\vskip.3cm
\noindent
How does a grammar specify a language?

We {\em derive} one string from another by replacing a non-terminal with
a string from the right hand side of its grammar rule.
So if we have a rule
$$
A ::= ...\ |\ \gamma\ |\ ... \ .
$$
we can replace $A$ by $\gamma$. We use the symbol $\Rightarrow$
for a derivation, and we write
$\alpha A\beta \mderive{}\alpha\gamma\beta$.

If $\mu$ and $\tau$ are strings,
we say that  $\tau$ {\em can be derived from} $\mu$,
and we write $\mu\derive\tau$, if there is a sequence
$$
\mu\mderive{}\alpha_1\mderive{}\ldots\mderive{}\alpha_n\mderive{}\tau.
$$
For the example above we have

\begin{eqnarray*}
\mbox{\tt
S} &\mderives{}& \mbox{\tt S + S} \\
  &\mderives{}& \mbox{\tt E + S} \\
  &\mderives{}& \mbox{\tt a + S} \\
  &\mderives{}& \mbox{\tt a + S + S} \\
  &\mderives{}& \mbox{\tt a + S * S + S}\\ 
  &\mderives{}& \mbox{\tt a + b * S + S} \\
  &\mderives{}& \mbox{\tt a + b * E + S} \\
  &\mderives{}& \mbox{\tt a + b * a + S }\\
  &\mderives{}& \mbox{\tt a + b * a + E} \\
  &\mderives{}& \mbox{\tt a + b * a + b} \\
\end{eqnarray*}
and so \ \ ${\tt S}\ \derive\ {\tt a + b * a + b}$.

The {\em language specified by a grammar} is the set of strings
of terminals which can be derived from its start symbol.
We say that $u\in${\bf T}$^*$ is a {\em sentence} if $S\derive u$.
(Here {\bf T}$^*$ denotes the set of strings of elements of {\bf T}
and includes the empty string $\epsilon$, so if {\bf T}=$\{a, b, +\}$ 
then \\
{\bf T}$^* = \{\epsilon, a, b, +, aa, ab, a+, ba, bb, b+, +a, +b, ++,
aaa, aab, \ldots\}$.)

The language generated by the grammar above is the set of all sums
and products of $a$'s and $b$'s.

\section{Formal grammars and \rdp}
Only the grammar rules are actually input to \rdp.
The following conventions are used by \rdp\ to deduce the remaining
aspects of the grammar: the
left hand side of the first grammar rule is the start symbol,
the terminal symbols are enclosed in single quotes, and each grammar
rule is terminated by a full stop.
The above example is an example input for \rdp\ (although it
should be noted that \rdp\ will not automatically
generate a parser for this example because it is left recursive
~\dash~ see below).


Given a `suitable' input grammar (we shall explain what
suitable means in this context in Chapter~\ref{LL1}),
\rdp\ generates a {\em parser} which takes as input a string $u$ of terminals
and either reports success, if $u$ is a sentence in the language of
the grammar, or issues an error message. (If the input grammar is not 
suitable \rdp\ issues a diagnostic identifying the aspect(s) of the
grammar with which it cannot cope.)

In the rest of this chapter we shall describe how to get \rdp\ to
generate a parser from a simple grammar. 
It is not possible to use \rdp\ to generate a
correct parser for the expression grammar given above, because this grammar
is not `suitable' in the sense that we have just discussed.
So we shall use the following grammar
(which specifies the same language as the original) as an example.

\begin{quote}
\begin{verbatim}
(** expr1.bnf **)

S ::= E Y.
Y ::= ['+' S].
E ::= T X.
X ::= ['*' E].
T ::= 'a' | 'b'.
\end{verbatim}
\end{quote}
We need to note here that \rdp\ does not 
directly accept `epsilon' rules
(i.e.
rules of the form $A\pdn\epsilon$, where $\epsilon$ denotes the empty
string). The notation {\tt [$\alpha$]} is used to represent
$\alpha | \epsilon$. So, for example, 

\vskip.2cm
{\tt Y ::= ['+' S].}\qquad corresponds to\qquad
{\tt Y ::= '+' S |\ }$\epsilon$.



\section{Building and running a parser}\label{running}
In this section we shall use the  grammar {\tt expr1.bnf}
to describe
the basic procedure for getting \rdp\ to generate a parser.

To build and run parsers using \rdp\ we must first compile the support library modules.
The exact command to do this depends on the C compiler that you are using. If, for instance
your compiler was called {\tt CC} then the following commands would compile the modules:
\begin{quote}
\begin{verbatim}
CC -c -Irdp_supp rdp_supp/arg.c
CC -c -Irdp_supp rdp_supp/graph.c
CC -c -Irdp_supp rdp_supp/memalloc.c
CC -c -Irdp_supp rdp_supp/scan.c
CC -c -Irdp_supp rdp_supp/scanner.c
CC -c -Irdp_supp rdp_supp/set.c
CC -c -Irdp_supp rdp_supp/symbol.c
CC -c -Irdp_supp rdp_supp/textio.c
\end{verbatim}
\end{quote}
The {\tt -c} flag here tells the C compiler to just run as far as producing an object file and 
to not attempt to link the module into an executable program. The \verb+-Irdp_supp+ flag
tells the compiler to look for include files in the \verb+rdp_supp+ subdirectory.

In general you will have to replace the {\tt CC} with the name of your
compiler, possibly along with some special flags. The following table
gives some examples: please refer to your compiler documentation if the combination of
operating system and compiler you use is not listed here.
\begin{quote}
\begin{center}
\begin{tabular}{ll}
If you are using\ldots&then replace {\tt CC} with \ldots\\
\hline
GNU C on Unix&{\tt gcc}\\
GNU C++ on Unix&{\tt g++}\\
Borland C V5.0 on MS-DOS&{\tt bcc}\\
Borland C++ V5.0 on MS-DOS&{\tt bcc -P}\\
Borland C V5.0 on Windows-95&{\tt bcc32}\\
Borland C++ V5.0 on Windows-95&{\tt bcc32 -P}\\
\end{tabular}
\end{center}
\end{quote}

Once the support library has been built, we can edit a {\tt .bnf} file, process it using
\rdp\, and then compile the resulting parser before linking with the support library modules
and testing the parser against a string file.

To build and run a parser for a language with gcc running under Unix and using the Emacs editor
we might use the following commands,
\begin{quote}
\begin{verbatim}
emacs expr1.bnf
rdp -oexpr1 expr1
gcc -Irdp_supp -c expr1.c
gcc expr1.o arg.o graph.o memalloc.o scan.o scanner.o set.o 
    symbol.o textio.o 
emacs expr1.str 
expr -v expr1.str
\end{verbatim}
\end{quote}

To build and run a parser for a language with Borland C++ 5.0 running
under Windows-95
and using the standard DOS editor we use the following commands,
\begin{quote}
\begin{verbatim}
edit expr1.bnf
rdp -oexpr1 expr1
bcc32 -P -Irdp_supp -c expr1.c
bcc32 expr1.obj arg.obj graph.obj memalloc.obj scan.obj 
      scanner.obj set.obj symbol.obj textio.obj 
edit expr1.str 
expr -v expr1.str
\end{verbatim}
\end{quote}

We now look at these commands line-by-line.
We can type the above grammar into a file using our editor (either {\tt emacs} or 
{\tt edit} here).
If we call the file {\tt expr1.bnf} say, then we can input it to \rdp\ as follows.
\begin{verbatim}
rdp -oexpr1 expr1
\end{verbatim}
This causes \rdp\ to produce a parser, called {\tt expr1.c} and written in
C, for the language specified by the grammar. The flag {\tt -o}
directs \rdp\ to call the file it produces {\tt expr1.c}; the default name
for the output,
which will be used if you leave out the {\tt -o} flag,
is {\tt rdparser.c}.
Note, all the examples discussed in this manual are included in the \rdp\
distribution in the subdirectory \verb+examples\rdp_tut+. If you wish to use
these directly you will need to give the path 
\begin{quote}
\begin{verbatim}
rdp -oexpr1 examples\rdp_tut\expr1
\end{verbatim}
\end{quote}


We then compile this file using a C compiler to produce an object
file {\tt expr1.obj}. The following command assumes that the compiler
is Borland C++:
\begin{verbatim}
bcc32 -P -Irdp_supp -c expr1.c
\end{verbatim}
The flag {\tt -I} instructs the compiler to look in the subdirectory
\verb+rdp_supp+ for the additional header files that it needs and the {\tt -c} flag tells
the compiler to only produce an object file and not to invoke the linker at this stage.

The final parser needs to use the various support routines which are provided
with the \rdp\ package. Some of these support modules are discussed 
later in this manual, and all the support modules are fully
documented in the accompanying support manual \cite{rdp:supp:1.5}.
Here we shall just generate an executable parser by linking in the
appropriate support modules, without explaining their functions.
\begin{verbatim}
bcc32 expr1.obj arg.obj graph.obj memalloc.obj scan.obj 
scanner.obj set.obj symbol.obj textio.obj
\end{verbatim} 
This produces an executable version of the parser, called {\tt expr1.exe} on DOS and Windows
systems or just plain {\tt expr1} on Unix systems.


We can then create a test file, {\tt expr1.str} say, that contains a
string for the generated parser to check, and
run it through the parser using the command
\begin{verbatim}
expr1 -v expr1.str
\end{verbatim}
The {\tt -v} flag runs the 
generated parser in verbose mode so that it gives information
about the execution.  For example, if {\tt expr1.str}
is
\begin{center}
\verb=a + b * a + b=
\end{center}
the following should be produced as a result
of the above command:
{\small
\begin{verbatim}
rdparser
Generated on Apr 14 1997 9:56:55 and compiled on Apr 14 1997 at 9:32:21

******: 0.008 CPU seconds used
\end{verbatim}
}
If we give the generated parser a string which is not in the language it issues
a suitable error message. For example, on input
\quad
\verb=a b=
\quad
we get 
{\small
\begin{verbatim}
rdparser
Generated on Apr 14 1997 9:56:55 and compiled on Apr 14 1997 at 9:32:21

     1: Error 1 (expr.str) Scanned 'b' whilst expecting one of EOF, '*', '+'
     1: a b
     1: --1
******: Fatal - error detected in source file
\end{verbatim}
}
\noindent
and on input \quad \verb=a + + b= \quad we get
{\small
\begin{verbatim}
rdparser
Generated on Apr 14 1997 9:56:55 and compiled on Apr 14 1997 at 9:32:21

     1: Error 1 (expr.str) Scanned '+' whilst expecting one of 'a', 'b'
     1: a + + b
     1: ----1
******: Fatal - error detected in source file
\end{verbatim}
}
In both cases the generated parser issues an error message which prints out
the section of the input string which has caused the trouble, indicates
where in the string the parse has failed, and issues a list of
symbols that would have been legitimate at the point of the error.

\section{Makefiles}
The \rdp\ distribution pack contains a makefile which you can use to
build and run the parsers. It is called {\tt makefile} and is in the
main \rdp\ directory.

The makefile contains options for running \rdp\ under Unix, DOS,
SunOS and Windows-95,  using gcc, acc 2.0, Borland C 3.1,
Borland C++ 5.0, and Microsoft 'C' 7.0. All
that is necessary to use a particular configuration
is to remove the commenting
`\#' from the appropriate section. For example, to run gcc under Unix
uncomment the commands
{\small
\begin{verbatim}
# Configuration for gcc on Unix. Also works for g++ if you set CC = g++
 CC      = gcc
 OBJ     = .o
 EXE     =
 DIFF    = diff -s
 RM      = rm
 CP      = cp
 SUPP_DIR = ./rdp_supp/
 CFLAGS = -I$(SUPP_DIR) -Wmissing-prototypes -Wstrict-prototypes 
                            -fno-common -Wall -ansi -pedantic -g
 LINK    = $(CC) -o ./
 MATHS   = -lm
 HERE    = ./
 OBJ_ONLY = -c
# End of gcc on Unix configuration
\end{verbatim}
}
There is a section in the makefile which allows it to be used to
build a parser for any suitable input grammar. The grammar
should be typed into a file with a {\tt .bnf} extension,
{\tt myfile.bnf} say. This file is then used 
by setting {\tt GRAMMAR=myfile} as part of the command line instructions
to {\tt make} (see below).
The makefile runs \rdp\ on the input file,
compiles the corresponding C file, links it with the appropriate
support files, and finally runs the executable parser on a file
{\tt myfile.str}
containing a test string. Typing
\begin{verbatim}
make GRAMMAR=examples\rdp_tut\expr1 parser
\end{verbatim}
under DOS generates the following:
{\small
\begin{verbatim}
MAKE Version 4.0  Copyright (c) 1987, 1996 Borland International
       rdp examples\rdp_tut\expr1
       bcc32 -Irdp_supp\ -A -c -P -w -c rdparser.c
Borland C++ 5.0 for Win32 Copyright (c) 1993,1996 Borland International
rdparser.c:
       bcc32 -erdparser.exe rdparser.obj arg.obj graph.obj memalloc.obj 
                   scan.obj scanner.obj set.obj symbol.obj textio.obj 
Borland C++ 5.0 for Win32 Copyright (c) 1993,1996 Borland International
Turbo Link Version 1.6.72.0 Copyright (c) 1993,1996 Borland International
       rdparser -v -Vparser.vcg -l examples\rdp_tut\expr1.str
rdparser
Generated on Dec 28 1997 9:08:55 and compiled on Dec 27 1997 at 8:41:23
******: 
     1: a + b * a + b
******: 0 errors and 0 warnings
******: 0.038 CPU seconds used
\end{verbatim}
}
\noindent
\rdp\ has built a parser for {\tt expr1.bnf} and run it on the file
{\tt expr1.str}, which in this case
happened to contain the string {\tt a + b * a + b}.


\section{\rdp\ parsers and recursive descent parsing}\label{works}

\rdp\ generates parsers which use a {\em recursive descent} technique.
The goal of a parser is
to construct a derivation of a given input string.
In order to use \rdp\ it is necessary to have an understanding of the
recursive descent technique which its parsers use.
In this section we outline the basic ideas of top-down
one-symbol-lookahead parsing in order to motivate our choice of
examples. Recursive descent is considered in more detail in
Chapter~\ref{LL1}.

\subsection{Left-most derivations}
\rdp-generated parsers use a {\em top down} approach; that is, they
start with the start symbol and attempt to construct a derivation
step-by-step from the left. The parsers also use a {\em left-most}
{\em depth-first} approach; that is, at each step in the constructed
derivation the left-most non-terminal in the string is expanded.

Consider the grammar {\tt expr1.bnf}
\begin{quote}
{\tt
S ::= E Y.\\
Y ::= ['+' S] .\\
E ::= T X.\\
X ::= ['*' E] .\\
T ::= 'a' | 'b'.}\\
\end{quote}
As it uses a top down depth first approach,
an \rdp-generated parser for the above grammar
would construct the following derivation 
of {\tt\ a + b * a}:

\begin{eqnarray*}
\mbox{\tt S} &\mderives{}& \mbox{\tt E Y}\ \mderives{}\ \mbox{\tt  T X Y}\  
\mderives{}\  \mbox{\tt a X Y}\ 
  \mderives{}\ \mbox{\tt  a Y}\ 
  \mderives{}\  \mbox{\tt a + S}\  \mderives{}\  \mbox{\tt a + E Y}\\
&\mderives{}& \mbox{\tt a + T X Y}\  \mderives{}\  \mbox{\tt a + b X Y}\ 
  \mderives{}\  \mbox{\tt a + b * E Y}\  \mderives{}\ \mbox{\tt a + b * T X Y}\\
&\mderives{}& \mbox{\tt a + b * a X Y}\  \mderives{}\ \mbox{\tt a + b * a Y}\ 
  \mderives{}\ \mbox{\tt a + b * a}\\
\end{eqnarray*}
but would not construct the following (legitimate) derivation of {\tt a}:
\begin{quote}
${\tt S}\ \mderives{}\ {\tt E Y}\ \mderives{}\ {\tt E}\ \mderives{}
\ {\tt T X}\ \mderives{}\ {\tt T}\ \mderives{}\ {\tt a}$
\end{quote}

\subsection{Selecting an alternate}
When there is more than one alternate in a grammar rule recursive descent parsers
need an algorithm for deciding which of the alternates to choose.
For example, in the first derivation above at the point
\begin{quote}
{\tt
S $\mderives{}$ E Y $\mderives{}$ T X Y 
}
\end{quote}
it was necessary to decide whether to replace {\tt T} by {\tt a} or
{\tt b} at the next step. This decision was made by looking at the 
{\em current input symbol}. This will be discussed formally below
but it may help the reader at this point to consider the following
informal discussion. As the parse begins the first symbol 
of the string to be parsed is read from the input buffer. 
This is the current input symbol. If the parse is
to succeed, eventually this symbol must appear at the beginning (left hand end)
of a string generated during the derivation.
When this happens the current input symbol has
been {\em matched}, and the next symbol is read from the input buffer,
becoming the current input symbol. Eventually this must be matched to the 
second symbol in a string generated during the derivation, and so on. 
This reading and
matching process carries on until the last symbol from the input buffer is matched
to the last symbol of a string generated by the derivation. At this point the parse
has succeeded. If this point cannot be reached then the parse has failed.

The value of the current input symbol is
the only information the parser has for use in selecting the alternate to be 
inserted at the next derivation step.
So if parser success is to be guaranteed, this information must be sufficient to
decide between the alternates.
For this reason, \rdp\ will not generate a parser from a grammar
in which two or more alternates from the same grammar rule have
the same first symbol.
For example, we could not use an \rdp\ parser generated from the grammar
\begin{quote}{\tt
S ::= E Y.\\
Y ::= ['+' S] .\\
E ::= T X.\\
X ::= ['*' E] .\\
T ::= 'a' 'a' | 'a' 'b'.}
\end{quote}
To see why this grammar is unsatisfactory consider the string 
{\tt ab + aa}. At the point
\begin{quote}
{\tt
S\ $\mderives{}$\ E Y\ $\mderives{}$\ T X Y 
}
\end{quote}
in an attempted parse of this string it is not possible to decide,
just by looking at the current input symbol {\tt a}, which
of the alternates {\tt aa} and {\tt ab} to use to replace {\tt T}.

In the original grammar,
\begin{quote}
\begin{verbatim}
S ::= S '+' S | S '*' S | E .
E ::= 'a' | 'b' .
\end{verbatim}
\end{quote}
two of the alternates in the rule for {\tt S} have {\tt S} as their
first symbol.
This is one reason why this grammar cannot be used with \rdp\
and a modified version {\tt expr1.bnf} was used as an example
in the previous sections.

A complete description of grammars which admit \rdp-generated parsers
is given in Chapter~\ref{LL1}.


\section{The \rdp\ scanner}
So far we have not discussed how \rdp-generated parsers match
characters in an input file to terminals in the grammar.
To use \rdp\ effectively it is necessary to know a little about
the initial phase of compilation usually called {\em lexical analysis}
or {\em scanning}.

\subsection{\rdp\ scanner tokens}\label{tokens}

A parser usually considers sentences in a language at  token, or `word',
level. It is presented with streams of tokens which have to be
structured into sentences. 
In reality, a sentence is presented as a stream of
characters, or `letters', and these characters must first be grouped
together into words. This is usually the job of the scanner
in a compiler. 

Tokens are not quite the same thing as words. A token often corresponds to
a set of words. For example, we describe the set of integers using the
token {\tt INTEGER} and the set of C style identifiers using the
token {\tt ID}. Sometimes tokens do correspond exactly to words.
For example, the token {\tt 'if'} corresponds just to the string
which forms the keyword {\tt if}.

So a token is the name of a set of strings of characters; this set
is called the {\em pattern} of the token.
We say that a string of characters {\em matches} a token if it belongs
to the pattern of that token. A string which matches a token is called
a {\em lexeme} of the token.
For example, a token {\tt op} may correspond to the less-than, greater-than,
less-or-equals, and greater-or-equals strings. In this case, the pattern of {\tt op}
is the set
$$
\{\ \mbox{\tt <},\ \mbox{\tt >},\ \mbox{\tt <=},\ \mbox{\tt >=}\ \}
$$
the string {\tt <=} matches {\tt op}, the string {\tt <<} doesn't match {\tt op},
and {\tt <=} is a lexeme of {\tt op}.

\rdp\ has a scanner which it uses to process its input files.
This scanner is automatically built into any parser that \rdp\ 
generates, so \rdp-generated parsers come with a hard wired scanner
giving the user access to certain standard patterns.

\subsection*{Simple tokens}
Any string of characters between single quotes is treated by the scanner
as a token which matches exactly that string. So {\tt 'a'} matches
the sequence {\tt a} and {\tt 'while'} matches the sequence {\tt while}, and
the singleton set
$\{{\tt a}\}$ is the pattern of {\tt 'a'} and $\{{\tt while}\}$ is the pattern of
{\tt 'while'}.

\subsection*{The tokens {\tt INTEGER} and {\tt REAL}}
The token {\tt INTEGER} matches C style integers such as 145 and 0xFE,
and {\tt REAL} matches any C style real number, such as 1.45 and
1.45e3. We can use the token {\tt INTEGER} to modify the expression
grammar given in Section~\ref{running} 
to generate all strings of integer expressions,
sums and products of integers.
\begin{quote}
\begin{verbatim}
(** expr2.bnf **)

S ::= E Y.
Y ::= ['+' S].
E ::= T X.
X ::= ['*' E].
T ::= INTEGER.
\end{verbatim}
\end{quote}


\subsection*{The {\tt STRING()} tokens}
Most languages allow string literals \dash alphanumeric strings
enclosed between, for example, single or double quotes.
For example, the C  command
\begin{center}
{\tt
printf("string") ;}
\end{center}
causes the characters {\tt string} to be printed.

\rdp\ allows you to use a paramaterisable token {\tt STRING('{\em delimiter
character}')}
which matches all sequences of letters and underscores
enclosed by the {\em delimiter character}. The symbol which is to delimit
the strings must itself be quoted. For example,
\begin{quote}
\begin{verbatim}
rule ::= STRING('"') .
\end{verbatim}
\end{quote}
matches strings between double quotes. So
\begin{quote}
\begin{verbatim}
"this is a string"    "string1"  "another_string"
\end{verbatim}
\end{quote}
are all lexemes of the token {\tt STRING('"')}.

To distinguish a single quote from the token quotes we use the
\verb+\+ character. So
\begin{quote}
\begin{verbatim}
rule ::= STRING('\'') .
\end{verbatim}
\end{quote}
matches strings between single quotes, e.g.
\begin{quote}
\begin{verbatim}
'this is a string'    'string1'  'another_string'
\end{verbatim}
\end{quote}

What if we want to include the delimiting character in the actual
string? Two consecutive delimiters represent the delimiter
symbol itself.
So, for example,
\begin{quote}
\begin{verbatim}
'this string''s delimiter is '''
\end{verbatim}
\end{quote}
matches the token \verb+STRING('\'')+ and the Pascal statement
\begin{quote}
\begin{verbatim}
writeln('this string''s delimiter is ''') ;
\end{verbatim}
\end{quote}
would cause 
\begin{center}
\verb+ this string's delimiter is '+
\end{center}
to be printed on the screen.

It is possible that a language designer would like to use an
escape symbol to access non-printing characters.  This is fully documented
in the user manual \cite{rdp:user:1.5}, here we just show its use
for printing a delimiter symbol.
Strings of the form
\begin{verbatim}
"this string is delimited by \" and has a special escape symbol"
\end{verbatim}
match the \rdp\ token \verb+STRING_ESC('"' '\\')+.

We can now add strings and a print facility to the expression
grammar which allow the user to print messages and the results of
calculations. 
\begin{quote}
\begin{verbatim}
(** expr3.bnf **)

S ::= S1 | 'print' '(' [String][S1] ')' .
S1 ::= E Y .
Y ::= ['+' S1].
E ::= T X.
X ::= ['*' E].
T ::= INTEGER.
String ::= STRING_ESC('"' '\\') .
\end{verbatim}
\end{quote}
A parser for this grammar accepts the input
\begin{center}
\verb-print("the result is " 10*8+5)-
\end{center}

\subsection{Defining a language which permits comments}
Most programming languages allow the programmer to include
comments in the code. These comments are designed to help a human
reader of the code to understand it but are not part of the
instructions to the computer. Such comments should be ignored
by the translator, and hence need to be filtered out at some point.

In the traditional model of compilation the scanner removes any comments
from the input before it is passed to the parser. The \rdp\ scanner
can recognise and remove comments and this facility is also
available in \rdp-generated parsers. The user must specify the form that
comments in their language will take. This is
done by including the appropriate {\tt COMMENT} primitive in the input
grammar.

For example, we can add C style comments to the language of 
integer expressions described in Section~\ref{tokens}. The parser
generated for the grammar
\begin{quote}
\begin{verbatim}
(** expr4.bnf **)

S ::= E Y .
Y ::= ['+' S].
E ::= T X.
X ::= ['*' E].
T ::= INTEGER.
comment ::= COMMENT('/*' '*/') .
\end{verbatim}
\end{quote}
accepts the following input:
\begin{verbatim}
/* Test input for expression grammar */
/*this string should be accepted*/
3 + 5 * 8/* multiplication will be done first */ + 10
/* this string should fail */
10 7
\end{verbatim}
The
above input will generate a parser error in the expression parser, and to
see if the first part is correct it would be useful to be able to comment
out the second part. 

In C comments may not nest, but it is possible to define languages with
nesting comments using grammars which will be accepted by \rdp.
For example, an \rdp-generated parser for the grammar
\begin{quote}
\begin{verbatim}
(** expr5.bnf **)

S ::= E Y .
Y ::= ['+' S].
E ::= T X.
X ::= ['*' E].
T ::= INTEGER.

comment ::= COMMENT_NEST('(*' '*)') .
\end{verbatim}
\end{quote}
accepts the following input:
\begin{verbatim}
(* Test input for expression grammar *)
(*this string should be accepted*)
3 + 5 * 8(* multiplication will be done first *) + 10
(* (* this string should fail *)
10 7 *)
\end{verbatim}

\chapter{Extended BNF}
\rdp\ grammars can have a more flexible type of grammar rule 
than standard BNF allows.
One of the major limitations of standard BNF is that it is only possible
to write out finitely many alternates. It is common practice in many
areas of computer science to use regular expressions as a concise
notation for sets of strings. This allows 
certain infinite sets to be
specified, and saves  tedious writing out of large finite sets.

For example, the grammar
\begin{quote}
{\tt 
S ::= 'a' $\{$ '+' 'a' $\}$ .
}
\end{quote}
defines the language of sums of $a$'s, 
$$
a,\ \ a+a,\ \ a+a+a,\ \ a+a+a+a, \ldots
$$
and
\begin{quote}
{\tt 
S ::= ('a' | 'b' | 'g')( 'c' | 'd' | 'h') .
}
\end{quote}
defines the language
$$
ac,\ ad,\ ah,\ bc,\ bd,\ bh,\ gc,\ gd,\ gh
$$
In the first case we have specified that a string in the language
can contain 0 or arbitrarily many {\tt +} symbols.
To give an equivalent specification in standard BNF
we would need to add extra grammar rules, for example
\begin{quote}
\begin{verbatim}
S ::= 'a' X .
X ::= ['+' 'a' X] .
\end{verbatim}
\end{quote}
In the second case, to give an equivalent specification in BNF
we would either need to add additional rules or extra alternates
\begin{quote}
\begin{verbatim}
S ::= 'a''c' | 'a''d' | 'a''h' | 'b''c' | 'b''d' | 'b''h' 
      | 'g''c' | 'g''d' | 'g''h' .
\end{verbatim}
\end{quote}
(Note: the first grammar can actually be written more concisely using
\rdp's iterator expression, see below.)


It is usual to allow the set of alternates on the right hand side
of a grammar rule to specified using a regular expression and in this
case we describe the notation as being
{\em extended BNF} (EBNF).
The \rdp\ grammar rules can contain the common forms
of regular expression,
we have already seen the use of {\tt []} to denote one-or-zero copies
of the enclosed string, and zero-or-many copies can be denoted using
{\tt \{\}}. \rdp\ also supports a more general form of regular expression
which allows upper and lower limits on the number of repeats of strings.
In this chapter we shall describe the full extended BNF that \rdp\ grammars
can use. We begin with the standard constructs, and then describe
\rdp's generalised expressions.

\section{Standard EBNF}\label{ebnf}
\subsection*{Strings and symbols}
Any singly quoted string is a regular expression, it represents
the set which just contains itself. Thus we can write grammar
rules of the form
\begin{quote}
{\tt
rule ::= 'fred' .
}
\end{quote}
The singly quoted strings are the tokens of the grammar.

Any string of alphanumeric characters is a regular expression. Thus
we can write grammar rules of the form
\begin{quote}
{\tt
rule ::= name1 .
}
\end{quote}
These are the non-terminals of the grammar.

\subsection*{Concatenation}
If $r$ and $s$ are regular expressions then so is $rs$, and the elements
of the set $rs$ are strings obtained by concatenating a string from $r$
and a string from $s$.
So, for example, we can write grammar rules of the form
\begin{quote}{\tt
rule ::= 'a' name1 'b1' 
}
\end{quote}

\subsection*{Alternation}
If $r$ and $s$ are regular expressions then so is $r|s$, and the elements
of the set $r|s$ are strings in $r$ together with the strings in $s$.
So, for example, we can write grammar rules of the form
\begin{quote}
{\tt
rule ::= 'a' name1 | B | 'b1' .
}
\end{quote}
The concatenation operation has higher priority than the 
alternate operation. So 

{\tt 'a' 'b' | B 'c'}\quad is the set\quad $\{${\tt 'a''b', B'c'}$\}$ 

\noindent
not the set $\{${\tt 'a''b''c', 'a'B'c'}$\}$.

\subsection*{Parentheses}
If $r$ is a regular expression then so is $(r)$, and the elements
of the set $(r)$ are exactly the elements of $r$. Parentheses have
higher priority than all the other operations and their
role is to allow other priorities to be overridden.
So, for example,
\begin{quote}
{\tt
rule ::= 'a' ( 'b' | B ) 'c' .
}
\end{quote}
is equivalent to
\begin{quote}
{\tt
rule ::= 'a' 'b' 'c' | 'a' B 'c' . 
}
\end{quote}
and to
\begin{quote}
\begin{verbatim}
rule ::= 'a' rule_1 'c' .
rule_1 ::= 'b' | B .
\end{verbatim}
\end{quote}

\subsection*{Zero or one}
We use square brackets to indicate `one or none'.
If $r$ is a regular expression then 
so is $[r]$, and the elements
of the set $[r]$ are the elements of $r$ together with the empty string.
So, we can write grammar rules of the form
\begin{quote}
{\tt
rule ::= [expr] .
}
\end{quote}
which is equivalent to the rule
\begin{quote}
{\tt
rule ::= expr\ |\ $\epsilon$ .
}
\end{quote}

\subsection*{Zero or many}

We use braces to indicate `zero or many'.
If $r$ is a regular expression then 
so is $\{r\}$, and the elements
of the set $\{r\}$ are the strings formed by concatenating zero or
more strings from $r$ together.
So, for example, we can write rules of the form
\begin{quote}
{\tt
rule ::= $\{$'a'$\}$'b' .}
\end{quote}
which is equivalent to the (infinite) rule
\begin{quote}
{\tt
rule ::= 'b' | 'a''b' | 'a''a''b' | 'a''a''a''b' | ...
}
\end{quote}
We can write more complicated grammar rules, for example
\begin{quote}
{\tt
rule ::= ('a' | 'c')$\{$'a' | 'c'$\}$ .}
\end{quote}
which is equivalent to the (infinite) rule
\begin{quote}
\begin{verbatim}
rule ::= 'a' | 'c' | 'a''a' | 'a''c' | 'c''a' | 'c''c' 
         | 'a''a''a' | 'a''a''c' | 'a''c''a' | 'a''c''c' 
         | 'c''a''a' ...
\end{verbatim}
\end{quote}

\subsection*{One or many}
We use angle brackets to indicate `one or many'.
If $r$ is a regular expression then 
so is $<r>$, and the elements
of the set $<r>$ are the strings formed by concatenating one or
more strings from $r$ together.
So, for example, we can write rules of the form
\begin{quote}
{\tt
rule ::= <'a'> .
}\end{quote}
which is equivalent to the rule
\begin{quote}
{\tt
rule ::= 'a'\ |\ 'a''a'\ |\ 'a''a''a'\ |\ 'a''a''a''a'\ ...
}
\end{quote}



\section{\rdp's IBNF}
We call the particular extended form of BNF which \rdp\ uses an
{\em iterator BNF} or IBNF. In this section we describe the 
additional construct {\tt @} which distinguishes IBNF from
standard EBNF.

Sometimes we need to specify strings of certain lengths. For example,
we may want to specify the strings of up to eight $a$'s and $b$'s.
We could do this by writing out all the strings in the standard BNF
style, but there are 511 of them! This language can be specified
in \rdp\ input grammars using the rule
\begin{quote}
{\tt
rule ::= \iter{'a' | 'b'}{0}{8}{\#} .
}
\end{quote}
Here, the symbol {\tt \#} is being used to denote the absence of a token.
It is necessary because the iterator operator can also be used to
specify a separator between symbols.
Integer arithmetic expressions are sequences of integers with $+$'s
between them, for example $17 + 80 + 9 + 27$. This can't be expressed
simply using braces \verb+{}+ because the first integer in the list
doesn't have a preceeding $+$, i.e. we can't just write $\{${\tt
'+' INTEGER}$\}$. (Of course, we can write \verb=INTEGER{'+' INTEGER}=
but if the are semantic actions associated with the calls to {\tt INTEGER}
then these will need to be repeated.)
The \rdp\  grammar rule
\begin{quote}
{\tt
rule ::= \iter{{\tt INTEGER}}{2}{8}{'+'} .
}
\end{quote}
describes the integer sums which have between two and eight operands.


\subsection*{Formal definition of the {\tt @} operator}
Each of the last four regular expressions in the EBNF description 
in section~\ref{ebnf}
is a special case of a regular
expression which is based on the parameterised operator {\tt @}.
We define {\em iterator expressions} as follows:

\begin{enumerate}
\item
Any regular expression is an iterator expression
\item
If $r$ is an iterator expressions then so is
$\miter{r}{l}{h}{'x'}$, where $l$ and $h$ are integers and $'x'$ is a token
or the special symbol {\tt \#}.
\end{enumerate}

The elements of the set $\miter{r}{l}{h}{'x'}$ are strings which are the 
concatenation of between
$l$ and $h$ strings from $r$, alternated with $x$ if it is not {\tt \#}.
(In the case where $h=0$ there must be at least $l$ strings from
$r$ but there is no upper limit on this number.)

\subsection*{Examples and correspondences}
The following rule allows us to declare function
prototypes which contain arbitraily long comma delimited lists 
of parameters
\begin{quote}
{\tt rule ::= ID '(' \iter{ID}{0}{0}{','} ')' .
}
\end{quote}
This rule matches things like

\verb=      My_Function(var1, var2, var3)     = or \verb=    print()=


\noindent
Note:
For \rdp\ the upper and lower limits are written next to the {\tt @}
operator, rather than subscripted.

The following is a list of the correspondences between
IBNF and standard EBNF constructs.
\begin{quote}
{\tt
rule ::= \iter{r}{0}{0}{\#}.   \mbox{\rm corresponds to} \qquad   rule ::= $\{$ r $\}$.\\
rule ::= \iter{r}{1}{0}{\#}.   \mbox{\rm corresponds to} \qquad   rule ::= < r >.\\
rule ::= \iter{r}{0}{1}{\#}.   \mbox{\rm corresponds to} \qquad   rule ::= [ r ].\\
rule ::= \iter{r}{1}{1}{\#}.   \mbox{\rm corresponds to} \qquad   rule ::= ( r ).\\
}
\end{quote}

We are now in a position to give an \rdp\ grammar for the
language 
of integer expressions, including {\tt -} and {\tt /}. This forms part of
the {\tt mini} grammar which will be discussed in later chapters.
\begin{quote}
\begin{verbatim}
(** expr6.bnf **)

e1 ::= e2 {'+' e2 | '-' e2 } .         
e2 ::= e3 {'*' e3 | '/' e3 } .
e3 ::= '+' e4 | '-' e4 |  e4 .
e4 ::= ID | INTEGER | '(' e1 ')' .
\end{verbatim}
\end{quote}
An \rdp-generated parser for this grammar accepts grammar 
strings of the form, for example,

\begin{quote}
\begin{verbatim}
10 * ( -4 + 6 * (-5)) / (sum - 27).
\end{verbatim}
\end{quote}


\section{Derivations in IBNF}\label{der}
In the previous section we have described the strings generated by \rdp's
iterator constructs. However, to understand what \rdp\ is actually doing,
to make full sense of the error messages it produces, and to use
semantic actions (see Chapter~\ref{semantics})
it is necessary to understand the IBNF constructs in terms of the
derivations they produce.

Basically, recursive descent parsers call a routine, or function,
at each step in the derivation being constructed. Each step corresponds
to the replacement of a non-terminal by one of the alternates from
its grammar rule. Thus there is effectively a routine for each
alternate of each rule. \rdp\ makes an internal subrule for each
alternate. For example, \rdp\ represents the grammar
\begin{quote}
\begin{verbatim}
rule ::= 'a' '+' rule | 'b' .
\end{verbatim}
\end{quote}
internally as
\begin{quote}
\begin{verbatim}
rule ::= rdp_rule_0 | rdp_rule_1 .
rdp_rule_0 ::= 'a' '+' rule .
rdp_rule_1 ::= 'b' .
\end{verbatim}
\end{quote}

If an alternate contains an iterator construct and something else then
\rdp\ takes the iterator construct out and makes a new rule for it.
For example, \rdp\ represents the grammar
\begin{quote}
\begin{verbatim}
rule ::= 'a' ('b')0@4',' .
\end{verbatim}
\end{quote}
internally as
\begin{quote}
\begin{verbatim}
rule ::= 'a' rdp_rule_0 .
rdp_rule_0 ::= ('b')0@4',' .
\end{verbatim}
\end{quote}
Recall that parantheses are special case of the iterator operator.
Effectively, if if you write
\begin{quote}
{\tt
rule ::= ( r ) .}
\end{quote}
\rdp\ automatically inserts an iterator construct and translates
the rule to
\begin{quote}
{\tt
rule ::= ( r )1@1\# .}
\end{quote}
So including parantheses 
in a rule will cause \rdp\ to generate an new corresponding
internal subrule.
For example, \rdp\ represents the grammar
\begin{quote}
\begin{verbatim}
rule ::= 'a' ('b' | 'c') 'd' .
\end{verbatim}
\end{quote}
internally as
\begin{quote}
\begin{verbatim}
rule ::= 'a' rdp_rule_2 'd' .
rdp_rule_2 ::= rdp_rule_1 | rdp_rule_0 .
rdp_rule_1 ::= 'b' .
rdp_rule_0 ::= 'c' .
\end{verbatim}
\end{quote}

\rdp\ treates single iterator constructs as though they were rules
with an aternate for each possible string. In other words
\begin{quote}
\begin{verbatim}
rule ::= ('a')1@6'+' .
\end{verbatim}
\end{quote}
behaves in the same way as
\begin{quote}
\begin{verbatim}
rule ::= 'a' | 'a''+''a' | ...
               | 'a''+''a''+''a''+''a''+''a''+''a' .
\end{verbatim}
\end{quote}

\subsection*{Recursion issues}

The language $\{a, aa, aaa, aaaa, \ldots\}$ can be described in three 
obvious ways in \rdp's IBNF, using right recursion, using left recursion
and using the iterator construct:
\begin{quote}
\begin{verbatim}
rule ::= 'a' [ rule ] .
rule ::= [ rule ] 'a' .
rule ::= ('a')1@0#
\end{verbatim}
\end{quote}
(In fact \rdp\ will not generate a parser from the second
grammar because it is not left factored, see Chapter~\ref{LL1},
but we shall use it here to illustrate the constrast in approaches.)
It would be possible to implement the iterator operator recusively
so it behaved like the first rule. In this case a derivation of
{\tt aaa} would have the form
\begin{quote}
{\tt 
rule $\mderive{}$ a rule $\mderive{}$ a a rule $\mderive{}$ a a a rule
$\mderive{}$ a a a
}
\end{quote}
In the case of the left recursive representation, a derivation of
{\tt aaa} would have the form
\begin{quote}
{\tt 
rule $\mderive{}$ rule a $\mderive{}$ rule a a $\mderive{}$ rule a a a
$\mderive{}$ a a a
}
\end{quote}
However, iterator constructs, as their name implies, are actually
implemented in \rdp\ using iteration so 
\begin{quote}
\tt
rule ::= ('a')1@0\#
\end{quote}
behaves as though it were the (infinite) rule
\begin{quote}
\tt
rule ::= 'a' | 'a''a' | 'a''a''a' | ...
\end{quote}
As a result, a derivation of
{\tt aaa} in the iterator grammar has the form
\begin{quote}
{\tt 
rule $\mderive{}$ a a a
}
\end{quote}

These issues are important when using semantic actions in the grammar,
see Chapter~\ref{semantics}, because they determine when in the parse
the actions are executed.

%From the point of view of semantic actions,
%it is also important to note one other aspect of \rdp's treatment of
%the iterator construct. Constructs which can generate the empty
%string, i.e. those whose low count is 0, are represented
%implicitly (although not explictly) so that the empty string
%is matched before the subroutine call rather than inside
%the subroutine. This means that the rule
%\begin{quote}
%{\tt
%rule ::= 'a' \iter{\tt 'b'}{0}{6}{,} 'c' .
%}
%\end{quote}
%is effectively represented in \rdp\ as
%\begin{quote}
%{\tt
%rule ::= 'a' rdp\_rule\_0 'c' | 'a' 'c' .\\
%rdp\_rule\_0 ::= \iter{\tt 'b'}{1}{6} .}
%\end{quote}
%rather than as
%\begin{quote}
%{\tt
%rule ::= 'a' rdp\_rule\_0 'c' .\\
%rdp\_rule\_0 ::= \iter{\tt 'b'}{0}{6}{','} .
%}
%\end{quote}
%In particular, it means that 
%\begin{quote}
%\begin{verbatim}
%rule ::= 'a' [r] 'c' .
%\end{verbatim}
%\end{quote}
%should be thought of as 
%\begin{quote}
%\begin{verbatim}
%rule ::= 'a' X 'c' | 'a' 'c' .
%X ::= r.
%\end{verbatim}
%\end{quote}
%rather than as
%\begin{quote}
%{\tt 
%rule ::= 'a' X 'c' .\\
%X ::= r | $\epsilon$ .
%}
%\end{quote}
%Thus the generated parser constructs the derivation
%$$
%{\tt rule}\ \mderive{}\ {\tt ac}
%$$
%of the string $ac$ rather than the derivation
%$$
%{\tt rule}\ \mderive{}\ {\tt a X c}\ \mderive{}\ {\tt ac}.
%$$

%The point here is that semantic actions associated with the
%iterator construct will not be executed in the case
%where the construct generates the empty string. We shall
%return to this issue in Chapter~\ref{semantics}.



\chapter{Restrictions on \rdp\ grammars}\label{LL1}

As we discussed in Chapter~\ref{basic},
\rdp\ generates parsers which use a {\em recursive descent} technique.
This means that there are restrictions on the grammars which
admit \rdp-generated parsers. If \rdp\ is presented with
a grammar which breaks these restrictions then it will issue a diagnostic
message explaining the nature of the problem and 
indicating the place in the
grammar where it occurs. In order to understand these messages and to
use \rdp\ effectively, it is necessary to understand the
conditions which input grammars must satisfy.
In this chapter we consider these
conditions in detail. We shall use the grammar
{\tt expr1.bnf}
\begin{quote}
\begin{verbatim}
S ::= E Y.
Y ::= ['+' S].
E ::= T X.
X ::= ['*' E].
T ::= 'a' | 'b'.
\end{verbatim}
\end{quote}
introduced in Chapter~\ref{basic}, to illustrate the discussion.

\section{Deterministic choice on alternates}
At each step in the parsing process, the parser replaces a non-terminal
with a string from the right hand side of that non-terminal's
grammar rule.
When there is more than one alternate in a grammar rule the parser
needs an algorithm for deciding which of the alternates to choose.
This decision is made by looking at the 
{\em current input symbol}. In order to see how this is done we need
to consider the parsing process in more detail.

Strings which can appear in derivations that begin with the start symbol
are called {\em sentential forms}. So in the following $S$, $\alpha_1$,
$\ldots$, $\alpha_n$ are all sentential forms:
$$
S \mderives{} \alpha_1\mderives{}\ldots\mderives{}\alpha_n.
$$
By the {\em current sentential form} at a stage in a parser execution we
shall mean the sentential form which was constructed at the previous
step. So $\alpha_n$ is the current sentential form at the stage at
which a parser has constructed the above derivation steps. 

Suppose that the input string $xyxyz$ is being parsed.
The parser is generating a left-most derivation
of the string, thus in the first steps of the process the
parser is replacing the first symbol of the current sentential form
and is attempting to construct a sentential form which looks like
$x\delta$. Suppose that the parser has constructed the steps
$$
S \mderives{}\alpha\mderives{}\beta\mderives{}\gamma
$$
that $\gamma$, the current sentential form,
begins with the non-terminal $X$ and that $X$ has associated grammar
rule
$$
X \pdn\ \beta_1\ |\ \beta_2\ |\ \beta_3\ |\ \beta_4\ .
$$
At the next step the parser should only replace $X$ with $\beta_1$ if there
is some derivation $\beta_1\derive x\beta_1'$ or if
$\beta_1\derive\epsilon$. In any other case it will be impossible to
complete the derivation if $\beta_1$ is chosen to replace $X$.

For example, suppose that we are using the expression grammar 
{\tt expr1.bnf} 
to parser the string {\tt a+b} and that the construction has
reached the stage
\begin{quote}$
S \mderives{} E Y \mderives{} T X Y $
\end{quote}
If at the next step {\tt T} were to be replaced by {\tt b}, giving
\begin{quote}
$S \mderives{} E Y \mderives{} T X Y \mderives{} b X Y$
\end{quote}
it would be impossible to complete the derivation and generate
{\tt a+b}.

\section{\FIRST\ sets}
The above discussion highlights the need to know which terminals
can appear at the beginning of something derivable
from a given string $\gamma$. Such terminals belong to the so-called
\FIRST\ set of $\gamma$. Formally we define {\FIRST($\gamma$)} to be
the set of terminals which can begin a string derivable from $\gamma$,
together with $\epsilon$ if $\gamma\derive\epsilon$.

For the example {\tt expr1.bnf}
at the beginning of the chapter we have
\begin{quote}
$\FIRST(a)$ = $\{a\}$ \\
$\FIRST(T)$ = $\{a,b\} $ = $\FIRST(E)$ = $\FIRST(S)$\\
$\FIRST(X)$ = $\{*, \epsilon\}$ \\
$\FIRST(EY)$ = $\{a,b\}$ = $\FIRST(TX)$.
\end{quote}

The general description of \FIRST\ sets is:
$$
\FIRST_{\bf T}(\gamma) = \{\ t\in{\bf T}\ |\ \gamma\derive t\gamma'\}
$$
$$
\FIRST(\gamma)=\cases{
\FIRST_{\bf T}(\gamma)\cup\{\epsilon\},& if $\gamma\derive\epsilon$,\cr
\FIRST_{\bf T}(\gamma),& otherwise.\cr
}
$$
Notice that if $t$ is a terminal then
$$
\FIRST(t) = \{t\} = \FIRST(t\gamma)
$$
for any string $\gamma$.

\rdp-generated parsers maintain a list of the \FIRST\ sets, and their contents,
for each alternate in each grammar rule of the grammar.
The parsers use these sets to decide with which alternate to replace a
given non-terminal.

\section{Parsing with \FIRST\ sets}

As the parse proceeds, the first few symbols of the
current sentential form will correspond exactly to an initial portion
of the input string. The parser reads in the input string symbol-by-symbol,
starting from the left of the string. When the first symbol in the input
string appears at the front of the current sentential form the parser
reads in the next symbol from the input. At each stage in the parsing
process the parser tries to replace the left-most non-terminal in the
current sentential form with an alternate that has the current input
symbol in its \FIRST\ set. 
For example, suppose that the input string
is $xyxyz$, that the parser has so far constructed
the derivation
$$
S\ \mderive{}\ \alpha_1\ \mderive{}\ \ldots\ \mderive{}\ \alpha_m\ 
\mderive{}\ xyx X\gamma,
$$
and that $X$ has associated grammar
rule
$$
X \pdn\ \beta_1\ |\ \beta_2\ |\ \beta_3\ |\ \beta_4\ .
$$
The current input symbol is $y$ and so the parser needs to replace
$X$ by which ever alternate has $y$ in its \FIRST\ set.

If no alternate has this property, and if $X$ does not derive $\epsilon$,
then the derivation cannot be completed and the parse has failed.
If more than one alternate has this property then the parser cannot
decide how to proceed. 

Thus it is necessary for grammars which are
to have \rdp-generated parsers to have the {\em disjoint \FIRST\ set property}.
In fact, grammars that are input to \rdp\ need to have a slightly stronger
property than this, which we will describe in the next three sections.

\section{The problem with $\epsilon$ rules}\label{empty}
We have seen in the previous section that \rdp\ requires each grammar
rule in the input
grammar to have alternates with disjoint \FIRST\ sets. That is,
if 
$$
X ::=\ \alpha\ |\ \beta\ .
$$
then the intersection of the \FIRST\ sets must
be empty, i.e. $\FIRST(\alpha)\cap \FIRST(\beta)=\emptyset$
(here $\emptyset$ denotes the emptyset, the set $\{\}$ which has no
elements).
However, if the grammar contains $\epsilon$ rules
(grammar rules of the form $A ::= ... |\ \epsilon\ |...$) then this property
may not be enough to allow the parser to determine which alternate
to use. 

Consider the grammar
\begin{quote}
\begin{verbatim}
S ::= 'b' A 'a' .
A ::= ['a'] .
\end{verbatim}
\end{quote}
If an \rdp-generated parser for this grammar is given input {\tt ba}
and has constructed the steps
$$
{\tt S}\ \mderive{}\ {\tt bAa}
$$
then the current input symbol is {\tt a} and since {\tt A}$\mderive{}${\tt a} the
parser may take this as the next step, giving
$$
{\tt S}\ \mderive{}\ {\tt b A a}\ \mderive{}\ {\tt b a a}
$$
which cannot be extended to generate {\tt ba}. However, if
the parser performed the step {\tt A}$\mderive{}\epsilon$ then
we would get a successful parse
$$
{\tt S}\ \mderive{}\ {\tt b A a}\ \mderive{}\ {\tt b a}
$$
Why not make choosing the $\epsilon$ step the default? 
If the parser is given input {\tt baa}
then choosing the $\epsilon$ alternate would result in failure.
The problem is that the parser cannot decide whether to use $\epsilon$
just by looking at the current input symbol {\tt a}.


We can see the general problem by considering
again the example, from the previous section,
in which the input string
is $xyxyz$, the parser has so far constructed
the derivation
$$
S \mderive{}\alpha_1\mderive{}\ldots\mderive{}\alpha_m
\mderive{}xyx X\gamma,
$$
and $X$ has associated grammar
rule
$$
X \pdn\ \beta_1\ |\ \beta_2\ |\ \beta_3\ |\ \beta_4\ .
$$
Suppose also that $\beta_4\derive\epsilon$. We could replace $X$ with
$\beta_4$ at the next step in the derivation and hope to complete the 
derivation from the string $\gamma$. 
If it is also the case that 
one of the other alternates, $\beta_1$ say, has $y$ in its \FIRST\ 
set then we can't decide whether to use $\beta_1$ or $\beta_4$ to
replace $X$.

If $\beta_4$ were used in the next step of the derivation and the parse 
were
to be successful then we would have to have $y\in \FIRST(\gamma)$ and 
hence
$\gamma\derive y\gamma'$ for some string $\gamma'$.
This would mean that
$$
S\derive xyxX\gamma\derive xyxXy\gamma'
$$
and hence that $y$ can follow $X$ in some sentential form.
Thus we are led to consider the so-called \FOLLOW\ sets.

\section{\FOLLOW\ sets}
The convention for recursive descent parsers is that the $\epsilon$
generating rule, $\beta_4$ in the above example, will only be chosen if
there is no alternate that has an appropriate \FIRST\ set.
This will be a correct strategy if none of the elements in these \FIRST\ sets
can also {\em follow} $X$ in a sentential form.
This is what is required for the above example because 
the existence of a successful derivation using $\beta_4$
would mean that $y$ could follow $X$, and hence 
the non-overlap between \FIRST\ sets and elements that can follow $X$
would mean that no
alternate had been chosen on application of the \FIRST\ set criterion.

Thus we are interested in the set of terminals which can follow $X$
in some sentential form. 

In the expression grammar {\tt expr1.bnf} we have
$$
{\tt S}\ \derive\ {\tt E + S}, \qquad {\tt S}\ \derive\ {\tt T * E Y}, 
\qquad {\tt S}\ \derive\ {\tt T + S},
$$
in fact
\begin{quote}
$\FOLLOW_{\bf T}({\tt E}) = \{{\tt +}\}$\\
$\FOLLOW_{\bf T}({\tt T}) = \{{\tt *},{\tt +}\}$
\end{quote}

Formally, for any non-terminal $A$ in any grammar we define
$$
\FOLLOW_{\bf T}(A) = \{t\in{\bf T}\ |\ S\derive\alpha At\beta\}.
$$
If $A$ can occur at the end of a sentential form then the \FOLLOW\ set
of $A$ also contains a special end-of-file symbol {\tt EOF}.
Then we have
$$
\FOLLOW(A) =\cases{
\FOLLOW_{\bf  T}(A)\cup\{{\tt EOF}\},& if $S\derive\gamma A$,\cr
\FOLLOW_{\bf  T}(A),& otherwise.\cr
}
$$

So for the expression grammar {\tt expr1.bnf} we have
\begin{quote}
$\FOLLOW({\tt X}) = \{{\tt +}, {\tt EOF}\}$\\
\end{quote}

\section{LL(1) grammars}
Grammars which have the properties that 
\begin{itemize}
\item
no two distinct alternates
in one grammar rule have common elements in their \FIRST\ sets,
\item
and that if a non-terminal $X$ derives $\epsilon$ then the \FIRST\ 
sets of the alternates in its grammar rule must be disjoint
from the \FOLLOW\ set of $X$
\end{itemize}
are called LL(1) grammars. Formally, a grammar is LL(1) if
\begin{enumerate}
\item
if $X ::= ... |\ \alpha\ | ... |\ \beta\ | ...$ t
hen $\FIRST(\alpha)\cap \FIRST(\beta) = \emptyset$
\item
if $X ::= ...|\ \alpha\ |...$ and $X\derive\epsilon$ then 
$\FIRST(\alpha)\cap\FOLLOW(X) = \epsilon$.
\end{enumerate}

\rdp\ requires its input grammars to be LL(1)
(although there is one special case involving the iterator construct
in \rdp's IBNF).
If the input grammar is not LL(1) then \rdp\ issues an error
message detailing which rule(s) is causing the problem.

\section{Overriding the LL(1) restrictions}
There are some constructs in some programming languages
which cannot be expressed
in an LL(1) grammar. A classic example is the {\tt if..then..else}
statement and its variants. For example, using the following grammar
\begin{quote}
\begin{verbatim}
(** ifelse1.bnf **)

S ::= 'if' B 'then' S X | 'STOP' | 'SKIP' .
X ::= ['else' S] .
B ::= 'true' | 'false' .
\end{verbatim}
\end{quote}
there are two distinct derivations of the string
\begin{quote}
\begin{verbatim}
if true then if false then STOP else SKIP
\end{verbatim}
\end{quote}
When the parser has constructed the following portion of a derivation
$$
{\tt S}\ \mderive{} \\
{\tt if\ B\ then\ S X}\ \mderive{}\\
{\tt if\ true\ then\ S X}\ \mderive{}\\
{\tt if\ true\ then\ if\ B\ then\ S\ X\ X} 
$$
there is no way to decide whether to replace the first $X$ by $\epsilon$
or by {\tt 'else' S}.

If the above grammar is input to \rdp\ the following message is generated:
{\small
\begin{verbatim}
******: Error - LL(1) violation - rule
 X ::= X .
 contains null but first and follow sets both include: 'else'
******: Error - LL(1) violation - rule
 rdp_X_1 ::= [ 'else' S ] .
 contains null but first and follow sets both include: 'else'
******: Error - LL(1) violation - rule
 rdp_X_2 ::= [ 'else' S ] .
 contains null but first and follow sets both include: 'else'
******: Fatal - Run aborted without creating output files 
 - rerun with -F to override
\end{verbatim}
}
%(The exact meanings of these messages will be made clear after we have
%discussed \rdp's EBNF in Chapter~\ref{EBNF}.)
\noindent
From the point of view of parsing,
the choice is irrelevant because either will result
in a successful completion of the derivation. (Of course, the user
needs to know which choice will be made so that appropriate
semantics can be inserted. The \rdp\ default actions are explained in detail in
Chapter~7 of \cite{rdp:user:1.5}.)

We can force \rdp\ to create a parser by running it with the flag
{\tt -F}. There is a target {\tt parserf} in the makefile which calls
\rdp\ with the {\tt -F} flag. Typing
\begin{verbatim}
make GRAMMAR=examples\rdp_tut\ifelse1 parserf
\end{verbatim}
excutes the command
\verb=   rdp -F -oifelse1 examples\rdp_tut\ifelse1=\\
and generates the following message:
{\small
\begin{verbatim}
******: Error - LL(1) violation - rule
 X ::= X .
 contains null but first and follow sets both include: 'else'
******: Error - LL(1) violation - rule
 rdp_X_1 ::= [ 'else' S ] .
 contains null but first and follow sets both include: 'else'
******: Error - LL(1) violation - rule
 rdp_X_2 ::= [ 'else' S ] .
 contains null but first and follow sets both include: 'else'
******: Warning - Grammar is not LL(1) but -F set: writing files
******: 3 errors and 1 warning
Borland C++ 5.0 for Win32 Copyright (c) 1993,1996 Borland International
rdparser.c:
	bcc32 -erdparser.exe rdparser.obj arg.obj graph.obj memalloc.obj 
              scan.obj scanner.obj set.obj symbol.obj textio.obj 
Borland C++ 5.0 for Win32 Copyright (c) 1993,1996 Borland International
Turbo Link Version 1.6.72.0 Copyright (c)1993,1996 Borland International
	rdparser -v -Vrdparser.vcg -l examples\rdp_tut\ifelse1.str

rdparser
Generated on Dec 6 1997 8:55:27 and compiled on Dec 4 1997 at 9:22:37
******: 
     1: if true then if false then STOP else SKIP
******: 0 errors and 0 warnings
******: 0.000 CPU seconds used
\end{verbatim}
}
Notice that this time instead of issuing a fatal error message, \rdp\ 
has issued a warning and generated the files.
(Since the {\tt -F} flag overrides \rdp's safety checks it should
be used with caution.)

\section{Inspecting the \FIRST\ and \FOLLOW\ sets}
\rdp\ allows you to look at the \FIRST\ and \FOLLOW\ sets that it has created
for a particular grammar. This is useful if the grammar is not LL(1)
because it is possible to see where the offending sets overlap.
It also means that \rdp\ can be used as a tool for constructing \FIRST\ and
\FOLLOW\ sets for any given grammar. This is particularly useful for \FOLLOW\ 
sets whose construction by hand is quite error prone.

Using the flag {\tt -e} causes \rdp\ to print out in BNF format
the grammar rules
that it is using internally, 
to detail the \FIRST\ set for each alternate and
the {\tt STOP} set (the \FOLLOW\ set together with
{\tt EOF}) for each non-terminal. Typing
\begin{verbatim}
rdp -e examples\rdp_tut\expr1
\end{verbatim}
results in the following output.
(Here, the non-terminals are shown as functions for reasons which
are explained in Chapter~\ref{semantics}.)
{\small
\begin{verbatim}
 E(void):void ::= rdp_E_0() .
 First set is {'a', 'b'}
 Stop set is {EOF, '+'}
 Production is called 2 times

 S(void):void ::= rdp_S_0() .
 First set is {'a', 'b'}
 Stop set is {EOF}
 Production is called 2 times

 T(void):void ::= rdp_T_0() | rdp_T_1() .
 First set is {'a', 'b'}
 Stop set is {EOF, '*', '+'}
 Production is called once

 X(void):void ::= rdp_X_2() .
 First set is {(NULL) '*'}
 Stop set is {EOF, '+'}
 Production is called once

 Y(void):void ::= rdp_Y_2() .
 First set is {(NULL) '+'}
 Stop set is {EOF}
 Production is called once

 rdp_E_0(void):void ::= T() X() .
 First set is {'a', 'b'}
 Stop set is {EOF, '+'}
 Production is called once

 rdp_S_0(void):void ::= E() Y() .
 First set is {'a', 'b'}
 Stop set is {EOF}
 Production is called once

 rdp_T_0(void):void ::= RDP_T_a() .
 First set is {'a'}
 Stop set is {EOF, '*', '+'}
 Production is called once

 rdp_T_1(void):void ::= RDP_T_b() .
 First set is {'b'}
 Stop set is {EOF, '*', '+'}
 Production is called once

 rdp_X_0(void):void ::= RDP_T_17 /* * */() E() .
 First set is {'*'}
 Stop set is {EOF, '+'}
 Production is called once

 rdp_X_1(void):void ::= [ rdp_X_0() ].
 First set is {(NULL) '*'}
 Stop set is {EOF, '+'}
 Production is called once

 rdp_X_2(void):void ::= rdp_X_1() .
 First set is {(NULL) '*'}
 Stop set is {EOF, '+'}
 Production is called once

 rdp_Y_0(void):void ::= RDP_T_18 /* + */() S() .
 First set is {'+'}
 Stop set is {EOF}
 Production is called once

 rdp_Y_1(void):void ::= [ rdp_Y_0() ].
 First set is {(NULL) '+'}
 Stop set is {EOF}
 Production is called once

 rdp_Y_2(void):void ::= rdp_Y_1() .
 First set is {(NULL) '+'}
 Stop set is {EOF}
 Production is called once
\end{verbatim}}


\chapter{The mini grammar}
In this chapter we give an \rdp\ IBNF definition {\tt mini1.bnf} of a small
language. The language allows variable declarations and assignment
of integer arithmetic expressions to those variables. 
Addition, subtraction, multiplication and division are all left associative,
and multiplication and division have higher priority than addition and
subtraction. There are also unary plus, {\tt +}, and minus, {\tt -},
signs, and an exponentiation operator, \verb+ ^+, which is right associative.
It allows branching {\em via} an {\tt if}
statement, and variable assignment and declaration. The 
C-style {\tt =} sign
is used for assignment. There is a print statement which can print
sequences of strings and values of expressions. Strings are delimited
by double quotes ({\tt "}), and comments are enclosed in Pascal-style 
brackets \verb+(* *)+ and can be nested.

\begin{verbatim}
(** mini1.bnf **)   

program   ::= {([var_dec  | statement ]) ';' }.
var_dec   ::= 'int' ( ID [ '=' e1 ] )@','.
statement ::=  ID '=' e0 
               | 'if' e0 'then' statement [ 'else' statement ] 
               | 'print' '(' ( e0 | String )@',' ')'.
e0 ::=  e1 ['>' e1 | '<' e1 | '>=' e1 |'<=' e1 | '==' e1 | '!=' e1].
e1 ::= e2 {'+' e2 | '-' e2 } .
e2 ::= e3 {'*' e3 | '/' e3 } .
e3 ::= '+' e4 | '-' e4 | e4 .
e4 ::= e5 ['^' e1] .
e5 ::= ID | INTEGER | '(' e1 ')' .
comment ::= COMMENT_NEST('(*' '*)').   
String ::= STRING_ESC('"' '\\') . 
\end{verbatim}

The {\tt 'if'...} alternate in the grammar rule for {\tt statement} is
inherently ambiguous. Thus the above grammar is not LL(1).
When the grammar is input to \rdp\ it will issue an error message
and terminate. If \rdp\ is run with the flag {\tt -F} this will force \rdp\ to
produce a parser from the above grammar. 
\clearpage
{\small
\begin{verbatim}
rdp -F examples\rdp_tut\mini1

******: Error - LL(1) violation - rule
 rdp_statement_2 ::= [ 'else' statement ] .
 contains null but first and follow sets both include: 'else'
******: Warning - Grammar is not LL(1) but -F set: writing files
******: 1 error and 1 warning
\end{verbatim}}

The generated parser will
resolve the ambiguity in `if' statements by using `longest match'.
The effect of this is that an `else' clause will be assumed to match
the nearest `then' to the left. In other words
\begin{verbatim}
if a<b then if c==d then c=1 else d=1 ;
\end{verbatim}
will be parsed as
$$
if\ a<b\ then\ (if\ c==d\ then\ c=1\ else\ d=1)\ ;
$$
not as
$$
if\ a<b\ then\ (if\ c==d\ then\ c=1)\ else\ d=1\ ;
$$


\chapter{Semantic actions}\label{semantics}
So far we have only described how to use \rdp\ to generate a parser
for a language. Parsers allow us to test whether a given string is in the
language, but what we actually want is to execute some
behaviour when a sentence is recognised. For example, a compiler,
on recognising a sentence, constructs an equivalent sentence
(one with the same meaning) in some specified target language.
An interpreter, on recognising a sentence, executes it.
A pretty printer, on recognising a sentence, reformats it and
then prints it out in what is usually a more readable form.

\rdp\ can be used to generate parsers which do useful work of these types.
The basic approach is that {\em
semantic actions} are inserted in the grammar rules; these actions are 
executed by the generated parser when the rule is used.

{\em Attributes} are used to pass
information between rules and can be used within semantic actions.
Two kinds of attributes
are supported by \rdp: {\em inherited attributes} which are passed as
parameters into rules and {\em synthesized attributes} that act like
return values from rules.

In this chapter we describe how various aspects
of these mechanisms work for \rdp-generated 
parsers. A full description of \rdp\ semantic actions
can be found in \cite{rdp:user:1.5}. In this guide we just illustrate the basic
ideas and point out some of the things to be wary of.

We begin with a little discussion of the function call based approach
which is used to implement \rdp-generated parsers. We then consider
a particular example of semantic action use, consider the iterator
construct in more detail and give an introduction to the use
of inherited attributes.

\section{The function based implementation of \rdp-generated \\
parsers}

The input for \rdp\ is a language
specification, {\tt grammar.bnf} say,
written in IBNF. \rdp\ writes a C program,
{\tt grammar.c} say,
based on the IBNF it is given. This program contains a function
for each non-terminal in the grammar. The code for each function depends
on the right hand side of the grammar rule for the non-terminal.
In a simple \rdp\ parser the functions take no input and return
nothing.


Suppose that the input grammar is
\begin{quote}
\begin{verbatim}
(** functn1.bnf **)

S ::= INTEGER E .
E ::= '+' E | '-' E | INTEGER .
\end{verbatim}
\end{quote}
The \rdp-generated file {\tt functn1.c} will contain two
functions {\tt void S()} and {\tt void E()} and a function
\verb+scan_()+ which reads the next input symbol and stores it
in a global variable \verb+current_input_symbol+
\footnote{
This global variable is actually a record {\tt text\_\,scan\_\,data}
with a field which is a union one of whose entries holds the
lexeme of the input symbol. To simplify this exposition
we shall think of this entry as a global variable which we
shall call {\tt current\_\,input\_\,symbol} .)}.
The function {\tt S()}
can be thought of as beginning with a call to a scanner function
\verb+ scan_test(INTEGER)+ which tests the current input symbol to 
see if it is 
an integer. If it is an integer then 
this symbol has been correctly parsed in which case
\verb+ scan_()+ is called to read in the next input symbol
and then the function {\tt E()} is called to continue the parse.

\begin{quote}
\begin{verbatim}
void S(void){
    scan_test( INTEGER );
    scan_();
    E(); 
}
\end{verbatim}
\end{quote}

The function {\tt E()} contains a branch statement with a branch
for each of the three alternates in its grammar rule. The current
input symbol is tested against the \first\ set of each alternate
and then the corresponding branch is executed. In this case
\verb= scan_test('+')= is called and if it returns with a match to the
current input symbol, the next input symbol is read and then
{\tt E()} is called again. If the match is not found then
\verb+ scan_test('-')+ is called. If this matches then the next input symbol
is read and {\tt E()} is called, otherwise \verb+ scan_test(INTEGER)+
is called. If this matches then the next input symbol is read, no
other action is required. If this does not match then the input string
is not in the language and a suitable error message is issued.

The complete parser simply calls \verb+ scan_()+ to
read in the first input symbol and then calls
the function for the start symbol, in this case {\tt S()}.

When \rdp\ generates a C file from the above grammar it provides
a lot of other code to, for example, set up a symbol table and
issue error messages. The following is a severely filleted version
of the file {\tt functn1.c} created using the command

\verb+ rdp -ofunctn1 examples\rdp_tut\functn1+

\clearpage
{\small
\begin{verbatim}
/*******************************************************************
*
* Parser generated by RDP on Nov 02 1997 09:33:36 from functn1.bnf
*
*******************************************************************/
...
/* Parser forward declarations and macros */
static void E(void);
void S(void);

/* Parser functions */
static void E(void){
  if (scan_test('+')) {
    scan_();
    E(); }
  else
    if (scan_test('-')) {
      scan_();
      E(); }
    else
      if (scan_test( INTEGER )) { scan_(); }
      else { /* report error in input */ }
}

void S(void){
  scan_test( INTEGER );
  scan_();
  E();
}

int main( ... ) {
  ...
  scan_();
  S();         /* call parser at top level */
  ...
}
/* End of functn1.c */
\end{verbatim}
}

\section{Semantic actions -- an example}
The following grammar can be input to \rdp:
\begin{verbatim}
(** functn2.bnf **)

S:integer ::= INTEGER:val1 [* result = val1 ; *] 
              ('+' S:val2 [* result = val1 + val2 ; *] | ';' ) 
\end{verbatim}

\noindent
The underlying grammar rule is
\begin{verbatim}
S ::= INTEGER ( '+' S | ';' ) .
\end{verbatim}
which generates sums of integers terminated by a semi-colon. 
The additional details are
attribute names (following colons :) and actions
(between brackets {\tt [* *]}). We shall see below that the attributes
cause the corresponding parser functions to return values rather than
void results, so we have {\tt integer S()}, 
and the actions are inserted verbatim into the code for {\tt S()}.
We now describe these effects in detail.

The parser functions associated with each non-terminal in the grammar
can be made to return a value.
The type of this value is indicated after a colon
on the left hand side of the corresponding grammar rule.
So, the 
declaration {\tt :integer} which appears on the left hand side
of the rule causes the function {\tt S()} 
to return an (unsigned) integer which is defined as a
C {\tt unsigned long}.
The identifier which holds the value to be returned is always
called {\tt result}.  Thus the function has the form
\begin{quote}
\begin{verbatim}
integer S(void){
  integer result;
  scan_test( INTEGER );
  scan_();
  if (scan_test('+')) {
    scan_() ;
    val2 = S(); }
  else 
  ...
  return result ;
}
\end{verbatim}
\end{quote}


The grammar writer will often want to give the returned value from a
routine a local name, so that it can be used. This is done by
putting a colon and then the chosen local name after the
symbol which generated the call to the routine. For example,
the declaration {\tt S():val2}
in {\tt functn2.bnf}
instructs the parser to write
the value returned by the call to {\tt S()}  to 
a variable called {\tt val2}. The value of a token such as {\tt INTEGER}
may also be given a local name, again by putting a colon and 
then the chosen local name after the token. 
For example,
{\tt INTEGER:val1} causes the value of the {\tt INTEGER} just scanned,
which was written to \verb+ current_input_symbol+ by \verb+scan_()+,
to be copied to {\tt val1}.
Thus the function {\tt S()} can be thought of as having the form
\begin{quote}
\begin{verbatim}
integer S(void) {
  integer result;
  long int val1;
  integer val2;
  
  scan_test(INTEGER);
  val1 = current_input_symbol;
  scan_();
  if (scan_test('+')) {
     scan_();
     val2 = S();
  }
  else
  ...
  return result;
}
\end{verbatim}
\end{quote}


The statements which appear between the brackets \verb+[*...*]+
in {\tt functn2.bnf}
are fragments of C code. As the parser constructs a derivation
it executes the fragments, as it meets them. 
This is done by inserting the code fragments verbatim in the
parser function at the place where they are encountered. For example,
the action after {\tt INTEGER} is inserted before the call to 
\verb-scan_test(+)- and the second action is
inserted after the call to {\tt S()}.
Thus we can think of {\tt S()} as having the form

\begin{quote}
\begin{verbatim}
integer S(void) {
  integer result;
  long int val1;
  integer val2;
  
  val1 = current_input_symbol;
  scan_test(INTEGER);
  scan_();
  result = val1 ; 

  if (scan_test('+')) {
     scan_();
     val2 = S();
     result = val1 + val2 ; }
  else
     if (scan_test(';')) { scan_(); }
     else /* error report */

  return result;
}
\end{verbatim}
\end{quote}

\vskip.5cm
To gain experience of these ideas the you might like to add an
extra grammar rule and associated semantic action which prints out
the value of an expression.
\begin{verbatim}
(** functn3.bnf **)

S ::= E:val [* printf("%i\n", val); *] .
E:integer ::= INTEGER:val1 [* result = val1; *] 
               ('+' E:val2 [* result = val1 + val2; *] | ';' ) .
\end{verbatim}
Running the generated parser on the string {\tt 2+3+6;}
effectively causes the following code to be executed
(the indentation indicates the nesting level of the parser function
producing the output)
\begin{quote}
\begin{verbatim}
val1 = 2 
result = val1
     /* code from subcall to E() */
     val1 = 3
     result = val1
         /* code from second subcall to E() */   
         val1 = 6
         result = val1
     val2 = result     /* val2 == 6 */
     result = val1 + val2
val2 = result          /* val2 == 9 */
result = val1 + val2
return result          /* return 11 */
\end{verbatim}
\end{quote}
The following output should be produced:
{\small
\begin{verbatim}
Generated on May 01 1997 17:15:40 and compiled on Apr 30 1997 at 13:02:55
******:
     1: 2 + 3 + 6;
11 
******: 0 errors and 0 warnings
******: 0.020 CPU seconds used
\end{verbatim}}


\section{Semantic actions in empty grammar rules}

The following grammar generates strings which are sums of integers
that are not terminated by a semi-colon.
%\begin{quote}
\begin{verbatim}
(** arith1.bnf **)

E:integer ::= INTEGER:val1 [* result = val1 *] 
                [ '+' E:val2 [* result = val1 + val2; *] ] .
\end{verbatim}
%\end{quote}
This corresponds to a parser function which is essentially
of the form
\begin{quote}
\begin{verbatim}
integer E(void) {
  integer result;
  long int val1;
  integer val2;

  scan_test(INTEGER);
  val1 = current_input_symbol;
  scan_();
  result = val1;
  if (scan_test('+')) {
     scan_();
     val2 = E();
     result = val1 + val2; 
  }
  return result;
}
\end{verbatim}
\end{quote}   


The semantic actions inserted inside IBNF
square brackets {\tt []} are only executed if the non-epsilon
part of the bracket is executed. In other words, the above
grammar is treated like
%\begin{quote}
\begin{verbatim}
E:integer ::= INTEGER:val1 [* result = val1 *] 
               ('+' E:val2 [* result = val1 + val2; *] | epsilon).
\end{verbatim}
%\end{quote}
not like
\begin{verbatim}
E:integer ::= INTEGER:val1 [* result = val1 *] 
                ('+' E:val2 [* result = val1 + val2; *] 
                     | epsilon [* result = val1 + val2; *] ) .
\end{verbatim}
Often we need to execute
a semantic action when an empty rule
is used, for example to initialise a variable. Semantic actions
which are to be executed on application of an empty rule (so called
default rules) are appended
to the square brackets using a colon. For example, the grammar
\begin{verbatim}
(** arith2.bnf **)

E:integer ::= INTEGER:val1 
              ['+' E:val2 [*result=val1+val2;*] ]:[*result=val1;*]
\end{verbatim}
behaves like
\begin{verbatim}
E:integer ::= INTEGER:val1 
               ('+' E:val2 [* result = val1 + val2; *] 
                     | epsilon [* result = val1; *] ) .
\end{verbatim}
and corresponds to a parser function which is essentially
of the form
\begin{quote}
\begin{verbatim}
integer E(void) {
  integer result;
  long int val1;
  integer val2;

  scan_test(INTEGER);
  val1 = current_input_symbol;
  scan_();
  if (scan_test('+')) {
     scan_();
     val2 = E();
     result = val1 + val2;  }
  else {
       /* default action processing */
       result = val1 ;  }
  return result;
}
\end{verbatim}
\end{quote}   

\section{Semantic actions and the iterator construct}
Iterators are implemented as `while loops'. At the beginning
of each execution of the loop the left hand side of the iterator operator
is executed as though it were an alternate of a grammar rule.
The next input symbol is then compared to the delimiter (right hand
side) of the iterator operator. If there is a match then the while loop
is executed again.

For example, the rule 
\begin{verbatim}
(** iter1.bnf **)

E ::= ('a' | 'b' ) 0@0 ',' .
\end{verbatim}
can be thought of as corresponding to a parser function of the form
\begin{quote}
\begin{verbatim}
void E(void) {
   while (1) {
     if (scan_test('a')) { scan_(); }
     else {
        if (scan_test('b')) { scan_(); }
        else /* error */ }
     if (current_input_symbol !=  ',' ) break;
     scan_(); 
   }
}
\end{verbatim}
\end{quote}
which accepts, for example, \verb+a,a,b,a+ and {\tt a}.

Part of the point of an iterator construct is that it does
not involve subfunction calls, thus semantic actions are executed
immediately after the corresponding token is parsed, i.e. `on the way down',
rather than when the function call is complete, i.e. `on the way back up'.

Semantic actions can be placed in the left hand
argument of the iterator and after the delimiter using a colon.
The latter action is executed only if the iterator does not consume
any input symbols, i.e. if the low count is 0 and it matches the
empty string. (This is the same feature as 
{\tt [...]:[*...*]} described in the previous section.)

In the following example semantic actions are being used to count
the numbers of $a$'s, $b$'s and delimiter $,$'s in a given input string.
For example, on input {\tt a,b,b,b,a,a,a,a,a,b,a} we get
\begin{verbatim}
******:
     1: a, b, b, b, a, a, a, a, a, b, a
7, 4, 10
******:
\end{verbatim}
The number of delimiters should be one less than the sum of the numbers
of $a$'s and $b$'s, except in the case of the empty string when all
the numbers should be 0. Thus a separate action is executed in this case.
\begin{verbatim}
(** iter2.bnf **)

E ::= [*int left=0, right=0, delim=-1;*]
        ('a'[*left++; delim++;*] | 'b'[*right++; delim++;*]) 
           0@0 ',':[* delim=0;*]
      [* printf("%i, %i, %i\n", left, right, delim);*] .
\end{verbatim}
This can be thought of as corresponding to a parser function of the form
\begin{quote}
\begin{verbatim}
void E(void) {
    int left=0, right=0, delim=-1;
    if (scan_test('a') | scan_test('b')) {
      while (1)  {
        if (scan_test('a')) {
          scan_();
          left++; delim++; }
        else
          if (scan_test('b')) {
            scan_();
            right++; delim++; }
          else /* error */
        if (current_input_symbol != , ) break;
        scan_();
      } }
    else { delim=0; }

    printf("%i, %i, %i\n", left, right, delim);
}
\end{verbatim}
\end{quote}

\section{Left associative operators}

Recall the grammar {\tt arith2.bnf} 
\begin{verbatim}
E:integer ::= INTEGER:val1 
              ['+' E:val2 [*result=val1+val2;*] ]:[*result=val1;*]
\end{verbatim}

If we run the parser generated from this grammar
on the string {\tt 2 + 3 + 6} the sum will
effectively be calculated in a right associative
manner, i.e. {\tt 2 + (3 + 6)}. This is acceptable since addition is associative
and the result is the same in either case. 
However, if we used the same approach
to specify subtraction we would get counter-intuitive outcomes.
Running \rdp\ with the grammar
\begin{verbatim}
(** arith3.bnf **)

S ::= E:val [* printf("%i\n", val) ; *] .
E:integer ::= INTEGER:val1 
              ['-' E:val2 [*result=val1-val2;*] ]:[*result=val1;*] .
\end{verbatim}
and then running the resulting parser on the string {\tt 2 - 3 - 6}
produces
{\small
\begin{verbatim}
Generated on May 3 1997 7:01:20 and compiled on Apr 30 1997 at 8:02:55
******: 
     1: 2 - 3 - 6
5
******: 0 errors and 0 warnings
******: 0.058 CPU seconds used
\end{verbatim}}
\noindent
The result is {\tt 2-(3-6) = 5} rather than the expected
{\tt (2-3)-6 = -7}.

We consider three ways of specifying a grammar so that operators
such as {\tt '-'} are left associative. 

One is to use inherited attributes,
and will be discussed in the next section. 

Another is to use
a left recursive definition. We could begin with the grammar
\begin{verbatim}
S ::= E .
E ::= [ E '-' ] INTEGER.
\end{verbatim}
\noindent
then annotate it to give
\begin{verbatim}
S ::= E .
E:integer ::= [* int flag = 1; *] [ E:valB '-']:[* flag = 0; *] 
              INTEGER:valA [* if(flag){result = valB - valA;}
                                else {result=valA;}; *].
\end{verbatim}
%The parser function {\tt E()} would have the form
%\begin{quote}
%\begin{verbatim}
%static integer E(void){
%  integer result;
%  integer valB;
%  long int valA;
%
%  int flag = 1; 
%  if (scan_test(INTEGER)) {
%      valB = E();
%      scan_test( - );
%      scan_();
%  }
%  else {
%      /* default action processing */
%      flag = 0; 
%  }
%  scan_test(INTEGER);
%  valA = current_input_symbol;
%  scan_();
%  if(flag){ result = valB - valA;} else {result=valA;}; 
%
%  return result;
%}
%\end{verbatim}
%\end{quote}

\noindent
A correct parser based on this grammar would give subtraction left
associative semantics but because the grammar is left recursive
\rdp\ cannot generate a correct parser from it.

%If this code actually ran then it would evaluate differences with
%left associativity, but the code will not run because {\tt E()} 
%calls itself indefinitely. (In addition it does not carry out the branch
%test properly, two symbols of lookahead are required for this
%test.)

A third way of enforcing left associativity
is to use the iterator construct.
An \rdp-generated parser from the grammar
\begin{verbatim}
(** arith4.bnf **)

S ::= E:val [* printf("%i\n", val) ; *] .
E:integer ::= INTEGER:result
              {'-' INTEGER:val2 [*result=result-val2;*] } .
\end{verbatim}
(which has underlying form \verb~ E ::= INTEGER { - INTEGER }. ~)
effectively executes the following steps on input {\tt 2 - 3 - 6},
giving the required evaluation.
\begin{quote}
\begin{verbatim}
current_input_symbol = 2 ;
result = current_input_symbol ; /* result == 2 */
  current_input_symbol = 3 ;
  val2 = current_input_symbol ; 
  result = result - val2 ;      /* result == 2-3 */
    current_input_symbol = 6 ;
    val2 = current_input_symbol ; 
    result = result - val2 ;    /* result == (2-3)-6 */
\end{verbatim}
\end{quote}

\section{Expression semantics in {\tt mini}}
We can use the techniques discussed in the previous section to add
semantic actions to the grammar rules which define expressions in mini.
{\small
\begin{verbatim}
(** miniexp.bnf **)
USES("mexp_aux.h")

S ::= e1:val [* printf("%i\n", val); *] .
e1:integer ::= e2:result {'+' e2:val [* result = result + val; *]
                           | '-' e2:val [* result = result - val; *] }.
e2:integer ::= e3:result 
              {'*' e3:val [* result = result * val; *]
               | '/' e3:val [* if(val==0)
                {text_message(TEXT_FATAL,"divide by zero attempted\n");}
                else {result = result / val;}; *] } .
e3:integer ::= '+' e4:result | '-' e4:val [*result = -val;*] | e4:result .
e4:integer ::= e5:result ['^' e4:val 
            [*result = (integer) pow((double) result, (double) val );*] ].
e5:integer ::= ID | INTEGER:result | '(' e1:result ')' .
\end{verbatim}
}
\noindent
The exponent operator \verb+^+ is implemented using the C maths library
function {\tt pow()}. The \rdp\ {\em directive} {\tt USES({\em file})}
tells \rdp\
to include the contents of {\em file} in the generated parser. In our case
the file \verb+mexp_aux.h+ contains the command to include the maths
library.
\begin{verbatim}
#include <math.h>
\end{verbatim}
The file \verb+mexp_aux.h+ can also be used to declare global variables
which can then be used in the semantic actions.

\section{Inherited attribute definition}
Recall the grammar 
\begin{verbatim}
(** arith3.bnf **)

S ::= E:val [* printf("%i\n", val) ; *] .
E:integer ::= INTEGER:val1 
            ['-' E:val2 [*result=val1-val2;*] ]:[*result=val1;*].
\end{verbatim}
from the previous section. This generates sequences of differences of integers,
but it calculates the result using right associativity.

To get left associativity using the right recursive `subtraction'
grammar
\begin{verbatim}
S ::= E .
E ::= INTEGER [ - E ].
\end{verbatim}
we need to add semantic actions in such a way that {\tt val1},
the value of the first {\tt INTEGER}, 
is passed into the function called for
the following {\tt E}.

We can pass parameters into function calls by inserting them in
parentheses after the appropriate non-terminal. For example,
consider the following annotation of the right recursive
`subtraction' grammar
\begin{verbatim}
(** arith5.bnf **)

S:integer ::= INTEGER:val E(val):result [*printf("%i\n",result);*].
E(lhs:integer):integer ::= ['-' INTEGER:val [* val = lhs - val; *] 
                            E(val):result ]:[* result = lhs; *]. 
\end{verbatim}
An \rdp-generated parser for this grammar would effectively execute the
following steps on input {\tt 2 - 3 - 6}
\begin{quote}
\begin{verbatim}
   val = 2 ;              
      lhs = val;          /* lhs == 2 */
      val = 3 ;
      val = lhs - val;    
         lhs = val ;      /* lhs == 2-3 */
         val = 6;
         val = lhs - val;
            lhs = val;    /* lhs = (2-3)-6 */
            result = lhs; /* result = (2-3)-6 */
\end{verbatim}
\end{quote}
Running the \rdp-generated 
parser for {\tt arith5.bnf} on the input {\tt 2 - 3 - 6}
should produce the following:
{\small
\begin{verbatim}
Generated on May 18 1997 9:19:07 and compiled on May 12 1997 at 9:15:30
******:
     1: 2 - 3 - 6
-7
******: 0 errors and 0 warnings
******: 0.034 CPU seconds used
\end{verbatim}}
Thus we see that
\rdp\ rules can have parameters passed into them. 
Each \rdp\ rule name may be followed by a parenthesised list of
{\tt identifier:type} pairs which are instantiated into the parser
rule as value parameters, so that

\begin{quote}
\verb+ inherited_rule( x : integer y: real) ::= 'a' 'b'.+
\end{quote}
maps to 

\begin{quote}
\begin{verbatim}
integer inherited_rule(integer x, real y) { ... }
\end{verbatim}
\end{quote}

\subsection{Semantic actions for {\tt IF} statements}
A common use of inherited
attributes is to pass information into a rule that will be used to
switch semantic actions off and on. 

The {\tt if} statement in the {\tt mini} grammar has two subclauses,
one that should be executed if a specified conditional is true and
another that should be executed if the conditional is false.
We achieve this by passing a parameter in to all statements and
ensuring that the semantic actions associated with the statement are
only executed if the parameter is true.
{\small
\begin{verbatim}
(**  mini2.bnf  **)
USES("mexp_aux.h")

program   ::= {([var_dec | statement(1) ]) ';' }.
XSvar_dec   ::= 'int' ( ID [ '=' e1 ] )@','.

statement(flag:integer) ::=  
          ID '=' e1 [*if(flag){/* assignment will go here*/;};*]
          | 'if' e0:cnd 'then' [* cnd = cnd && flag;*] statement(cnd) 
                     [ 'else' [*cnd =!cnd&&flag;*] statement(cnd) ] 
          | 'print''(' ( e0:val [* if(flag){printf("%i\n", val);};*]
                         | String:str
                              [*if(flag){printf("%s\n", str);};*] 
                        )@',' ')'.

e0:integer ::=  e1:result 
                [  '>' e1:val  [*result = result > val;*]
                 | '<' e1:val  [*result = result < val;*]
                 | '>=' e1:val [*result = result >= val;*]
                 | '<=' e1:val [*result = result <= val;*]
                 | '==' e1:val [*result = result == val;*]
                 | '!=' e1:val [*result = result != val;*]
                ].

e1:integer ::= e2:result {'+' e2:val [* result += val; *]
                           | '-' e2:val [* result -= val; *] } .

e2:integer ::= e3:result 
               {'*' e3:val [* result *= val; *]
                | '/' e3:val [* if(val==0)
                {text_message(TEXT_FATAL,"divide by zero attempted\n");}
                else {result = result / val;}; *] } .

e3:integer ::= '+' e4:result | '-' e4:val [*result = -val;*] | e4:result.

e4:integer ::= e5:result ['^' e4:val 
           [*result = (integer) pow((double) result, (double) val );*] ].

e5:integer ::= ID | INTEGER:result | '(' e1:result ')' .

comment ::= COMMENT_NEST('(*' '*)').   
String:char* ::= STRING_ESC('"' '\\'):result .    
\end{verbatim}
}

In the grammar rule for {\tt program} the call to {\tt statement}
is passed a constant value 1 because its associated semantic actions
should always be executed. The actions associated with the
assignment and print alternates of
the {\tt statement} grammar rule will be executed if the parent statement
is called with a `true' flag. (Some of the actions have not actually been
written because we need to use a symbol table which will be discussed
in Chapter~\ref{symbol}.) The actions associated with the first
sub-statement in the `if' alternate will be executed if both the 
governing condition and the flag in the parent statement are true.

If we run an \rdp-generated parser for the above grammar on input
\begin{verbatim}
if 1>2 then print(1, "true") else print(2, "false") ;
\end{verbatim}
we get output of the form
{\small
\begin{verbatim}
******:
2
false
     1: if 1>2 then print(1, "true") else print(2, "false") ;
******: 0 errors and 0 warnings
******: 0.145 CPU seconds used
\end{verbatim}}



\chapter{Symbol tables in \rdp}\label{symbol}

We have already mentioned that \rdp-generated parsers deal with tokens, and that
there is a built-in scanner which groups the input stream into token 
lexemes.
The parser must keep track of the lexemes which match each token. 
For example, 
the parser only needs to know that the token it is currently dealing with is {\tt ID},
but in
the final output code we need to restore the actual identifier originally given. So this 
information
must be stored somewhere. Also, at various stages in the input program an identifier
will have a specific associated value, and usually an associated type. This
information is held by an \rdp-generated parser in a {\em symbol table}.

\rdp\ has a built-in symbol table building library. The user can
write parsers which use symbol tables by including calls to the \rdp\ 	
symbol table library functions. In this chapter we shall give a basic guide
to using this library.

\section{Hash coded symbol tables}

The symbol table is declared by the user in the BNF file which
defines their language. The following is an example of a declaration of
a symbol table which could be used in a parser for the mini language.

\begin{verbatim}
SYMBOL_TABLE(mini 101 31
             symbol_compare_string
             symbol_hash_string
             symbol_print_string
             [* char* id; integer i; *]
            )
\end{verbatim}
The first parameter, in this case {\tt mini}, is the name of
the symbol table.
A novice \rdp\ user can just use the above incantation, putting in the name
they require, but in order to have some 
understanding of the different components of the definition it is necessary
to have an elementary understanding of hash tables.
(More detailed information on \rdp\ symbol tables
can be found in \cite{rdp:user:1.5}.)

Symbol tables need to be of arbitrary size, since we do not know 
in advance how many
identifiers we will encounter during a particular parse. The \rdp-generated 
symbol tables are based on linked lists, organised 
to make looking up a value reasonably efficient. Rather than a single list,
a symbol table actually has several lists, called {\em buckets}. 
So, for example, instead of having
one list of length about 100, we may have 10 lists each of length about 10
and, provided we know which list to search, looking up an entry could
be a factor of 10 quicker.

This is the principle of a {\em hash table}.
The bucket in which a particular entry should be stored is calculated
from that entry by a {\em hash function}. The idea is that the hash function
should assign approximately the same number of entries to each of the buckets.

\vskip.3cm
\hspace*{.8cm}\input sym_sub.pic
\vskip.3cm
\noindent
Perhaps the simplest hash function for a string is to add together the
ASCII values for all of the characters in the string, and then take the
modulus of the result with the number of sub-lists available. It turns
out that this function works best if there are a prime number of
sublists. An even better result is achieved if another number, 
coprime with the
number of lists is factored in at each addition. 

The \rdp\ symbol table library
contains a hash function of this type, called \verb+symbol_hash_string+. 
To use it in an \rdp-generated
parser just declare it in the symbol table definition, as above. The two numbers 
101 and 31 in the
definition are the primes that the hash function is to use.

Every record in the symbol table has a key field which is used to access
that record. 
\verb+symbol_compare_string+ is a function which is used by \rdp's symbol
table library to compare an input string with these 
keys when accessing records.

At the end of the symbol table definition, between the {\tt [* *]} brackets,
are the data fields which contain the actual information held for each entry in
the symbol table. The mini symbol table holds 
the identifiers of a mini program, and these all have type {\tt integer}. 
So there are two
data fields; the first holds the lexeme of the token and the other
contains its (integer) value.


\section{Assignment}
The construct
\quad
{\tt ID = e1}
\quad
in the mini grammar is intended to assign the value of the expression
{\tt e1} to the identifier which is the particular lexeme of {\tt ID}.
When an assignment is carried out
the new value is placed in the appropriate field in the symbol table.
This is done by using semantic actions in the rule which
defines identifier declaration.

\begin{verbatim}
statement ::= ID:name '=' e1:val [* mini_cast(
               symbol_lookup_key(mini, &name, NULL))->i = val; *] 
\end{verbatim}
The call to {\tt ID} returns the lexeme which matched that instance of {\tt ID},
and the symbol table is `keyed' on this value. The \rdp\ symbol library function
\verb+symbol_lookup_key()+ looks up the entry in the symbol table
which is keyed on {\tt name}. In this entry, the field {\tt i} holds the value
of the identifier and the semantic action above assigns the value of 
{\tt e1},
returned in a variable called {\tt val}, to the field {\tt i}.

When an identifier is to be assigned the value of another identifier, or
when an expression involves an identifier,
\begin{verbatim}
     fred_copy = fred ;
     total = sub_total + 15;
\end{verbatim}
then the values of these identifiers need to be extracted from the symbol table.
This is also done using \verb+symbol_lookup_key()+.

\begin{verbatim}
e5:integer ::= ID:name [* result =  mini_cast(
                   symbol_lookup_key(mini, &name, NULL))->i; *]
\end{verbatim}
The return type of a function such as \verb+symbol_lookup_key()+
depends in part on the user-defined structure of the entries in the
symbol table, and thus is not fixed. To cope with this
\verb+symbol_lookup_key()+ actually returns a void pointer, which is
then {\em cast} to the appropriate type by a function
{\em table}\verb+_cast()+. This function is constructed automatically by \rdp.
The reader who is not confident in dealing with C-style void pointers
need not worry about it. Just encase calls to functions such as 
\verb+symbol_lookup_key()+ in a call to  {\em table}{\tt\_\,cast()}
and everything will be dealt with automatically.


\section{Identifier declaration}

The construct 
\begin{verbatim}
var_dec   ::= 'int' ID:name [ '=' e1:val ] .
\end{verbatim}
in the mini grammar allows identifiers to be declared. 
The effect of a declaration
is intended to be that an entry in the symbol table is created for that
identifier. There is an option to assign a value to the identifier at
the same time as it is declared. These effects can be achieved using
the symbol table library function \verb+symbol_insert_key()+.

\begin{verbatim}
var_dec   ::= 'int' ID:name [ '=' e1:val ] [* mini_cast(
                symbol_insert_key(mini, &name, sizeof(char*), 
                                    sizeof(mini_data)))->i = val; 
                *].
\end{verbatim}
The function \verb+symbol_insert_key()+ reserves enough space for
both the key which will be used to access the particular entry
and for the actual data which will be stored. These values
depend on the data types specified by the user in their input
grammar. In the case of {\tt mini} we have specified that the
key will be a string (the lexeme recognised by the scanner)
and that the data will contain that string and an integer value.
The size of the key is the third parameter of 
\verb+symbol_lookup_key()+, and the size of the entry is
the fourth parameter. The data fields enclosed between
{\tt [* *]} brackets in a declaration of a symbol table,
{\em table} say, is referred to as {\tt {\em table}\_\,data}
by \rdp. Thus \verb+sizeof(mini_data)+ is the value required
as the fourth parameter in our example.


\section{Using undeclared variables}

The symbol table can be used to resolve context sensitivities.
In {\tt mini} we intend that an identifier cannot be used before it is
declared. However, to exclude something of the form
\begin{quote}
\begin{verbatim}
fred = 3 ;
int fred ;
\end{verbatim}
\end{quote}
from a language usually requires a context sensitive grammar. So instead
we allow such constructs but then issue an error message when an attempt
is made to execute semantic actions on such input.
We use the fact that \verb+symbol_lookup_key()+ returns {\tt NULL}
if it doesn't find a particular entry in the symbol table.

\begin{verbatim}
statement ::= ID:name '=' e1:val
    [* if (symbol_lookup_key(mini, &name, NULL) == NULL)
        text_message(TEXT_ERROR, 
               "Undeclared variable '%s'\n", name);
       else { mini_cast(
               symbol_lookup_key(mini, &name, NULL))->i = val;}
    *] 
\end{verbatim}





\chapter{A mini interpreter}

We are now in a position to give a full decorated grammar,
\verb+mini_itp.bnf+,
for the mini language. Running this grammar through \rdp\
generates a parser which acts as an interpreter for programs
written in the mini language.

{\small
\begin{verbatim}
(**   mini_itp.bnf   **)

USES("mexp_aux.h")

SYMBOL_TABLE(mini 101 31
             symbol_compare_string
             symbol_hash_string
             symbol_print_string
             [* char* id; integer i; *]
            )

program ::= {([var_dec | statement(1) ]) ';' }.

var_dec ::= 'int' ( ID:name [ '=' e1:val ]
             [* mini_cast(symbol_insert_key(mini, &name, sizeof(char*), 
                                           sizeof(mini_data)))->i = val; 
                *]
              )@','.

statement(flag:integer) ::=  
       ID:name '=' e1:val 
       [* if(flag) 
           if (symbol_lookup_key(mini, &name, NULL) == NULL)
             text_message(TEXT_ERROR, "Undeclared variable '%s'\n", name);
           else {
             mini_cast(symbol_lookup_key(mini, &name, NULL))->i = val; }
       *] 

       | 'if' e0:cnd 'then' [* cnd = cnd && flag;*] statement(cnd) 
                     [ 'else' [*cnd =!cnd&&flag;*] statement(cnd) ] 
       | 'print''(' ( e0:val [* if(flag){printf("%i\n", val);};*]
                         | String:str
                              [*if(flag){printf("%s\n", str);};*] 
                        )@',' ')'.

e0:integer ::=  e1:result 
                [  '>' e1:val  [*result = result > val;*]
                 | '<' e1:val  [*result = result < val;*]
                 | '>=' e1:val [*result = result >= val;*]
                 | '<=' e1:val [*result = result <= val;*]
                 | '==' e1:val [*result = result == val;*]
                 | '!=' e1:val [*result = result != val;*]
                ].

e1:integer ::= e2:result {'+' e2:val [* result += val; *]
                           | '-' e2:val [* result -= val; *] } .

e2:integer ::= e3:result 
               {'*' e3:val [* result *= val; *]
                | '/' e3:val [* if(val==0)
                {text_message(TEXT_FATAL,"divide by zero attempted\n");}
                else {result = result / val;}; *] } .

e3:integer ::= '+' e4:result | '-' e4:val [*result = -val;*] | e4:result.

e4:integer ::= e5:result ['^' e4:val 
           [*result = (integer) pow((double) result, (double) val );*] ].

e5:integer ::= ID:name 
          [* if (symbol_lookup_key(mini, &name, NULL) == NULL)
                text_message(TEXT_ERROR, 
                         "Undeclared variable '%s'\n", name);
             else { result = mini_cast(
                         symbol_lookup_key(mini, &name, NULL))->i; }
          *] 
          | INTEGER:result | '(' e1:result ')' .

comment ::= COMMENT_NEST('(*' '*)').   
String:char* ::= STRING_ESC('"' '\\'):result .    
\end{verbatim}

\noindent
If we input the above grammar to \rdp\ 
\begin{verbatim}
       rdp -F examples\rdp_tut\mini_itp
       bcc32 -P -Irdp_supp -c rdparser.c
       bcc32 -erdparser.exe rdparser.obj arg.obj graph.obj memalloc.obj 
                   scan.obj scanner.obj set.obj symbol.obj textio.obj 
       rdparser examples\rdp_tut\mini_itp.str
\end{verbatim}
}
\noindent
running the resultant parser on the input
\begin{verbatim}
(****** mini_itp.str ******)

int fred = 1 ;
print("value of fred = ", fred) ;
int me = fred + 1 ;
print("value of me = ", me) ;
me = fred * me + 6/3*5 ;
print("value of me = ", me) ;
undefined = 4 * me ;
fred = undefined + 4 ;
\end{verbatim}

\noindent
then the following output is printed on the screen.
\begin{verbatim}
value of fred = 
1
value of me = 
2
value of me = 
12
     9: Error (examples\rdp_tut\mini_itp.str) Undeclared variable 'undefined'
    10: Error (examples\rdp_tut\mini_itp.str) Undeclared variable 'undefined'
******: Fatal - errors detected in source file
\end{verbatim}
The parser has evaluated each statement, printing out error
messages when undeclared variables are used -- as specified
in the semantic actions in the grammar.

In this sense the program produced by \rdp\ is an {\em interpreter};
no executable code from the mini input statements remains when the
interpreter has finished running. In the 
associated case study document \cite{rdp:case:1.5} the mini 
grammar is extended
and given different semantic actions so that \rdp\ generates a compiler
from the grammar rather than an interpreter.

\input{rdp_inst.tex}

\bibliographystyle{alpha}
\bibliography{adrian}

\end{document}

