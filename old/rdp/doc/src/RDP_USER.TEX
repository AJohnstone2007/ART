\documentstyle[rhultechreport,epsf,twoside,11pt]{report}
\renewcommand{\today}{December 20, 1997}
\newcommand{\derive}{{\mathop{\Rightarrow}\limits^*}}
\newcommand{\mderive}[1]{{\mathop{\Rightarrow}\limits^{#1}}}
\newcommand{\quietsection}[1]{\subsubsection*{#1}\addcontentsline{toc}{subsection}{#1}}
\newcommand{\errorsection}[1]{\subsubsection*{#1}}
\newcommand{\rdpsupp}{{\mediumseries\tt rdp\_\,supp}}
\newcommand{\rdp}{{\mediumseries\tt rdp}}
\title{\rdp\ -- a recursive descent\\compiler compiler\\[1ex]User 
manual for version 1.5}
\author{Adrian Johnstone \and Elizabeth Scott}
\reportnumber{\csnum{97}{25}} %Uncomment this line only when
\begin{document}
\makecstitle %make Adrian's title page
\thispagestyle{empty}
\vspace*{1cm}
\begin{center}\bf Abstract\end{center}

%%%%%%% modified by EAS 18/8/98 %%%%%%%%%%

\rdp\ is a system for implementing language processors. Compilers,
assemblers and interpreters may all be specified in the \rdp\ source
language (an extended Backus-Naur Form with support for inherited and
synthesized attributes which may be accessed from within C-language
semantic actions). These specifications may then be processed by the
\rdp\ command to produce a program written in ANSI C which can be
compiled by any ANSI standard C compiler. It is possible to use
\rdp\ to write, for example, compilers (by using the  semantic actions to
specify the corresponding target code), interpreters (by using the 
semantic actions to evaluate input fragments) and pretty printers (by 
using the semantic actions to  reformat the input fragments).

This report describes the \rdp\ source language, command switches and
error messages. Serious usage of \rdp-generated parsers requires an
understanding of the support library {\tt rdp\_supp} which is documented
in a companion report~\cite{rdp:supp:1.5}. A third, tutorial, report
assumes no knowledge of parsing, grammars or language design and shows
how to use \rdp\ to develop a small calculator-like
language~\cite{rdp:tut:1.5}. The emphasis in the tutorial guide is on
learning to use the basic \rdp\ features and command line options. A
large case study is documented in~\cite{rdp:case:1.5} which extends the
language described in the tutorial guide with details of a syntax
checker, an interpreter and a compiler along with an assembler and
simulator for a synthetic architecture which is used as the compiler
target machine.

The \rdp\ source code is public domain and has been successfully built
using Borland C++ version 3.1 and Microsoft C++ version 7 on MS-DOS,
Borland C++ version 5.1 on Windows-95, GNU {\tt gcc} and {\tt g++}
running on OSF/1, Ultrix, MS-DOS, Linux and SunOS, and Sun's own {\tt
acc} running on Solaris. Users have also reported straightforward ports to
the Amiga, Macintosh and Archimedes systems.

\vspace*{\fill}
\begin{center}
\fbox{\parbox{12cm}{This document is \copyright\,Adrian Johnstone and Elizabeth Scott 1997.\\[1ex]
Permission is given to freely distribute this document
electronically and on paper. You may not change this document or
incorporate parts of it in other documents: it must be distributed intact.\\[1ex]
The \rdp\ system itself is \copyright\,Adrian Johnstone but may
be freely copied and modified on condition that details of the
modifications are sent to the copyright holder 
with permission to include
such modifications in future versions and to discuss them (with
acknowledgement) in future publications.\\[1ex]
The version of \rdp\ described here is version 1.50 dated 16 August
1997.\\[1ex] 
Please send bug reports and copies of modifications
to the authors at the address on the title page or electronically
to {\tt A.Johnstone@rhbnc.ac.uk}.
}}
\end{center}
\clearpage
\pagenumbering{roman}
\tableofcontents
\listoffigures
\listoftables
\clearpage
\setcounter{page}{0}
\chapter{Introduction}
\pagenumbering{arabic}

\rdp\ is a system for implementing language processors. Compilers,
assemblers and interpreters may all be specified in the \rdp\ source
language (an extended Backus-Naur Form featuring {\em iterators} along
with support for inherited and
synthesized attributes which may be accessed from within C-language
semantic actions). These specifications may then be processed by the
\rdp\ command to produce a program written in ANSI C which can be
compiled by any ANSI standard C compiler. It is possible to use
\rdp\ to write, for example, compilers (by using the  semantic actions to
specify the corresponding target code), interpreters (by using the 
semantic actions to evaluate input fragments) and pretty printers (by 
using the semantic actions to  reformat the input fragments).

This report describes the \rdp\ source language, command switches and
error messages. Serious usage of \rdp-generated parsers requires an
understanding of the support library {\tt rdp\_supp} which is documented
in a companion report~\cite{rdp:supp:1.5}. A third, tutorial, report
assumes no knowledge of parsing, grammars or language design and shows
how to use \rdp\ to develop a small calculator-like
language~\cite{rdp:tut:1.5}. The emphasis in the tutorial guide is on
learning to use the basic \rdp\ features and command line options. A
large case study is documented in~\cite{rdp:case:1.5} which extends the
language described in the tutorial guide with details of a syntax
checker, an interpreter and a compiler along with an assembler and
simulator for a synthetic architecture which is used as the compiler
target machine.

The \rdp\ source code is public domain and has been successfully built
using Borland C++ version 3.1 and Microsoft C++ version 7 on MS-DOS,
Borland C++ version 5.1 on Windows-95, GNU {\tt gcc} and {\tt g++}
running on OSF/1, Ultrix, MS-DOS, Linux and SunOS, and Sun's own {\tt
acc} running on Solaris. Users have also reported straightforward ports to
the Amiga, Macintosh and Archimedes systems.

\section{Specifying languages to \rdp}

Parser generator tools like \rdp\ usually work from specifications
written using variants of the {\em generative grammar} formalism which
was introduced in the 1950's by Chomsky. The formalism was first applied
to the development of programming languages by John Backus and Peter
Naur in the design of Algol-60 and the notation used is
called Backus-Naur Form (or BNF)~\cite{bs60} in commemoration of that pioneering
work. For technical reasons, programming languages and other  synthetic
computer languages rarely use the full power of generative grammars but
instead are based on a restricted kind of generative grammar called a
{\em context free} grammar. 

BNF is sufficient to describe context free grammars, but most real tools
add extensions to the basic notion which might be thought of as
shorthands for commonly occurring BNF idioms. These {\em extended} BNF's
come in several varieties, but the basic idea is to combine the notion
of {\em regular expressions} with the core BNF notation in such a way as
to provide compact ways of specifying repetition within the strings of a
language. This allows language specifications to be smaller, and may
allow the parser generator to easily exploit structure within the rules
so as to improve efficiency.

The particular extended BNF used by \rdp\ is called {\em Iterator
Backus-Naur Form} or IBNF. An iterator is a generalisation of the
kinds of regular expressions found in other forms of extended BNF. 
In addition to supporting the traditional BNF extensions, iterators
allow {\em list-like} structures within languages to be conveniently
specified.

You can find an introduction to the basic notions of generative
grammars, BNF and IBNF in the first chapters of the \rdp\ tutorial
manual~\cite{rdp:tut:1.5}. 
A full description of the capabilities of
IBNF is given below.

\section{Acceptable languages}
\rdp\ generates parsers that work using recursive descent. It
requires grammars to be LL(1) (or something very close to LL(1)), that
is they must be unambiguously parsable using a single token of lookahead
and there must be no left recursive rules.
This is not a significant constraint for modern languages like
Ada, Pascal and C which were to some extent designed with a view
to easy parsing. On the other hand, some languages are just too
difficult\,---\,you should probably forget all about using \rdp\ to
write a FORTRAN parser, for instance.

The main advantages of recursive descent parsing are
\begin{itemize}
\item fast (linear time) parsing,
\item the availability of standardised error recovery mechanisms and
\item the straightforward one-to-one relationship between the code in the
parser and the rules in the grammar specification. This makes it straightforward to
debug the grammar, because a C language debugger may be used to step through
the parser functions and, equivalently, to step through the grammar rules.
\end{itemize}

If the language you present to \rdp\ is not LL(1), \rdp\ issues
detailed diagnostics explaining which tokens and rules are
giving the trouble. It is possible to write algorithms that
translate certain non-LL(1) grammars automatically to LL(1) form,
but \rdp\ does not attempt to perform any such transformations
because that might produce an obscure parser that was no longer
directly related to the input grammar.

\rdp\ is itself a language processor, and the \rdp\ source language has a grammar that is
almost LL(1). In fact \rdp\ is `written in itself'\dash an early version
of the system was hand written and later versions developed from a
grammar description written in \rdp's own source language. This process
(developing new versions of a tool by writing each new version in the
language acceptable to the old version of the tool) is called {\em
bootstrapping} and is a common technique in compiler development.




\section{Support modules}
\rdp-generated parsers use a set of general purpose support
modules collectively known as \verb+rdp_supp+. There are seven parts to
\rdpsupp:
\begin{itemize}
\item a hash coded symbol table handler which allows multiple tables to
be managed with arbitrary user data fields ({\tt symbol.c}),
\item a set handler which supports dynamically resizable sets ({\tt
set.c}),
\item a graph manager which allows arbitrary directed graphs to be
constructed and manipulated, with a facility to output any graph in a
form that may be read and visualised by the VCG~\cite{SANDER95} tool on
Windows and Unix/X-windows systems ({\tt graph.c}),
\item a memory manager which wraps fatal error handling around the
standard ANSI C heap allocation routines ({\tt memalloc.c}),
\item a text handler which provides line buffering and string management
without imposing arbitrary limits on input line length ({\tt textio.c}),
\item a command line argument parsing package that allows Unix style
options to be implemented in a standardised way ({\tt arg.c}),
\item scanner support routines for handling tokens in recursive descent
parsers ({\tt scan.c} and {\tt scanner.c}).
\end{itemize}

Writing effective language processors in \rdp\ requires a detailed
understanding of these modules. The \verb+rdp_supp+
routines are documented in~\cite{rdp:supp:1.5}.

\begin{figure}
{\footnotesize\input{flow.pic}}
\caption{\rdp\ design flow}
\label{flow}
\end{figure}

\section{System flow}
The steps involved in producing a new language processor for a
mythical new language {\tt myth} using the \rdp\ parser generator are
\begin{enumerate}
\item Create a file {\tt myth.bnf} containing an Iterator Backus-Naur
Form (IBNF) specification of the {\tt myth} language. Decorate the
grammar with attributes and C-language fragments describing semantic
actions. By convention, large semantic routines are kept in a file
called the {\em auxiliary} file with a name like \verb+myth_aux.c+.
\item Process {\tt myth.bnf} with \rdp\ to produce {\tt myth.c}, the \rdp-generated parser
for our language {\tt myth}.
\item Compile {\tt myth.c} and \verb+myth_aux.c+ with an ANSI C compiler.
\item Link the {\tt myth} object file with the \verb+rdp_supp+
modules and any other required semantic routines. 
\item Run the resulting executable on {\tt test.mth}, a test
program for the {\tt myth} language.
\end{enumerate}
This process is illustrated in Figure~\ref{flow}.

A complete sequence of commands to generate and build an \rdp\ based
parser using Unix commands might be 
\begin{quote}
\verb+edit myth.bnf       +{\em Create BNF file}\\
\verb+edit myth_aux.c     +{\em Create auxiliary file (optional)}\\
\verb+rdp -omyth myth     +{\em Use \rdp\ to generate the parser}\\
\verb+cc -c myth.c        +{\em Compile the generated C parser}\\
\verb+cc -c myth_aux.c    +{\em Compile the auxiliary file}\\
\verb+cc -omyth myth.o myth_aux.o arg.o graph.o memalloc.o scan.o+\\
\verb+scanner.o set.o symbol.o textio.o  +{\em Link object files}\\
\verb+edit test.mth       +{\em Create a test file contaning a myth program}\\
\verb+myth test.mth       +{\em Run the executable parser on the test file}\\
\end{quote}

The following chapters include reference documentation on \rdp\ command
line parameters, a full description of the \rdp\ iterator BNF source
language, a discussion of the use of derivation trees with the VCG tool,
and a summary of all \rdp\ error messages. Any serious use of \rdp\ will
require familiarity with the support library which is described in a
companion report \cite{rdp:supp:1.5}. Extensive tutorial documentation,
suitable for both novice and expert users, will be found in the tutorial
guide~\cite{rdp:tut:1.5} and in the case study documented in~\cite{rdp:case:1.5}.

\chapter{IBNF\,--\,the \rdp\ source language}
\label{bnf}

This chapter introduces the basic syntax of Iterator Backus-Naur Form
(IBNF) which is the language in which \rdp\ specifications are written.
Figure~\ref{rdp_bnf} shows the syntax of the \rdp\ source language
written in IBNF. An \rdp\ source file is a collection
of rules and directives.  Directives are used to parameterise the
grammar, often by setting default values for command line switches. 
Rules are IBNF grammar rules describing the syntax of the target
language.  Below we describe basic BNF. In the next chapter we describe
the extended forms which are accepted by \rdp. 

\begin{figure}
\footnotesize
\begin{verbatim}
unit ::= { rule | dir}.

dir ::= 'ARG_BOOLEAN' '(' ID ( ID | code ) String ')'  |
        'ARG_NUMERIC' '(' ID ( ID | code ) String ')'  |
        'ARG_STRING'  '(' ID ( ID | code ) String ')'  |
        'ARG_BLANK'   '(' String ')'                |
        'CASE_INSENSITIVE'  |
        'INCLUDE' '(' code ')' |
        'OUTPUT_FILE' '(' String  ')' |
        'MAX_ERRORS' '(' INTEGER  ')' |
        'MAX_WARNINGS' '(' INTEGER  ')' |
        'PARSER' '(' ID  ')' |
        'PASSES' '(' INTEGER  ')' |
        'POST_PARSE' '(' code  ')' |
        'PRE_PARSE' '(' code  ')' |
        'SUFFIX' '(' String  ')' |
        'SHOW_SKIPS'  |
        'SYMBOL_TABLE' '(' ID INTEGER INTEGER ID ID ID code ')' |
        'TITLE' '(' String  ')' |
        'TAB_WIDTH' '(' INTEGER  ')' |
        'TEXT_SIZE' '(' INTEGER  ')' |
        'USES' '(' String ')'.


rule ::= ID ['(' { ID [':' ID {'*'} ] } ')' ] [':' ID {'*'} ] [ '!' ] '::=' prod '.' .

prod ::= ( seq )@'|' . 

seq ::= < (item_ret [':' ID] | item_inl) [ '!' ] > .

item_ret ::= ID '(' { ( INTEGER | REAL | String | ID ) } ')' |
             token  |
	     'CHAR' '(' token ')'  |
	     'CHAR_ESC' '(' token token ')'  |
	     'STRING' '(' token ')'  |
	     'STRING_ESC' '(' token token ')'  |
	     'COMMENT' '(' token token ')'  |
	     'COMMENT_VISIBLE' '(' token token ')'  |
	     'COMMENT_NEST' '(' token token ')'  |
	     'COMMENT_NEST_VISIBLE' '(' token token ')'  |
	     'COMMENT_LINE' '(' token ')'  |
	     'COMMENT_LINE_VISIBLE' '(' token ')'.


item_inl ::= code [ '@' INTEGER  ] |
	     '('prod')' [ '@' [ INTEGER [ '..' INTEGER ] ] ( token | '#' ) ] |
	     '{'prod'}' (* Kleene closure *) |
	     '['prod']' (* Optional *) |
	     '<'prod'>' (* Positive closure *).

token   ::= STRING_ESC('\'' '\\').
String  ::= STRING_ESC('"' '\\').
code    ::= COMMENT_VISIBLE('[*' '*]').
comment ::= COMMENT('(*' '*)').
\end{verbatim}
\caption{\rdp\ syntax}
\label{rdp_bnf}
\end{figure} 

\section{Grammars and BNF} 

It is standard practice to use formal grammars to specify computer
languages. We give  a very brief summary of the notation here. You can
find more detail in the tutorial manual~\cite{rdp:tut:1.5} and in
standard texts on compiler design. 

A grammar consists of a set {\bf N} of {\em non-terminals}, a set  {\bf
T} of {\em tokens}, and a set {$\bf\cal P$} of {\em grammar rules}.
Non-terminals are written as strings which must start with an alphabetic
character or an underscore, and may then continue with alphabetic,
numeric or underscore characters. Tokens are written as singly quoted
strings. 

Each grammar rule is of the form 
\begin{quote}
\verb+rule_name ::=+ {\em rule expression}. 
\end{quote} 
where \verb+rule_name+ is a non-terminal and the {\em rule expression} is a
collection of sequences of grammar symbols. These sequences are called
{\em alternate productions} of the grammar rule. 

For example,
\begin{quote}
\begin{verbatim}
S ::= S '+' S | S '*' S | E .
E ::= 'a' | 'b' .
\end{verbatim}
\end{quote}
is a set of grammar rules which generates a language of sums and
products, for example,
\verb£a+b*a+a£ or \verb£a£.
In this grammar, the non-terminals are {\tt S}, {\tt E}, the terminals are 
{\tt +},{\tt *},{\tt a},{\tt b}, and the start symbol is {\tt S}.

In basic BNF the rule expression
is described by writing out the sequences and separating them using a
vertical bar (\verb+|+). IBNF also allows certain sets of
alternates to be represented using regular expression like structures.
We shall discuss the details of these IBNF expressions
in Chapter~\ref{ibnf}.

We {\em derive} one sequence of grammar symbols
from another by replacing a non-terminal (rule name) with
a sequence from the right hand side of its grammar rule.
For example, given the grammar
\begin{quote}
\verb+start ::= 'a' start | 'b'.+
\end{quote}
we can derive {\tt 'a''b'} from {\tt 'a'start} by replacing 
{\tt start} with {\tt 'b'}. We write 
\begin{quote}
{\tt 'a' start $\mderive{}$ 'a' 'b'}
\end{quote}

We can perform a series of derivations one after the other:
\begin{quote}
{\tt start $\mderive{}$ 'a' start $\mderive{}$ 'a' 'a' start
$\mderive{}$ 'a' 'a' 'b'}
\end{quote}
In this case we write
\begin{quote}
{\tt start $\derive$  'a' 'a' 'b'}.
\end{quote}

The {\em language generated by the grammar} is the set of  sequences of
tokens which can be derived from the start symbol.

In the rest of this chapter and in Chapter~\ref{ibnf} we shall describe
the detailed capabilities of IBNF.

\section{Layout and comments}

The \rdp\ IBNF source language is {\em free-format}, that is
whitespace and newlines can be used anywhere between lexemes to
provide a neat layout. 

It is possible to insert comments into an \rdp\ IBNF source file.
IBNF comments are delimited by \verb+(*   *)+ brackets and may
appear in any position that white space is legal. Comments may be
nested: the maximum nesting level is limited only by available memory.
For example,
\begin{quote}
\begin{verbatim}
S ::= S '+' S | (* Sum *)
      S '*' S | (* Product *)
      E .       (* Constant terms *)

E ::= 'a' | 'b' .
\end{verbatim}
\end{quote}
\section{Identifiers}
Tokens are singly quoted strings
and rule names are identifiers in the \rdp\ source language.
User defined \rdp\ identifiers must start with an alphabetic character or an
underscore (\verb+_+) and can contain only alphanumeric
characters or underscores. In general, \rdp\ identifiers must
obey the rules for ANSI C identifiers. 

Internally, \rdp\ uses many identifiers and it would be catastrophic if a user
defined, say, a rule name that clashed with an internal library
routine's name. To stop this happening \rdp\ reserves several prefixes
which may not be used to start an identifier. The list of reserved prefixes is shown
in Table~\ref{prefixes}: they correspond to the function name prefixes used in the support library.
\begin{table}
\begin{center}
\begin{tabular}{|l|}
\hline
{\tt arg\_}\\
{\tt graph\_}\\
{\tt mem\_}\\
{\tt rdp\_}\\
{\tt scan\_}\\
{\tt set\_}\\
{\tt symbol\_}\\
{\tt text\_}\\
\hline
\end{tabular}
\end{center}
\caption{Reserved identifier prefixes}
\label{prefixes}
\end{table}

As well as checking for reserved prefixes, \rdp\ also checks user
defined identifiers against a list of C keywords and library names to
ensure that clashes do not occur at compile time: defining a production
called {\tt printf} for instance would cause the library {\tt printf()}
routine to become invisible with very confusing results. You can add
names to this list by modifying the definition of
\verb+RDP_RESERVED_WORDS+ in file \verb+rdp_supp/rdp_aux.h+.

\rdp\ itself sets no limit on the length of identifiers subject
to there still being room left in the text buffer, but note that 
many C compilers only recognise the
first 32 characters of an identifier as significant and some
linkers only recognise the first eight characters. In some
contexts \rdp\ can generate identifiers that are extensions of a
user-defined identifier, so it might be wise to keep your identifiers to
less than 20 characters in length.
\rdp\ is case sensitive, so {\tt Adrian} is a
different identifier to {\tt adrian}.

\section{Grammar rule format}
Each grammar
rule must only be defined once, in other words there can only
be one rule for each rule name.  

Any non-terminal in a sequence on the right hand side of a rule must also
appear on the left hand side of some rule, i.e. must be a rule name.
However, forward references are allowed (that is, rule names may
appear on the right hand side of a rule before they appear on the
left hand side). Such forward references are resolved using a two pass parser.

Every rule must terminate with a full stop (period). Neither empty rules
nor empty alternate productions are allowed: there are special
constructions for describing rules that expand to the empty string and
these are described in Chapter~\ref{ibnf}.

\chapter{IBNF extended forms}\label{ibnf}
In this chapter we 
shall describe the full generality of grammar rules which
can be written in \rdp-IBNF (the \rdp\ source language). 

\section{Sequences}
A grammar rule might have a single sequence on its right hand side.
A sequence is simply the concatenation of the
tokens and rule names which make up that sequence:
\begin{quote}
\begin{verbatim}
seq1 ::= seq2 seq2 'z'.
seq2 ::= 'a' 'b' 'c'.
\end{verbatim}
\end{quote}

These two productions define a small language that will be recognised by
the corresponding \rdp-generated parser. The complete language
comprises the following set which contains just one string:

\begin{quote}
$\{$ {\tt abcabcz} $\}$
\end{quote}

\section{Alternate productions}
Alternative sequences on the right hand side of a rule
are written out separated by vertical bars (\verb+|+)
which we call the {\em alternation operator}. Alternation
has lower priority than sequencing, so the rule
\begin{quote}
\verb+rule ::= 'a' 'b' | 'c' 'd' .+
\end{quote}
describes the sequences $\{$\verb+ab, cd+$\}$, {\em not} the sequences
$\{$\verb+abd, acd+$\}$. 

The alternation operator can be used to separate any type of
rule expression. For example, we can write
\begin{quote}
\verb+rule ::= 'a' {rule 'b'} | [ 'c' ].+
\end{quote}
(The constructs {\tt \{\}} and {\tt []} are described below.)

For a grammar to be acceptable to \rdp, no two alternates in the same
rule can generate sequences that begin with the same token. For example,
if 
\begin{quote} 
\begin{verbatim} 
rule_name ::= ... | alternate1 | ... | alternate2 | ...  . 
\end{verbatim} 
\end{quote} 
then we cannot have
\begin{quote} 
{\tt alternate1 $\derive$  'a' string1},\qquad {\tt alternate2 $\derive$  'a' string2} 
\end{quote} 
for any token  {\tt 'a'}. This is because \rdp-generated parsers may only look
one token ahead, and must be able to make a deterministic choice of alternates on this basis.
\rdp\ will issue an LL(1) error if it cannot disambiguate alternate
productions. 

Hence, 
\begin{quote}
\begin{verbatim}
seq1 ::= 'a' 'b' | 'a' 'c'.
\end{verbatim}
\end{quote}
is not legal, but
\begin{quote}
\begin{verbatim}
seq2 ::= 'a' seq3.
seq3 ::=  'b' | 'c'.
\end{verbatim}
\end{quote}
specifies the same language and is acceptable to \rdp.

\section{Recursion}

\rdp\ allows most directly recursive and indirectly recursive rules,
but {\em left recursive} rules of either type generate LL(1)
errors. This is because a left recursive rule will generate a
similarly left recursive set of function calls, which will never
terminate, so
\begin{quote}
\begin{verbatim}
rec1 ::= 'a' rec1 | 'b'.
\end{verbatim}
\end{quote}
is legal, but
\begin{quote}
\begin{verbatim}
rec1 ::= rec1 'a' | 'b'.
\end{verbatim}
\end{quote}
is not.

\section{Do-first}
Parentheses \verb+(...)+ may be used to override the relative
priority of alternation and sequencing, so the language
$\{$\verb+abd+,\ \verb+acd+$\}$ may be described with
\begin{quote}
\verb+a ::= 'a' ('b' | 'c') 'd' .+
\end{quote}
In fact any the contents of any \verb+(+\ldots\verb+)+,
\verb+[+\ldots\verb+]+, \verb+{+\ldots\verb+}+ or
\verb+<+\ldots\verb+>+ bracket pair is evaluated immediately,
that is all bracket pairs have maximum priority.

\section{Zero-or-one occurrences (optional sub-productions)}
Optional parts of a grammar are enclosed in square brackets
\verb+[...]+. The set of tokens that may appear first in 
an optional phrase must not include any tokens that can appear
immediately after an optional phrase.
This is because \rdp-generated parsers may only look one token ahead. If there is a token
that could be both the first in the optional phrase {\em and\/} be the
first token of the phrase after the optional phrase then the
parser will not know which rule to follow. \rdp\ will issue an
error in this case. 

\section{Zero-or-many occurrences (Kleene closure)}
Iteration may be directly represented (without using recursion)
by curly braces \verb+{...}+ which is a shorthand for `zero or many'
occurrences of the iterator body.
The set of tokens that may appear first in a string derived from
the repeat construct
must not include any tokens that can appear
immediately after that repeat construct.
This is because \rdp-generated parsers may only look one token ahead. If there is a token
that could be both the first token in a string derived from 
the repeat construct {\em and} be the
first token of a string derived from the sequence following that 
repeat construct then the
parser will not know which rule to follow. \rdp\ will issue an
error in this case. 

\section{One-or-many occurrences (positive closure)}
Angle brackets \verb+<...>+ form a shorthand for `one or many'
occurrences of the iterator body.
The set of tokens that may appear first in a string derived from
the repeat construct
must not include any tokens that can appear
immediately after that repeat construct.
This is because \rdp-generated parsers may only look one token ahead. If there is a token
that could be both the first token in a string derived from 
the repeat construct {\em and} be the
first token of a string derived from the sequence following that 
repeat construct then the
parser will not know which rule to follow. \rdp\ will issue an
error in this case.


\section{The iterator operator {\tt @}}
\rdp\ provides a generalised iterator operator which subsumes the
standard extended BNF brackets described above. The construction
\begin{quote}
\begin{verbatim}
 ( 'body' ) 2 @ 4 'separator'
\end{verbatim}
\end{quote}
matches the following strings
\begin{quote}
\begin{verbatim}
body separator body 
body separator body separator body 
body separator body separator body separator body
\end{verbatim}
\end{quote}
that is, between two and four instances of {\tt body} separated by the
token  {\tt separator}. The general form of the iterator is 
\begin{quote}
{\tt (} {\em valid subproduction} {\tt )} {\em lo} {\tt @} {\em hi}
{\em token} 
\end{quote}
This specifies that the \rdp-generated parser should match the body
represented by {\em valid subproduction} between {\em lo} and {\em high}
times interspersing each instance with one instance of the separating
{\em token}. A {\em hi} value of zero means `without limit', that is the
iteration will continue arbitrarily.

Either, or both, of {\em hi} and {\em lo} may be absent in which case
they default to zero. The separating {\em token} may be set to the
special token {\tt \#} which means `nothing' or the empty string
(sometimes represented by $\epsilon$). In this case no separating
token is looked for.

The IBNF brackets described in the previous sections are in fact just
shorthands for special cases of the iterator construct. The
correspondences are shown in Table~\ref{iterators}. None of them carries
a separating token, and all of them have lower bounds of zero or one 
and upper bounds of one or zero ({\em without
limit}).
\begin{table}
\begin{center}
\begin{tabular}{lll}
\verb+( ... )+&$\rightarrow$&\verb+( ... ) 1@1 #+\\
\verb+< ... >+&$\rightarrow$&\verb+( ... ) 1@0 #+\\
\verb+[ ... ]+&$\rightarrow$&\verb+( ... ) 0@1 #+\\
\verb+{ ... }+&$\rightarrow$&\verb+( ... ) 0@0 #+\\
\end{tabular}
\end{center}
\caption{Iterator:bracket correspondences}
\label{iterators}
\end{table}

\section{Using iterators to implement lists}
Delimited lists are common in high level languages. Consider, for
instance, a function call in C:
\begin{quote}
\verb+func(param1, param2, param3)+
\end{quote}
In general, parameter lists are comma-delimited lists of identifiers.
If we have an \rdp\ rule {\tt ID} which matches a
C-style identifier,
one way of writing an \rdp\ specification of a function call is:
\begin{quote}
\begin{verbatim}
func_call ::= ID '(' param_list ')'.
param_list ::= [ ID param_tail ].
param_tail ::=  [ ',' ID param_tail ].
\end{verbatim}
\end{quote}

This uses recursion to match an arbitrary number of parameters. We can
use the \verb+{ ... }+ iterator brackets and give a more compact description:
\begin{quote}
\begin{verbatim}
func_call ::= ID '(' param_list ')'.
param_list ::= [ ID {',' ID } ].
\end{verbatim}
\end{quote}
 Here the recursion has been replaced by iteration.

Using the iterator operator with the optional delimiter token we can
further compact this to
\begin{quote}
\begin{verbatim}
func_call ::= ID '(' param_list ')'.
param_list ::= [ (ID) @ ',' ].
\end{verbatim}
\end{quote}
or just
\begin{quote}
\begin{verbatim}
func_call ::= ID '(' [ (ID) @ ',' ] ')'.
\end{verbatim}
\end{quote}

\chapter{Scanner elements}
\label{scanner:elements}
\section{Introduction}
Under the traditional model of compilation parsers operate on the
grammar of a language, and a separate {\em scanner} or {\em lexical analyser}
reads the input characters and groups them into tokens which are then
passed on to the parser for processing.

It is possible to build the scanning phase into the
parser by specifying the language down to character level
in the grammar. In practice this is both tedious and difficult
because the grammar specification required may not satisfy
the LL(1) requirements.
Another traditional role of the scanner is to remove
comments from the input file. It is also possible to
remove comments at parser level
by adding appropriate rules to the grammar,
but this is both tedious and inefficient.

\rdp\ does not use a scanner generator, relying instead on a hard wired
scanner when it reads an IBNF input file. This same hard wired scanner is
automatically attached to the front end of \rdp-generated parsers and
the user can access this scanner by putting certain built in token names
and parser directives into their IBNF grammars. In addition, the inclusion
of the scanner allows the generated parsers to efficiently perform
buffering and error reporting on their source files.

Although the scanner is essentially pre-defined, aspects of it are
paramaterisable, and it can be made to handle the constructs in most
high level languages. For example, it is possible to define a language
in which strings are enclosed in single quotes (Pascal style) and to
define a language in which strings are enclosed in double quotes (C
style). This is because, as we shall see below, the hard wired token
which matches strings takes a parameter which is the string delimiter.

The scanner also has primitives which allow commenting styles to
be specified in a language. These primitives are paramaterisable
to allow, for example, Pascal like comments, which are enclosed in
braces, and C++ like comments, which begin with \verb+//+ and terminate
at the end of the line.

We now give a summary of the types of hard wired tokens available in the
scanner, and the tokens and strings (lexemes) that they match, along with the
family of comment definition primitives.


\begin{itemize}
\item simple character sequences such as \verb+'fred'+ are tokens and
they match the corresponding lexeme or string ({\em fred} in this case),
\item the token \verb+ID+ matches
C-style identifiers such as \verb+adr123+ and \verb+_temp+,
\item the token \verb+INTEGER+ matches
C-style integer literals such as \verb+145+ and \verb+0xFE+ (a
hexadecimal integer), 
\item the token \verb+REAL+ matches
C-style real literals such as  \verb+1.45+, \verb+1.+, \verb+1.45e3+ and
\verb+1.45E-02+,
\item the token \verb+STRING('\'')+ matches
Pascal style strings where two adjacent quotes are
read as a quote mark in the string, as in \verb+'Adrian''s book'+,
\item the token \verb+STRING_ESC('"' '\\')+ matches
C-style strings where as {\em escape character} is used to
introduce quote marks and other special characters into the
string, as in \verb+"\"Good\" she said"+,
\item the token \verb+EOLN+ matches the end of line marker,
\item a variety of comment styles are supported including both nestable and non-nestable
comment brackets along with comments that start with a token and
terminate at the end of line.
\end{itemize}

\quietsection{\mediumseries Keyword tokens}
A keyword token is any character string delimited by single
quotes, such as \verb+'>='+ \verb+'while'+ and \verb-'++'-. 
This token matches just the string itself, so \verb+'while'+
matches the string of letters {\em while}.
Just as in a C string, 
the backslash
character can be used as an escape character so that the token
\fbox{'} is represented as \verb+'\''+.
Empty tokens
(\verb+''+) and tokens containing non-printing characters such as
\verb+'long int'+ and \verb+'bad_code\8'+ are illegal. 

In the following sections we describe hard wired tokens
which can be used in an input grammar for \rdp.
 
\quietsection{{\mediumseries\tt ID} token}
The token {\tt ID} matches any string comprising
an alphabetic character (\verb+a..z+ and
\verb+A..Z+) or an underscore (\verb+_+) followed by any number
of alphabetic, numeric or underscore characters, such as
\verb+temp+, \verb+temp123+ or \verb+_temp_123+.

\quietsection{{\mediumseries\tt INTEGER} token}
The token {\tt INTEGER} matches any valid C-style integer
such as \verb+145+ and \verb+0xFE+ (a
hexadecimal integer). In an extension to standard C-style integers, you may 
insert underscore characters within a numeric literal so as to improve
readability: hence \verb+999_999_999+ is valid. 
The scanner builds a {\tt long unsigned} value from the
digits.

\quietsection{{\mediumseries\tt REAL} token}
The token {\tt REAL} matches any valid C-style real literal, 
such as \verb+1.45+, \verb+1.+, \verb+1.45e3+ and
\verb+1.45E-02+. In an extension to standard C-style integers, you may 
insert underscore characters within a numeric literal so as to improve
readability: hence \verb+999_999.999+ is valid. The scanner builds
a {\tt double} value from the digits.

\quietsection{{\mediumseries\tt STRING({\rm\em\mediumseries open\/})} token}
Simple strings are specified with a single token which marks both
the opening and closing quote. Two consecutive quotes are used to
represent an embedded quote character.

If there exists a rule like
\begin{quote}
\verb+string1 ::= STRING('\'').+
\end{quote}
then the scanner will look for Pascal-style strings delimited by
single quotes, such as \verb+'adrian'+ which returns {\em
adrian} and \verb+'adrian''s book'+ which returns {\em adrian's
book}. Similarly
\begin{quote}
\verb+string2 ::= STRING('|').+
\end{quote}
accepts strings such as \verb+|adrian|+ and \verb+|the symbol || is
used for alternation|+ which returns
{\em the symbol $|$ is used for alternation}.

\quietsection{{\mediumseries\tt STRING\_\,ESC\,({\rm\em\mediumseries open escape\/})} token}
There is no way to directly
represent control characters with a simple {\tt STRING} primitive. 
\rdp\ {\em escaped strings} support
the full range of ANSI standard C escape sequences although 
trigraph sequences are not available. The specification of the
string includes an opening token and the escape token, so that
strings in C can be recognised with

\begin{quote}
\verb+stringc ::= STRING_ESC('"' '\\').+
\end{quote}

Table~\ref{escapes} shows  the special escape sequences. In addition,
any combination \verb+\+$y$, where $y$ is a character not shown in
Table~\ref{escapes}, is replaced by the character $y$\footnote{Note that
in ANSI standard C the result of such an escape sequence is undefined.}.
For octal numbers there must be exactly 1, 2 or 3 digits. For hex
numbers any sequence of valid hexadecimal digits will be accepted
regardless of length. Both upper and lower case hex digits will be
accepted.

\begin{table}
\begin{center}
\begin{tabular}{|ccl|}
\hline
Escape&Replacement&Name\\
sequence&character&\\
\hline
\verb+\a+&BEL&alert\\
\verb+\b+&BS&backspace\\
\verb+\f+&FF&form feed\\
\verb+\n+&NL&newline\\
\verb+\r+&CR&carriage return\\
\verb+\t+&HT&horizontal tab\\
\verb+\v+&VT&vertical tab\\
\verb+\\+&\verb+\+&backslash\\
\verb+\"+&\verb+"+&double quote\\
\verb+\+$ooo$&&character with octal code $ooo$\\
\verb+\x+$hh$&&character with hex code $hh$\\
\hline
\end{tabular}
\end{center}
\caption{\rdp\ character and string escape sequences}
\label{escapes}
\end{table}

\quietsection{{\mediumseries\tt CHAR({\rm\em\mediumseries open\/})} token}
Single characters are specified with one token which marks both
the opening and closing quote. Two consecutive quotes are used to
represent an embedded quote character.

If there exists a rule like
\begin{quote}
\verb+string1 ::= CHAR('\'').+
\end{quote}
then the scanner will look for Pascal-style character literals delimited by
single quotes, such as \verb+'a'+ which returns the single character {\em
a}.

\quietsection{{\mediumseries\tt CHAR\_\,ESC\,({\rm\em\mediumseries open escape\/})} token}
There is no way to directly
represent control characters within a simple {\tt CHAR} primitive. 
\rdp\ {\em escaped character literals} support
the full range of ANSI standard C escape sequences although 
trigraph sequences are not available. The specification of the
literal includes an opening token and the escape token so that, for instance,
C-language character literals can be recognised with

\begin{quote}
\verb+stringc ::= CHAR_ESC('\'' '\\').+
\end{quote}

Table~\ref{escapes} shows 
the special escape sequences. Any combination \verb+\+$y$, where $y$
is a character not shown in Table~\ref{escapes}, is replaced by
the character $y$\footnote{Note that in ANSI standard C the
result of such an escape sequence is undefined.}. For octal
numbers there must be exactly 1, 2 or 3 digits. For hex numbers
any sequence of valid hexadecimal digits will be accepted
regardless of length. Both upper and lower case hex digits will
be accepted.

\quietsection{{\mediumseries\tt EOLN} token}
\verb+EOLN+ matches a newline marker. If
you do not use the \verb+EOLN+ primitive anywhere in your
grammar, then newlines are suppressed and treated as whitespace
by the scanner.

\section{Describing comments to the scanner}
Most programming languages include a commenting facility.
If \rdp\ is to generate a parser for a language
which has a commenting facility then the commenting style required
must be specified in the language grammar.
In this section we shall describe the primitives which allow the
built in scanner which is included in an \rdp-generated parser
to detect and remove comments. However, to motivate the
definitions of these primitives, we first give a brief discussion
on various commenting conventions.


Specifying comments in grammars is a rather tricky area. The usual
practice is to allow comments wherever whitespace is legal in
the language, and to suppress comments in the scanner so
that they are not visible in the phrase level grammar.
If comments are to be visible in the phrase level grammar then
either there must be a call to a comment rule after every
token in the phrase level grammar or else comments must be
restricted to certain contexts. This latter option was tried
early on in the development of free-format languages (for instance
in Algol-60) but was soon found to introduce inconvenient and
unnecessary restrictions on program layout.


There are several varieties of commenting conventions in use. The
most common in block structured languages is to use opening and
closing comment brackets such as 
\verb+{...}+ or the alternate form
\verb+(*...*)+ in Pascal, or \verb+/*...*/+ in C. In both these
languages, comments are not nestable, that is 
\begin{quote}
\begin{verbatim}
/* This is a C comment
   /* with a nested comment inside it */
  which is illegal */
\end{verbatim}
\end{quote}
is illegal in C. The first \verb+*/+ will be taken as closing off
the first \verb+/*+, and the second \verb+*/+ will generate an
error.
However, there are  languages which do allow
nested comments, and some C compilers (such as Borland C++
3.1) allow nested comments to be switched on in C.

A third style of comment specification is to use a token 
to introduce the comment which
terminates at the line end. 
This form is the standard in
non-free format languages such as assemblers and FORTRAN, and has
made a belated comeback in free format languages such as Ada and
C++.
 
There is some dispute as to which style is best, and some
languages offer more than one. The argument for nested comments is that
they allow sections of code to be easily `commented out', that is
removed from a compilation. The argument against is that it  is
easy to overlook a comment bracket and not realise that a block
has actually been commented out. Commenting out by prepending, say,
\verb+--+ to each line as in Ada certainly makes disabled code
stand out and any good editor will allow simple macros to be
written which add and delete comment prefixes to a block of code.

A final complication with comments is that under some
circumstances they need to be visible to the phrase level
grammar. This is particularly so for languages that support {\em
pragmas} which are special comments usually used to switch
compiler features on and off, replicating the functionality of
command line arguments.

\rdp\ provides a family of six comment primitives, which may be
intermixed. If you use more than one comment primitive
then of course they must all have different opening tokens so that the
parser can tell them apart purely on the basis of their opening tokens. The full set is 

\begin{quote}
\hspace*{-2cm}\begin{tabular}{ll}
\tt COMMENT(OPEN CLOSE)&Everything between {\tt OPEN} and
first {\tt CLOSE}.\\
\tt COMMENT\_\,VISIBLE(OPEN CLOSE)&Everything between {\tt OPEN} and
first {\tt CLOSE}.\\
\tt COMMENT\_\,NEST(OPEN CLOSE)&Everything between {\tt OPEN} and
matching {\tt CLOSE}.\\
\tt COMMENT\_\,NEST\_\,VISIBLE(OPEN CLOSE)&Everything between {\tt OPEN} and
matching {\tt CLOSE}.\\
\tt COMMENT\_\,LINE(OPEN)&Everything between {\tt OPEN} and the
line end.\\
\tt COMMENT\_\,LINE\_\,VISIBLE(OPEN)&Everything between {\tt OPEN} and the
line end.\\
\end{tabular}
\end{quote}

The \verb+..._VISIBLE+ primitives return the body of the comment
to the phrase level
grammar and so   may be used for pragmas. The normal primitives discard the
comments in the
scanner, treating them identically to white space.

Comment close tokens can only be a maximum of two characters
long, and conform to the usual token rules, that is empty tokens
and tokens containing white space are not allowed. 

\chapter{Attributes and semantic actions} 

A basic \rdp-generated parser acts as a {\em syntax checker} for the
specified language, which is a useful but rather limited function. By
including embedded {\em semantic actions} within a parser specification
we can force the running parser to execute particular functions as it
recognises portions of the input text string. In general these semantic
actions will need to be able to interact with the parsing process proper. A
calculator, for instance, will need to be able to parse numbers and
operators and then execute the appropriate semantic actions. In detail, the action
to add two numbers  together will need to know not just that a number
has been parsed, but what its value was. This information is transmitted
into semantic actions by using {\em synthesized attributes} which act a
little like the return values of functions in a conventional
programming language.

Occasionally, the semantic actions may need to influence the future
behaviour of the parser, and so \rdp\ also supports the use of {\em
inherited attributes} which act a little like parameters to the rules
that make up a language specification.

This chapter provides a very brief overview of the action and attribute
definition features of \rdp. A much more extensive discussion of the design of
language processors using these features will be found in the \rdp\ tutorial manual
~\cite{rdp:tut:1.5} and example case study~\cite{rdp:case:1.5}.

\section{An introductory example}
\label{attributes}
Here is a very simple example grammar that can be input to \rdp. We shall examine the
runtime behaviour of the parser generated by \rdp\ from this grammar.
\begin{quote}
\begin{verbatim}
start:integer ::= INTEGER:val1 '+' 
                     expr:val2 [* result = val1 + val2; *].
expr:integer  ::= INTEGER:val1 '*' 
                     INTEGER:val2 [* result = val1 * val2; *].
\end{verbatim}
\end{quote}

Imagine that the generated parser is asked to parse the string \verb' 2 +
4 * 5'. As the parse proceeds, the parser calls the functions associated
with each grammar symbol it encounters.  The {\em return type declarations} of the form {\tt
:integer} which appear on the left hand sides of the rules cause the
functions for \verb+start+ and \verb+expr+ to return a value of type {\tt
integer}. The identifier which holds the value to be returned is always
called {\tt result}.

The parser begins by calling the function for the start symbol, {\tt
start}. This then calls the scanner routine for {\tt INTEGER}, which 
will return the value of the integer recognised, in this case
the value 2. The {\em synthesized attribute declaration} {\tt :val1} which appears after
the {\tt INTEGER} scanner directive instructs the parser to write the value returned by the
call to the {\tt INTEGER} scanner primitive into a local variable called {\tt val1}. 

The parser then recognises \verb'+' and then calls the function
corresponding to grammar rule {\tt expr}. This function parses the phrase
\verb+4*5+, writing the values 4 and 5 to the local variables {\tt val1}
and {\tt val2} respectively. The last section of the {\tt expr} routine
then executes the semantic action which is enclosed between \verb+[*+
and \verb+*]+ brackets. The effect of this is to write the value 20 to the
predefined identifier {\tt result}, and this value is then returned as
the {\tt expr} routine is exited. 

The synthesized attribute declaration {\tt :val2} which is appended to
the symbol {\tt expr} in the rule for {\tt start} instructs the parser
to write the returned value from {\tt expr} to the identifier {\tt
val2}, so in this case 20 is assigned to {\tt val2}. The semantic action
at the end of the start rule is then executed so that the final return
value, held in {\tt result}, is 22.

We now give a fuller description of attribute and semantic action
use in \rdp-generated parsers.

\section{Synthesized attribute definition}
Each \rdp\ rule and token can optionally return a single
attribute. A rule that does {\em not} return an attribute
is implemented in the C code for the
generated parser as a {\tt void} function with the
same name as the rule, so 
\begin{quote}
\verb+ simple_rule ::= 'a' 'b'.+
\end{quote}
maps to 
\begin{quote}
\begin{verbatim}
void simple_rule(void) 
{ 
  ... 
}
\end{verbatim}
\end{quote}

If the rule name is followed by a colon and a data type,
then a function returning that type is declared along with a
local variable called {\tt result}, also of the same type as the
function, which is used to hold the return value.

\begin{quote}
\verb+ attributed_rule: integer ::= 'a' 'b'.+
\end{quote}
maps to 
\begin{quote}
\begin{verbatim}
integer attributed_rule(void) 
{ 
  integer result;
  ... 
  return result;
}
\end{verbatim}
\end{quote}

The return value in {\tt result} can be loaded using semantic actions, or
directly from the return value of a rule call: the following are both valid
ways of getting a value into {\tt result}.

\begin{quote}
\begin{verbatim}
rule1: integer ::= INTEGER:value [* result = value; *].
rule2: integer ::= INTEGER:result.
\end{verbatim}
\end{quote}


Note that the data type {\tt integer}  is defined to be a synonym for
{\tt long int} in the parameter file {\tt scan.h} held in the
\rdpsupp\ subdirectory.

The data type can consist of a {\em single} identifier followed
by one or more stars (to indicate indirection). If you need a
rule to return a complex datatype, such as a struct, then
use a {\tt typedef} to define a synonym for it.

Multiple attributes can be returned from a rule by packing
them into a {\tt struct} or {\tt array}. You will need to 
implement the code to do this yourself.

\section{Synthesized attribute types for scanner primitives}
The scanner primitives have built in attribute types which may be
used to retrieve, for instance, the string associated with an
identifier or the numeric value of a {\tt REAL} or {\tt INTEGER}.
The full set of primitives, their return types and return values
is summarised in Table~\ref{scanner:attributes}.

\begin{table}[btp]
\hspace*{-1cm}\begin{tabular}{|l|l|l|}
\hline
Primitive&Return type&Return value\\
\hline
{\tt ID}&{\tt string}&characters making up the identifier\\
{\tt INTEGER}&{\tt unsigned\_integer}&unsigned integer value of literal constant\\
{\tt REAL}&{\tt real}&floating point value of literal constant\\
{\tt STRING}&{\tt string}&characters making up the string\\
{\tt STRING\_ESC}&{\tt string}&characters making up the string\\
{\tt COMMENT\_VISIBLE}&{\tt string}&characters making up the comment\\
{\tt COMMENT\_NEST\_VISIBLE}&{\tt string}&characters making up
the comment nest\\
{\tt COMMENT\_LINE\_VISIBLE}&{\tt string}&characters making up the comment\\
\hline
\end{tabular}
\caption{Scanner primitive attribute types}
\label{scanner:attributes}
\end{table}

\section{Using synthesized attributes}

Synthesized attribute values are created by appending a colon and
a  name to a symbol on the right hand side of a grammar rule. \rdp\
declares a local variable with the same name, and of the type specified
by the return type of the generated parser function for that symbol.
After the generated parser has called the function for a symbol, the
return value is loaded into the local variable, making it available to
subsequent semantic actions. Synthesized attributes cease to exist when
a parser function is exited.

\begin{quote}
\verb+ rule ::= ID:name attributed_rule:value.+
\end{quote}
where \verb+attributed_rule+ has been defined as returning an integer attribute,
maps to 
\begin{quote}
\begin{verbatim}
void rule(void) 
{ 
  string name;
  integer value;
  ... 
}
\end{verbatim}
\end{quote}
\noindent
Values will be loaded into the variables {\tt name} and {\tt
value} after the corresponding phrases have been parsed.

If a rule that returns a result is called without an
attribute name being declared then the result is simply thrown
away.

\section{Inherited attribute definition}
\rdp\ rules can have parameters passed into them. 
Each \rdp\ rule name may be followed by a parenthesised list of
{\tt identifier:type} pairs which are instantiated into the parser
rule as value parameters, so that

\begin{quote}
\verb+ inherited_rule(x:integer y:real):integer ::= 'a' 'b'.+
\end{quote}
maps to 
\begin{quote}
\begin{verbatim}
integer inherited_rule(integer x, real y) 
{ 
  ... 
}
\end{verbatim}
\end{quote}


The most common use of inherited attributes is to pass information into
a rule that will be used to enable semantic actions. In the \rdp\ case 
study~\cite{rdp:case:1.5}, an interpreter for an enhanced version of the
{\tt mini} language is used to illustrate the application of inherited
attributes to the implementation of an {\sc if} \ldots {\sc then} \ldots
{\sc else} statement.

In general, parser rules can both have inherited attributes and
return a single synthesized attribute.

\section{Semantic actions}
C-code fragments may be added to \rdp-generated parsers by enclosing them in
\verb+[*+\ldots\verb+*]+ brackets in the IBNF specification. 
These brackets do not nest,
and no escape sequence is needed. 
The contents of each bracket
pair is simply copied directly to the parser without any
intervening spaces. If for some
reason you want to get the string \verb+something*]else+ into the
output you can write it as 
\begin{quote}
\verb+[*something**] [*]else*]+
\end{quote}


The usual purpose of semantic actions is to manipulate the values
of attributes passed into the rule by other rules
or scanner tokens. 

\section{Error checking of semantic actions}
No syntax checking of code fragments occurs when \rdp\ generates a parser
since
\rdp\ is not itself a C compiler. As a result, any syntactic or
logical errors that you introduce into the generated parser will
not be detected until it is compiled or run. If you have a
problem and are not clear whether it is the semantics or the grammar
that is causing it then try running
\rdp\ with the {\tt -p} option, which suppresses semantic action
insertion, to check whether your grammar correctly parses a
test file.

\section{Default actions for iterators that match the empty string}

An iterator with a lower bound of zero (which of course includes the
\verb+{  }+ and \verb+[  ]+ shorthands) may match against nothing, or to
put it another way the body of the iterator may not be entered. In such cases, it is useful
to be able to specify a semantic action that acts as a {\em default}, that is, an action that
is executed only when the body is not entered. \rdp-IBNF allows such a default action to
be appended to an iterator or bracket with a lower bound of zero by inserting a colon.

Consider the grammar
\begin{quote}
\begin{verbatim}
start ::= 'a' { 'b' } 'c'.
\end{verbatim}
\end{quote}
which generates the language comprising zero or more instances of {\tt b} bracketed by
{\tt a} and {\tt c}. The following grammar prints out a message when presented with
the input string {\tt ac}.
\begin{quote}
\begin{verbatim}
start ::= 'a' { 'b' }:[* printf("No b's in string"); *] 'c'.
\end{verbatim}
\end{quote}

The construct \verb+{  }:[* +{\em default action}\verb+ *]+ defines a default action that
is only executed when the body of the iterator is not entered, i.e. the \verb+{  }+ brackets
are matched against the empty string $\epsilon$.

Defaults can also be attached to full iterators as in:
\begin{quote}
\begin{verbatim}
start ::= ID 0@8 ',':[* printf("No identifiers seen"); *] .
\end{verbatim}
\end{quote}

\section{Semantic rules}
\label{semantic:rules}
Semantic actions are often quite large pieces of code, and they
can obscure the flow of the grammar by overwhelming the IBNF. In
addition, it is confusing to read a single specification that
contains code operating on different levels\dash in this case the high level
IBNF and the low level C syntax.

\rdp\ allows you to parcel up large semantic actions into
rules of their own, whose right hand sides contain only semantic actions,
which are inserted {\em inline} into the
appropriate function in the generated parser. This allows
semantic actions to be described away from the actual
instantiation point with no loss of efficiency.

A {\em semantic
rule} is a special form of grammar rule that contains only 
semantic actions. 

Consider this grammar fragment:
\begin{quote}
{\footnotesize
\hspace*{-2cm}
\begin{verbatim}
statement ::= ID:name '=' e1:value 
                [* symbol_lookup_id(name)->data.i = value; *] |
              'print' '(' ( e1:value [* printf("%i",value); *] |
                            string:str [* printf("%s", str+1); *]
                          )@','
                      ')'.
                   
\end{verbatim}
}
\end{quote}
Using semantic rules this may be reworked as
\begin{quote}
{\footnotesize
\hspace*{-3cm}
\begin{verbatim}
statement ::= ID:name '=' e1:value _1 | 
              'print' '(' ( e1:value _2 | string:str _3 )@',' ')'.

_1 ::= [* symbol_lookup_id(name)->data.i = value; *].
_2 ::= [* printf("%i",value); *].
_3 ::= [* printf("%s", str+1); *].
\end{verbatim}
}
\end{quote}
The version incorporating the semantic rules splits the semantics out from the syntax 
definition making the grammar rather more readable.

\section{Semantic actions in multi-pass parsers}

By default, \rdp-generated parsers make a single pass over the input
text, executing semantic actions on the fly. Many programming languages
are designed to be parsed in this way: in C and Pascal for instance
identifiers must be declared before use to allow single
pass translation.

Some translation tasks are hard to accomplish in a single pass. \rdp\
itself, for instance, is a translator for a language that does {\em not}
require identifiers to be declared before use. In fact \rdp\ makes two
passes over a {\tt .bnf} file: on the first pass all of the rule names
are collected together and any rules that have been declared more than
once are reported. On the second pass any references to undeclared rules
can be detected. Other examples of translators that typically use more
than one pass are assemblers and other low level languages that allow
identifiers to be defined and used in arbitrary order.

\rdp\ allows multiple pass parsers to be created easily. If a {\tt
PASSES({\em n})} declaration is inserted into a {\tt .bnf} file then
\rdp\ will make {\em n} passes over the text (see section~\ref{passes}).
Usually, semantic actions in multi-pass translators are designed to be
executed on particular passes. Within a multi-pass parser, the global
variable \verb+rdp_pass+ holds the current pass number (see
section~\ref{rdp:pass}) which may be used to filter actions. A semantic
action such as
\begin{quote}
\hspace*{-1cm}\verb+[* if (rdp_pass == 2) printf("Executing actions on second pass"); *]+
\end{quote}
will only generate output on pass two. It would be tiresome to have to
insert these kinds of {\tt if} statements into every semantic action of
a multi-pass parser, so \rdp\ allows specification of the pass on which an action is to
be executed. This semantic action is equivalent to the previous one:
\begin{quote}
\verb+[* printf("Executing actions on second pass"); *]@2+
\end{quote}
By appending an expression of the form {\tt @{\em n}} to an action then
it is restricted to execution on pass {\em n}. \rdp\ implements
selective execution by simply wrapping the appropriate {\tt if}
statement around the action. An action without a trailing {\tt @}
expression will be executed on all passes.

\chapter{Directives}

\rdp\ directives are used to parameterise the parser: for instance most
of the standard command line switches have default values which can be
set up using directives. Other features controlled by directives include
the instantiation of symbol tables in the generated parser with the
\verb+SYMBOL_TABLE+ directive and the definition of new command line
switches which can be added using the \verb+ARG_...+ family of
directives.  In addition, some global values such as the case
sensitivity of the target language  can be initialised using 
directives.

\section{Flow control directives}
\label{passes}
\quietsection{{\mediumseries\tt INCLUDE("}{\rm\em\mediumseries filename\/}{\mediumseries\tt")}}

IBNF descriptions can span several files. The {\tt INCLUDE} directive
pulls in another {\tt .bnf} file in exactly the same way as the
\verb+#include+ preprocessor command in C. Included files can be nested
to arbitrary depth: the only limit is the amount of available memory
available to hold the list of nested file descriptor blocks. 

\section{Parser setup directives}

\quietsection{{\mediumseries\tt USES("}{\rm\em\mediumseries filename\/}{\mediumseries\tt")}}

All \rdp-generated parsers automatically include the header files for
the scanner, text handler, memory manager, argument handler, graph
handler, symbol table and set handling modules. Any user header files
(such as the \verb+ myth_aux.h+ file from the example in
Figure~\ref{flow}) can be specified using this directive. Multiple {\tt
USES} directives may be issued, one for each included file, to generate a
sequence of \verb+#include+ preprocessor directives in the C parser
source file. The \verb+#include+ directives will appear in the same
order as they are declared in the IBNF source file and will be followed
with \verb+#include"+{\em filename}\verb+.h"+ where {\em
filename} is the name of the C parser header file. Token names for the
grammar and symbol table data structures are defined in this header
file. 

\quietsection{{\mediumseries\tt TITLE("}{\rm\em\mediumseries string\/}{\mediumseries\tt")}}

The title of the generated parser, as reported in verbose mode and at
the top of the help message is set using this directive.  If no {\tt
TITLE} directive  appears in an IBNF description then the default title
of {\tt rdparser} will be used.

\quietsection{{\mediumseries\tt SUFFIX("}{\rm\em\mediumseries string\/}{\mediumseries\tt")}}

The default filetype for the generated parser is set using the {\tt
SUFFIX} directive. \rdp\ automatically appends a period (.) and the
suffix to any source file name that is specified without a filetype. The
{\em string\/} argument specified to the {\tt SUFFIX} directive should not contain
the leading period.

If no {\tt SUFFIX} directive appears in an IBNF description then
filetype processing is disabled and the user filename will be used
literally.

\quietsection{\mediumseries\tt PARSER({\rm\em\mediumseries start})}
The parser start rule is declared using this directive. If no {\tt PARSER}
directive appears in the grammar then the first rule encountered
is taken to be the start rule.

\quietsection{{\mediumseries\tt PRE\_\,PARSE([*}{\rm\em\mediumseries~action~}{\mediumseries\tt *])}}

The \rdp-generated parser \verb+main()+ function checks command line
arguments, initialises various subsystems and then makes a call to the
parser function corresponding to the first IBNF rule found. If a {\tt
PRE\_\,PARSE} directive is found in the IBNF description then the C
language {\em action} is copied into the \verb+main()+ function
immediately before the call to the parser.

\quietsection{{\mediumseries\tt POST\_\,PARSE([*}{\rm\em\mediumseries~action~}{\mediumseries\tt *])}}

The \rdp-generated parser \verb+main()+ function checks command line
arguments, initialises various subsystems and then makes a call to the
parser function corresponding to the first IBNF rule found. If a {\tt
POST\_\,PARSE} directive is found in the IBNF description then the C
language {\em action} is copied into the \verb+main()+ function
immediately after the call to the parser.

\quietsection{{\mediumseries\tt OUTPUT\_\,FILE("}{\rm\em\mediumseries file\/}{\mediumseries\tt")}}

The default value of the output filename for the generated parser is set
using {\tt OUTPUT\_\,FILE}. It can be overridden on the command line
with a {\tt -o} directive. If no {\tt OUTPUT\_\,FILE} directive appears
in the grammar then a default output name of {\tt rdparser} is used.

\quietsection{{\mediumseries\tt PASSES(}{\rm\em\mediumseries count}{\mediumseries\tt)}}

Normally the \rdp-generated parser contains a {\tt main()} function that simply
calls the function corresponding to the first IBNF rule,
and then returns control to the user. For some applications, such as
assemblers, it is convenient to have the parser called multiple
times. If a {\tt PASSES} directive is encountered then the parser
call is wrapped in a {\tt for} loop causing the parser to be
called {\em count} times. The internal variable \verb+rdp_pass+
may be referenced in semantic actions to check which pass is
currently executing.

Note that the \verb+POST_PARSE+ routine is not called until all passes
are complete, and that any listing requested by a {\tt -l} command line
option is not generated until the last pass.

\quietsection{{\mediumseries\tt SYMBOL\_\,TABLE(}{\rm\em\mediumseries
name size prime compare hash print}
{\mediumseries\tt[*}{\rm\em\mediumseries~data~}{\mediumseries\tt *])}}
\label{symbol:table}

\rdp-generated parsers make use of the hash coded symbol table package
{\tt symbol} which is described in~\cite{rdp:supp:1.5}. Each symbol
table takes
\begin{itemize}
\item a {\em name} which must be a valid C identifier,
\item an integer {\em size} which is the number of hash buckets to
allocate,
\item an integer {\em prime} which would ideally be a large prime number
less than {\em size},
\item the name of a {\em compare} function,
\item the name of a {\em hash} function,
\item the name of a {\em print} function,
\item a list of data fields.
\end{itemize}

{\em name} can be any identifier not used elsewhere in the grammar.
The {\em size} of the table should be set to about 30--50\% of the
expected number of symbols to be placed in the table. The table will
work correctly even if {\em size} is very small compared to the
number of symbols but performance will suffer. {\em prime} must be
coprime ({\em i.e.} not sharing any common factors greater than 1) with
{\em size} for the standard hashing functions to work well.

{\em compare}, {\em hash} and {\em print} are pointers to
functions that understand the layout of the user data. If your user data
consists of a pointer to a string and a set of other fields, and if that
string is the symbol table key (a common situation) then the standard
routines supplied as part of the {\tt symbol} package may be used.

The {\em data} fields are a list of semicolon delimited data declarations which
are copied into the body of a {\tt struct} by \rdp.

For simple tables that are keyed on a string the following directive
works well:
\begin{quote}
\begin{verbatim}
SYMBOL_TABLE(mytable 101 31
             symbol_compare_string
             symbol_hash_string
             symbol_print_string
             [* char* id; integer i; *]
            )
\end{verbatim}
\end{quote}

For each \verb+SYMBOL_TABLE+ directive, \rdp\ creates global variable
{\em name} which points to the table and then initialises it by calling
\verb+symbol_new_table()+ before beginning the parse. In the header
file, \rdp\ also creates a data structure from the {\em data} fields and
uses a {\tt typedef} to create a name of the form {\em
name}\verb+_data+ by which it may be called. Finally, a cast macro
called {\em name}\verb+_cast+ is defined.

\section{Command line argument definition directives}

\rdp\ builds ready-to-run parsers that include an automatically
generated help facility: if a user mistypes a command line when trying
to run an \rdp-generated parser then a fatal error message will be
issued which includes a condensed guide to the command line switches
supported by the parser. By default, \rdp-generated parsers support the
command line arguments shown in Table~\ref{standard}. Extra command line
arguments may be added using a family of four directives. They map onto the
library functions declared in \verb+rdp_supp\arg.c+ which are described in
the support library manual~\cite{rdp:supp:1.5}. The \rdp\ source file {\tt rdp.bnf}
provides a large example of the use of command line argument definitions.

\quietsection{{\mediumseries\tt ARG\_\,BOOLEAN(}{\rm\em\mediumseries key identifier key\_\,string}{\mediumseries\tt)}}

Add a boolean command line argument. {\em key} should be a single alphabetic character.
{\em identifier} is the name of a variable that will be automatically declared in the
generated parser and initialised to zero. {\em key\,\_string} is a descriptive string that will
be reproduced if the help message is displayed.

For example, this declaration
\begin{quote}
\begin{verbatim}
ARG_BOOLEAN(X x_flag "Set X flag")
\end{verbatim}
\end{quote}
will add a {\tt -X} command line argument and insert a variable called
\verb+x_flag+ into the parser. The \verb+x_flag+ variable will be
initialised to {\sc false} (zero), and then each instance of  {\tt -X}
will invert the flag: hence a parse invocation of the form
{\tt rdparser -X myfile} will cause \verb+x_flag+
to be set to {\sc true} (1).


\quietsection{{\mediumseries\tt ARG\_\,NUMERIC(}{\rm\em\mediumseries key identifier key\_\,string}{\mediumseries\tt)}}

Add a numeric command line argument. {\em key} should be a single
alphabetic character. {\em identifier} is the name of a variable that
will be automatically declared in the generated parser and initialised
to zero. {\em key\,\_string} is a descriptive string that will be
reproduced if the help message is displayed.

For example, this declaration
\begin{quote}
\begin{verbatim}
ARG_NUMERIC(N n_value "Set value of n")
\end{verbatim}
\end{quote}
will add a {\tt -N} command line argument and insert a variable called
\verb+n_value+ into the parser. The \verb+n_value+ variable will be
initialised to zero and then a parser invocation of the form
{\tt rdparser -N25 myfile} will cause \verb+n_value+
to be set to the value of the numeric parameter (25 in this case).

\quietsection{{\mediumseries\tt ARG\_\,STRING(}{\rm\em\mediumseries key identifier key\_\,string}{\mediumseries\tt)}}

Add a string command line argument. {\em key} should be a single
alphabetic character. {\em identifier} is the name of a variable that
will be automatically declared in the generated parser and initialised
to the empty string (\verb+""+). {\em key\,\_string} is a descriptive
string that will be reproduced if the help message is displayed.

For example, this declaration
\begin{quote}
\begin{verbatim}
ARG_STRING(S s_value "Set value of s")
\end{verbatim}
\end{quote}
will add a {\tt -S} command line argument and insert a variable called
\verb+s_value+ into the parser. The \verb+s_value+ variable will be
initialised to zero and then a parser invocation of the form as
{\tt rdparser -Sstring myfile} will cause \verb+s_value+
to be set to the value of the string parameter (\verb+string+ in this case).

\quietsection{{\mediumseries\tt ARG\_\,BLANK(}{\rm\em\mediumseries key\_\,string}{\mediumseries\tt)}}

Add a {\em blank} argument. No actual command line switch is instantiated: this declaration
is used to add a line to the help message.
{\em key\,\_string} is a descriptive string that will be
reproduced if the help message is displayed.


\section{Command line default directives}
\quietsection{{\mediumseries\tt TAB\_\,WIDTH(}{\rm\em\mediumseries count}{\mediumseries\tt)}}
This directive sets the default number of spaces to expand tabs to
when producing listings. If no \verb+TAB_WIDTH+ directive appears
in the IBNF source then 8 is assumed. It may be over-ridden with
the {\tt -t} command line directive.

\quietsection{{\mediumseries\tt TEXT\_\,SIZE(}{\rm\em\mediumseries count}{\mediumseries\tt)}}

This directive sets the default size of the scanner's text buffer in
bytes. If no \verb+TEXT_SIZE+ directive appears in the IBNF source then
20,000 is assumed. It may be overridden with the {\tt -T} command line
directive. 

Note that your operating system and compiler may impose their own limits
on the size of the buffer: for instance MS-DOS 16-bit compilers often
limit the size of a single heap object to 64K bytes, which acts as an
effective limit to the size of the text buffer. \rdp\ will exit with a
fatal memory allocation error if you exceed the operating system limit.
You can usually get a good idea of the limitations of your system by
looking at the definition of the ANSI C datatype \verb+size_t+ which is
used to represent the size of memory objects. If, as in Borland C++
version 3.1, \verb+size_t+ is a 16 bit number then the 64K limit
applies.

\quietsection{{\mediumseries\tt MAX\_\,ERRORS(}{\rm\em\mediumseries count}{\mediumseries\tt)}}

This directive sets the maximum number of errors that will be reported
before parsing is aborted. If no \verb+MAX_ERRORS+ directive appears in
the IBNF source then 25 is assumed.

\quietsection{{\mediumseries\tt MAX\_\,WARNINGS(}{\rm\em\mediumseries count}{\mediumseries\tt)}}

This directive sets the maximum number of warnings that will be reported
before parsing is aborted. If no \verb+MAX_WARNINGS+ directive appears
in the IBNF source then 100 is assumed.

\section{Scanner directives}

\quietsection{\mediumseries\tt CASE\_\,INSENSITIVE}

By default, \rdp-generated parsers are case sensitive. For languages
such as Pascal which are case insensitive, the scanner may be set by a
\verb+CASE_INSENSITIVE+ directive so as to force all characters outside
of strings and comments, including tokens and identifiers, 
to be lower case. Since conversion is from upper
to lower case, tokens in the IBNF description of a case insensitive
language should be written in lower case. The file {\tt pascal.bnf} supplied in
the standard \rdp\ distribution provides an example of the use of this directive.

\quietsection{\mediumseries\tt SHOW\_\,SKIPS}

After detecting an error, \rdp-generated parsers consume input until a
token that might reasonably be used to restart the parse is found. This
process is known as {\em skipping}, and if a \verb+SHOW_SKIPS+ directive
appears in the IBNF description then an extra warning message is enabled
that marks the end of the skipped passage. This is useful when debugging
error handling.

\section{Tree generation directives}

For completeness, this section summarises the directives that enable
automatic tree generation. For fuller documentation, please refer to
Chapter~\ref{tree}.

\quietsection{{\mediumseries\tt TREE([*}{\rm\em\mediumseries~data~}{\mediumseries\tt *]})} Switch on tree generation and (optionally)
define extra data fields to be added to each tree node. The trees will
have epsilon nodes deleted: leaf nodes containing epsilon are simply
removed and internal epsilon nodes are removed with their children being
promoted to be at the same level as the internal epsilon node was at
before pruning. Fuller documentation on tree generation will be found in Chapter~\ref{tree}.

\quietsection{{\mediumseries\tt EPSILON\_\,TREE([*}{\rm\em\mediumseries~data~}{\mediumseries\tt *]})} Switch on tree generation and (optionally)
define extra data fields to be added to each tree node. Epsilon nodes
will be left in the tree. Fuller documentation on tree generation will be found in Chapter~\ref{tree}.

\quietsection{{\mediumseries\tt ANNOTATED\_\,EPSILON\_\,TREE([*}{\rm\em\mediumseries~data~}{\mediumseries\tt *]})} Switch on tree
generation and (optionally) define extra data fields to be added to each
tree node. Epsilon nodes will be left in the tree as with the {\tt
EPSILON\_\,TREE} directive but each such node will be annotated with the
string {\tt \#:{\em name}} where {\em name} is the name of the subrule
that generated the epsilon. Fuller documentation on tree generation will be found in Chapter~\ref{tree}.

\chapter{Running \rdp}

This chapter describes the \rdp\ command line options.  
\rdp\ reads a single IBNF source file (of default filetype \verb+.bnf+)
and writes out a header file and a parser file. If no output filename is
supplied then the files are written to {\tt rdparser.h} and {\tt
rdparser.c} respectively.

The \rdp\ command accepts parameters which can either be {\em option
switches} which are denoted by a leading minus sign (\verb+-+) followed
by a letter, or {\em filename arguments} which are anything else.
Options and filenames can be intermixed: it is not necessary to place
the filename after the options. \rdp\ expects a single
filename\,---\,if you issue multiple filenames then only the leftmost one
will be used.

All \rdp\ options are processed in strict left to right order. This is
significant because some options can override the actions of other
options: in such cases the rightmost instance of an option will override
any earlier ones.

\section{\rdp\ filename parameters}

Any \rdp\ parameter that does not consist of minus sign (\verb+-+)
followed by a non-whitespace character will be taken as a filename. 

The \rdp\ scanner attempts to add a default filetype to the filename you
specify. It starts at the rightmost character, and looks backwards for a
period (\verb+.+). If it encounters one {\em before} it finds the start
of the filename or an instance of either the Unix or MS-DOS directory
separators (\verb+/+ and \verb+\+) then it assumes that you have
supplied your own filetype and leaves the filename untouched. If it does
not find a period then it appends \verb+.bnf+ to your filename.

\section{\rdp\ option parameters}

\quietsection{{\mediumseries\tt -e} write out expanded IBNF} This option
enables an extended listing mode that causes \rdp\ to render all of its
internal and external rules as human readable BNF, as well as
enumerating the first and follow sets for each rule, and giving a count
of the number of times the rule is called in the grammar, that is the
number of times a particular rule names appears on the right hand side
of rules.

An internal rule (or {\em subrule}) is the expansion of 
one of the \rdp\ extended rule types that are described in Chapter~\ref{ibnf}: the
\verb+(+\ldots\verb+)+, \verb+[+\ldots\verb+]+, \verb+{+\ldots\verb+}+
or \verb+<+\ldots\verb+>+ bracket pairs or the expansion of an iterator
operator {\tt @}.
Each internal rule inherits its parent rule's name
with the string {\tt rdp\_} prepended and the string \verb+_+$n$
appended, where $n$ is a unique integer. 

This option usually generates a lot of output, but can be very
educational when analysing first and follow sets for simple languages.

\quietsection{{\mediumseries\tt -E} add rule name to error messages}

When debugging a grammar it is sometimes helpful to know which rule was
being processed when an error occurred. If you regenerate the parser
using \rdp\ and add the {\tt -E} flag to the \rdp\ command line, then
the message {\tt In rule '{\em name}'} is prepended to all syntax errors
displayed by the generated parser where {\em name} is the name of the active rule
at the time the error was found.

\quietsection{{\mediumseries\tt -f} filter mode}

In filter mode, input is read from the standard input and written to the
standard output. The {\tt -f} option sets the input to {\tt stdin}
(either the keyboard, or the output of a previous operation within a
pipe) and the output to {\tt stdout}, but subsequent {\tt -o} options or
filenames can be used to override this. Similarly, this option overrides
any previous {\tt -o} option. 

\quietsection{{\mediumseries\tt -F} force creation of output files}

Any ambiguities or left recursion in the supplied grammar will cause \rdp\ to report
LL(1) error messages, and inhibit production of the output files. Most
real languages have at least one ambiguity (the {\sc if \ldots\ then
\ldots\ else} problem) and several others (such as C) have ambiguities
based on the use of identifiers in different contexts. Careful design of
the source grammar can result in correctly working parsers even in the
face of these ambiguities because \rdp\ will accept the first matching
production alternate in a rule, in which case the {\tt -F} option can be
used to force \rdp\ to produce its output files.

\quietsection{{\mediumseries\tt -l} make a listing}

Usually, only lines containing syntax errors are echoed to the screen
whilst an \rdp-generated parser is running. When a {\tt -l} option is
issued each line of the source file is echoed to the message stream as
it is read. Usually the message stream is the standard error stream, but
you can change this by altering the macro \verb+TEXT_MESSAGES+ which is
defined in {\tt textio.h} and recompiling the whole system. It is also
possible to change the message stream at run time using the
\verb+text_redirect()+ routine: see the support
manual~\cite{rdp:supp:1.5} for more information.

\quietsection{{\mediumseries\tt -ofilename} write output to filename}
By default \rdp\ creates output files {\tt rdparser.h} and {\tt
rdparser.c}. When a {\tt -o} option is issued, the characters
immediately following the {\tt o} up to the next whitespace
character are taken as the filename. Any filetype is stripped
off, and the remaining characters are used as a filename body. 

\quietsection{{\mediumseries\tt -p} make parser only}
It is often useful to be able to disable semantic actions and
produce a pure parser so as to debug the grammar without
interference from embedded C semantic actions. The {\tt -p} option causes
\rdp\ to suppress the writing of semantic actions into the parser
source code which may then be compiled into a pure syntax checker.

\quietsection{{\mediumseries\tt -R} add rule entry and exit messages}
When debugging a grammar it is useful to be able to get a trace of the parser's
execution path. One way to do this is to add semantic actions to each rule which
print out a message on entry to the rule and on exit. It would be
tedious to do this by hand: the {\tt -R} option instructs \rdp\ to
automatically add these messages for all rules. This option can cause
generated parsers to produce voluminous output.

\quietsection{{\mediumseries\tt -s} echo each scanner symbol as it is read}
When debugging scanners it can be very helpful to
get a diagnostic dump of each lexeme as it is passed to the
parser. This option produces one line of output {\em per} lexeme and is
only recommended for detailed debugging since it generates a lot of output.

\quietsection{{\mediumseries\tt -S} print summary symbol table statistics}
\rdp-generated parsers use hash coded symbol tables that are declared in the IBNF source file. 
The number of hash buckets in each table is specified by the user in the grammar
and should be kept large enough to keep the number of entries per
bucket below about four or five for efficient parsing. The {\tt -S}
option prints out a histogram of bucket utilisation frequencies and the
mean bucket utilisation figure for each declared table. Note that the
scanner uses one table internally to hold the keywords from the IBNF
specification, and statistics for that table are printed too. If the
tables are becoming congested then increase the size in the
corresponding \verb+SYMBOL_TABLE()+ directive (see
section~\ref{symbol:table}) and regenerate.

\quietsection{{\mediumseries\tt -tn} tab expansion width}
When echoing lines read in by the scanner it is important that
tabs are correctly expanded or the user's formatting may be lost.
\rdp\ supports fixed tab stops every $n$ characters where $n$
defaults to 8, but may be set to some other value with a {\tt -t}
option.
 
\quietsection{{\mediumseries\tt -Tn} text buffer size in bytes for scanner}
The \rdp\ scanner allocates a fixed text area at initialisation
time. The text buffer is used efficiently, but will eventually
fill up when parsing long files. The {\tt -T} option may be
used to override the default text buffer size for the running parser.

Note that your operating system and compiler may impose their own limits
on the size of the buffer: for instance MS-DOS 16-bit compilers often
limit the size of a single heap object to 64K bytes, which acts as an
effective limit to the size of the text buffer. \rdp\ will exit with a
fatal memory allocation error if you exceed the operating system limit.
You can usually get a good idea of the limitations of your system by
looking at the definition of the ANSI C datatype \verb+size_t+ which is
used to represent the size of memory objects. If, as in Borland C++
version 3.1, \verb+size_t+ is a 16 bit number then the 64K limit
applies.

\begin{table}[t]
\begin{center}
\begin{tabular}{ll}
\verb+-f+&Filter mode\\
\verb+-l+&Make a listing\\
\verb+-ofilename+&Write output to {\tt filename}\\
\verb+-s+&Echo scanner symbols\\
\verb+-S+&Print symbol statistics\\
\verb+-tn+&Tab expansion width\\
\verb+-Tn+&Text buffer size\\
\verb+-v+&Set verbose mode\\
\verb+-Vfilename+&Write derivation tree to {\tt filename} in VCG format\\
\end{tabular}
\end{center}
\caption{Standard command line options}
\label{standard}
\end{table}


\quietsection{{\mediumseries\tt -v} set verbose mode}

In verbose mode \rdp\ issues a running commentary on its progress,
reporting all stages of the grammar checking process. All \rdp-generated
 parsers also report CPU time usage in verbose mode. The value of the
verbose flag (o if it is absent on the command line and 1 if it is
present) is held in global variable \verb+rdp_verbose+ which may be
examined from within semantic actions. This feature can be used to
provide extra output from generated parsers in verbose mode.


\quietsection{{\mediumseries\tt -V} dump derivation tree in VCG format}

\rdp-generated parsers built from specifications that include one of the
three {\tt TREE} directives automatically build derivation trees using
the graph manipulation support library. These trees can be output in a
textual form that is suitable for reading into the VCG compiler graph
visualisation tool~\cite{SANDER95}. Activation of this option causes the
tree to be dumped out at the end of the final parser pass. Further
details on tree construction and manipulation will be found in
Chapter~\ref{tree}.

\section{Options understood by \rdp-generated parsers}

All \rdp-generated parsers automatically include all of the option flags
listed in Table~\ref{standard}. In addition, extra options can be specified
in the grammar using the {\tt ARG} directives described in the previous
chapter.

\chapter{\rdp\ global variables}

\section{Monitoring parser status at runtime}
\label{rdp:pass}
Each \rdp-generated parser has a set of global variable definitions written into
it that are initialised before the parser start rule is called. Semantic
actions in the parser file can access these variables. 

\quietsection{\tt rdp\_\,error\_\,return}

The contents of this variable supply an error return status to the
operating system on normal completion. By default it is set to zero but
semantic actions may set it to any value. A fatal error always returns a
fatal status to the operating system regardless of the contents of this variable.

\quietsection{\tt rdp\_\,outputfilename}

The value of the {\tt -o} output file command line switch, or \verb+"-"+
if a {\tt -f} argument was last seen. 

\quietsection{\tt rdp\_\,pass}

The current pass number. Passes are numbered 1
to $n$ where $n$ is the number defined in the {\tt PASSES()} directive.
Pass expressions of the form \verb+@+$n$ may be appended to semantic
actions to control which pass they are executed on.

\quietsection{\tt rdp\_\,sourcefilename}

The value of the source filename supplied on the command line.

\quietsection{\tt rdp\_\,tree}
A pointer to the root of the derivation tree for parsers generated from specifications
that include one of the {\tt TREE} directives. 

\quietsection{\tt rdp\_\,verbose}

The value of the verbose mode flag. By default it is set to 0,
but if a {\tt -v} command line switch is encountered it is set to 1.

\section{Defining the message stream}
The initial destination for messages created by the
\verb+text_message()+ and 
\break
\verb+text_printf()+ functions is controlled
by the value of the \verb+TEXT_MESSAGES+ macro. 
By default this is defined to be {\tt stderr}, the
standard error stream. On MS-DOS in particular it is sometimes
useful to redefine this to be {\tt stdout} because of the 
difficulty of capturing the standard error stream to a file.
The message stream can also be redirected in mid-parse using the
\verb+text_redirect()+ routine. See the support library manual \cite{rdp:supp:1.5} for further details.

\section{Adding reserved words to the dangerous identifier list}
\rdp\ checks that all your identifiers are valid C identifiers that
will not clash with C or C++
reserved words. The macro \verb+RDP_RESERVED_WORDS+ which is defined in
\verb+rdp_aux.h+ specifies the
list of reserved words. The standard distribution contains the
ANSI reserved words and a few standard library functions.
You can add strings to this list in any order: you might have your own standard library functions, for instance.
Checking for reserved words is efficient\dash at the end of
parsing a complete IBNF specification all of the identifiers will be in
the \rdp\ symbol table. During the grammar checking phase \rdp\ looks to
see if any of the words specified in \verb+RDP_RESERVED_WORDS+ is in
the symbol table, and issues error messages accordingly. Hence checking
time is linear in the number of reserved words and is independent of the
length of the source text.

\chapter{Derivation tree construction and visualisation}
\label{tree}

Some translation tasks are difficult to perform during a parse, even if
a multi-pass parser is employed. In such cases, it is normal to construct an 
internal representation of the source text during parsing which may be traversed efficiently,
and to use an {\em intermediate form} for tasks such as optimisation.

High quality compilers
can perform many different code improvement transformations as part of
an optimisation phase. Typically, optimisations work by relating
together separate parts of the source text and so are very difficult to implement
in a single pass compiler which only `sees' a very small part of the input at any one time.

Take for example,
{\em common sub-expression elimination} which is one of the most
commonly applied optimisations. Consider two 2-dimensional arrays declared as
\begin{quote}
\begin{verbatim}
int a[10][20], b[10][20];
\end{verbatim}
\end{quote}
We can copy one element of {\tt b} to the corresponding position in {\tt a} as follows:
\begin{quote} \verb+a[i][j] = b[i][j];+ \end{quote}

This simple assignment actually hides two indexing calculations which we can
render explicitly in C using address arithmetic. In detail the 
computer has to perform this calculation:
\begin{quote}
\begin{verbatim}
*(a + (i*10) + j) = *(b + (i*10) + j);
\end{verbatim}
\end{quote}
Here, the index {\tt i} is multiplied by the width of the array (10 in
this case) and then added to the  value of {\tt j} and the base address
of {\tt a} to get the machine location of element  {\tt a[i][j]}, and
then essentially the same calculation is performed to find the location
of {\tt b[i][j]}.

A single pass compiler is pretty much limited to producing this kind of repetitive code, but
a compiler which is capable of gathering together information from potentially widely separated
parts of the source program can implement the common sub-expression separately, producing this
more efficient code:
\begin{quote}
\begin{verbatim}
int temp = (i*10) + j;
*(a + temp) = *(b + temp);
\end{verbatim}
\end{quote}


If a multiple pass translator is to be used then it is usual to
construct a data structure  in memory that represents the input program
in a manner which may be efficiently processed.  Simply storing the
original program text is inefficient because discovering a derivation
for an input text is time consuming~\dash that is after all the primary
function of the parsers that \rdp\ constructs and it would clearly be
wasteful to run the process several times\footnote{Of course, just  because making multiple passes over the source code
is a wasteful process it need not stop us using it where applicable and
\rdp\ provides the {\tt PASSES} directive for precisely this purpose.
Simple multi-pass applications, such as the implementation of a
translator from a machine's assembly language to its machine code, may
usefully exploit this strategy. You can read about the design and
implementation of such as assembler in the case study
manual~\cite{rdp:case:1.5}.}.

Leaving aside issues of efficiency, making multiple independent passes
over the source text does not of itself allow us to make connections
between widely separated parts of the text because the parsers generated
by \rdp\ only look at a single symbol at a time: they do not of
themselves keep track of complete sentences or program statements.
However, \rdp\ can be set to build a {\em derivation tree} whilst it
performs a parse. This tree reflects explicitly relationships between symbols in the
source program, and since it
is held as a pointer-based data structure rather than as a single long text string, it 
can be traversed and rearranged efficiently.

\section{Derivation trees}
Informally, a derivation tree is a {\em trace} of the parser's behaviour
during a particular parse. The derivation tree is constructed top down,
left to right by creating a new tree node every time a nonterminal or
terminal is matched. Every nonterminal when matched creates a new
internal tree node and every terminal when matched causes a new tree
leaf node to be added. In addition, when  an iterator with a lower bound
of zero (or the shorthands \verb+[ ... ]+ and \verb+{ ... }+) match the
{\em empty} string $\epsilon$ (or {\tt \#} in \rdp\ syntax) an empty
tree leaf node is added. The idea is that the nodes created whilst matching
the body of a nonterminal will be attached as children of the node corresponding
to that nonterminal.

This rather complicated recipe is best illustrated with an 
example. Let us revisit the example used in section~\ref{attributes} which describes
a minimalist grammar which can generate arithmetic expressions made up of an
addition followed by a multiplication:
\begin{quote}
\begin{verbatim}
start ::= INTEGER '+' expr.
expr  ::= INTEGER '*' INTEGER.
\end{verbatim}
\end{quote}

When presented with the source string \verb|3 + 6 * 7| the parser generated by \rdp\ from the
above grammar will construct the tree shown in Figure~\ref{first:tree}.
\begin{figure}
\begin{center}
~\hspace*{0.5cm}
\epsfbox{firsttre.ps}
\end{center}
\caption{A simple derivation tree}
\label{first:tree}
\end{figure}

In this example, tree construction starts by making a root node labeled
{\tt start}. The scanner then matches an {\tt INTEGER} with lexeme {\tt
3} and so a suitable {\tt INTEGER} leaf node is added to the tree. The
token {\tt +} is then matched and another leaf node is added. At this
point in the parse, the parser function  for rule {\tt start} calls the
function corresponding to rule {\tt expr} so a matching child node is added that then
becomes the parent node for subsequent leaf nodes.

This picture was made with the VCG (Visualisation of Compiler Graphs)
tool~\cite{SANDER95} which you can obtain from the \rdp\ archive as
described in appendix~\ref{distribution}. Any \rdp-generated parser may use the
automatic tree generation capability described in this chapter to allow
derivation trees to be
displayed on screen and printed using VCG if you are running under
Windows or X-windows on Unix. You will find further information on using
VCG in section~\ref{VCG:instructions}.

Derivation trees grow rather rapidly. In the standard \rdp\ distribution there is 
a grammar
for the Pascal language ({\tt pascal.bnf}) and a corresponding test file ({\tt test.pas})
containing 283 lines of Pascal. The tree produced contains 7167 nodes, one of which has 
67 children. It is quite difficult to visualise these large structures although
VCG provides useful navigation facilities. 

\subsection{A larger example}
Let us examine a grammar which describes a language of
assignment expressions. We
allow the usual four arithmetic operators along with exponentiation (denoted by the
operator {\tt **}), monadic {\tt +} and {\tt -} operators and parenthesised expressions.
The exponentiation operator is right associative and the other operators are left associative.
\begin{quote}
\small
\begin{verbatim}
program ::= { statement ';' }.
statement ::= ID '=' e1.
e1 ::= e2 { ('+' | '-') e2 }. (* Add or subtract              *)
e2 ::= e3 { ('*' | '/') e3 }. (* Multiply or divide           *)
e3 ::= e4 | ('+' | '-') e3.   (* Monadic positive or negative *)
e4 ::= e5 [ '**' e4 ].        (* Exponentiate                 *)
e5::= ID                      (* Variable or ...              *) 
      [ '(' (e1)@',' ')' ] |  (* ... function call            *) 
      INTEGER              |  (* Numeric literal              *)  
      '(' e1 ')'.             (* Bracketed subexpression      *) 
\end{verbatim}
\end{quote}
Figure~\ref{second:tree} shows the result of using this grammar to parse the string
\begin{quote}
\begin{verbatim}
a = 2;
b = a - 1 - 2 * (4 - 3) ** 4 ** 5 ** 6 / --+- 7;
\end{verbatim}
\end{quote}
\begin{figure}
\begin{center}
\epsfbox{secondtr.ps}
\end{center}
\caption{Derivation tree for expression grammar}
\label{second:tree}
\end{figure}

This large tree displays several interesting features. The first thing
to note is that the trees are designed to be read in a depth-first,
left-to-right fashion. One useful side effect of this is that if the
rectangular terminal nodes are written out in left-to-right order we
recover the original string. This list of leaf nodes is sometimes called
the {\em yield} of a tree.

It can also be useful to examine a horizontal section of the tree. When
printed, the trees display all nodes having the same depth in the tree
on the same horizontal line. Since the depth in the tree is dictated by
the number of nested grammar rules active at any given point in the
parse, a horizontal strip can tell you what was matched within a single
body. The very top of the tree shown in Figure~\ref{second:tree} for
instance shows that the first rule expanded by the parser was
\verb+program+ and the expansion was \verb+statement ; statement ;+

Rules {\tt e1, e2} and {\tt e4} in our grammar each have the form of a
call to a nonterminal followed by an optional phrase as in:
\begin{quote}
\verb+e2 ::= e3 { ('*' | '/') e3 }.+
\end{quote}
When an optional phrase matches the empty string $\epsilon$ (or \verb+#+
in \rdp\ terminology) an empty node is added to the tree, and the tree
shown in Figure~\ref{second:tree} shows many examples of this.

Finally, note that different forms of operator specification generate
different tree forms. In this case, the operators specified using
\verb+{  }+ iterator brackets such as ({\tt
+, -, *} and {\tt /}) generate horizontal runs of operators as in the
sub-expression \verb|b=a-1-2|. On the other hand, 
operators specified using right recursion such as {\tt **} generate a descending sequence of
nodes.

Since the full derivation tree is so large, it is conventional to
discard some parts of the tree, retaining only those nodes that convey
information needed by later stages of processing. \rdp\ provides a set
of  {\em promotion operators} that allow nodes to be moved back up the
tree, potentially overlaying earlier nodes. The operators are described
later in this chapter, and you will find large scale examples of their
use in the \rdp\ case study document~\cite{rdp:case:1.5}. To give you a flavour of what is
possible, Figure~\ref{third:tree} shows the result of applying these promotion operators
to the tree shown in Figure~\ref{second:tree}.

\begin{figure}
\begin{center}
~\hspace*{0.5cm}
\epsfbox{thirdtre.ps}
\end{center}
\caption{A modified derivation tree}
\label{third:tree}
\end{figure}

The {\em modified derivation tree} has been obtained by
\begin{enumerate}
\item moving certain arithmetic operator terminals up so that they overlay their parents,
\item deleting some tokens which are redundant in the tree representation such as \verb+;+,
\verb+(+ and \verb+)+,
\item deleting all empty ($\epsilon$) nodes left after the previous steps have been performed.
\end{enumerate}

In addition, we ensure that chains of left associative arithmetic operators are converted to
left descending sub-trees in a way that is symmetric with the right descending sub-trees 
used in the original tree to represent the right associative exponentiation operator,

\section{Tree generation directives}

By default, \rdp-generated parsers do not generate trees because the tree
construction process does impose some overhead on the parsing process,
and for simple single pass parsers this would be extravagant. Tree generation
is switched on by adding one of the three tree directives to a grammar and then
regenerating the parser by running the grammar through \rdp.

\quietsection{{\mediumseries\tt TREE([*}{\rm\em\mediumseries~data~}{\mediumseries\tt *])}} Switch on tree generation and
(optionally) define extra data fields to be added to each tree node. The
trees will have epsilon nodes deleted: leaf nodes containing epsilon are simply removed and
internal epsilon nodes are removed with their children being promoted to be at
the same level as the internal epsilon node was at before pruning.

\quietsection{{\mediumseries\tt EPSILON\_\,TREE([*}{\rm\em\mediumseries~data~}{\mediumseries\tt *])}} Switch on tree generation
and (optionally) define extra data fields to be added to each tree node.
Epsilon nodes will be left in the tree.

\quietsection{{\mediumseries\tt ANNOTATED\_\,EPSILON\_\,TREE([*}{\rm\em\mediumseries~data~}{\mediumseries\tt *])}} Switch on tree generation and (optionally)
define extra data fields to be added to each tree node. Epsilon nodes
will be left in the tree as with the {\tt EPSILON\_\,TREE} directive but
each such node will be annotated with the string {\tt \#:{\em name}}
where {\em name} is the name of the subrule that generated the epsilon.

Figures~\ref{fourth:tree}--\ref{sixth:tree} show the different
effects of these directives when added to the expression grammar given
above and used to parse the string \verb+a=2;+

\begin{figure}
\begin{center}
~\hspace*{0.5cm}
\epsfbox{fourthtr.ps}
\end{center}
\caption{Effect of the {\tt TREE} directive}
\label{fourth:tree}
\end{figure}

\begin{figure}
\begin{center}
~\hspace*{0.5cm}
\epsfbox{fifthtre.ps}
\end{center}
\caption{Effect of the {\tt EPSILON\_\,TREE} directive}
\label{fifth:tree}
\end{figure}

\begin{figure}
\begin{center}
~\hspace*{0.5cm}
\epsfbox{sixthtre.ps}
\end{center}
\caption{Effect of the {\tt ANNOTATED\_\,EPSILON\_\,TREE} directive}
\label{sixth:tree}
\end{figure}


\section{Using VCG to visualise derivation trees}
\label{VCG:instructions}

All \rdp-generated parsers accept the {\tt -V{\em filename}} command
line switch. For parsers that have been generated from grammars that do
not include one of the three {\tt TREE} directives this switch simply generates a warning
message, but for parsers that do have tree generation enabled a text file
will be created containing a specification of the derivation tree in the
language understood by VCG. If the optional {\em filename} is specified
then this will be the name of the VCG file, otherwise the default name
of {\tt rdparser.vcg} will be used.

On MS-Windows and Unix systems running X-windows the VCG tool may be started by typing
\begin{quote}
\verb+vcg rdparser.vcg+
\end{quote}
or the equivalent for your own file name. VCG will read the tree in (which may take a little 
while for a large tree) and then draw it on the screen. You can use VCG's navigational
facilities to move around within the tree, zoom in and out, and print out the whole tree or
a portion of it. VCG is a powerful tool and you should read the VCG manual supplied with the
VCG distribution to get a full understanding of the tool. We are grateful to the author of VCG for permission
to distribute it with \rdp.

\chapter{Tree manipulation}

Full derivation trees consume a lot of space, and often contain nodes
that are of little use in subsequent language processing. Most books on
compiler theory describe {\em concrete} and {\em abstract syntax trees}
(often called AST's). There is rather little agreement on the
formal definition of an AST, and in practice most language tool
designers design  an {\em ad hoc} representation which is built on the
fly during the parsing phase. By embedding semantic actions in the specification of
an \rdp-generated
parser it is, of course, possible to adopt this approach using \rdp, but
\rdp\ provides a set of {\em promotion operators} which allow common AST
forms to be  automatically generated from the derivation tree. The
advantage of this approach is that the grammar itself directly dictates
the shape of the modified derivation tree whereas traditional AST's are
only loosely related to the actual derivation tree. As a result,
maintaining  a language processor based on the traditional twin-track
grammar and AST structure requires two independent tree-like forms to be
described whereas in \rdp\ the grammar itself fulfills both functions.
The disadvantage is that the \rdp\ promotion operators are not very easy
to use, and we view them as somewhat experimental at this stage. The
authors would be interested to hear of user experiences, both good and
bad.

\section{Normal tree construction}
The promotion operators are applied on the fly during tree construction, and it is possible
for a sequence of nodes to be promoted above each other. A full understanding of the effects
of the promotion operators therefore requires an understanding of the order in which the tree
is constructed. 

At any given time during a parse there will be a {\em current parent}, that is a particular tree
node which is the one to which children are being added. Immediately before a parse 
begins a root node representing the first call to the parser function for the start
production is created and this is made the current parent. In the absence of promotion
operators, subsequent tree growth occurs as
a result of one of three processes:
\begin{enumerate}
\item Whenever a terminal is encountered within a rule a new node is added as a child of the
current parent labeled with the terminal's lexeme. The current parent does not change, therefore
matches against terminals
cause tree nodes to be added from from left to the right without changing the level.
\item Whenever an optional subphrase arising from \verb+[...]+ or \verb+{...}+ brackets or
from an iterator with a low count of zero matches against the null string $\epsilon$, an epsilon
node is added as a child of the
current parent. The current parent does not change. 
\item Whenever a nonterminal is encountered within a rule, a new child
node is added to the current parent and labeled with the name of that
nonterminal {\em and that node is made the current parent for any nodes
that are created as a result of matches against that nonterminal's
productions}. When the parser finishes matching against that nonterminal's productions, the
original current parent is restored.
\end{enumerate}
The effect of these rules is to go down one level in the tree each time
a nonterminal is encountered and to go back up a level as the parser
completes the matching of each production. 

\section{Modifying tree construction with promotion operators}
The \rdp\ promotion operators act so as to modify the rules above. 
There are four possible operators:
\subsection{Promote underneath parent} The \verb+^+ (promote underneath) operator
forces the node to be promoted to the parent node but the parent node's
fields overwrite those of the node being promoted. The resulting node becomes the current parent for subsequent operations.
\subsection{Promote on top of parent} The \verb+^^+ (promote on top of) operator forces 
the node to be promoted to the parent node and the parent node's
fields are overwritten by those of the node being promoted. The resulting node becomes the current parent for subsequent operations.
\subsection{Promote above parent} The \verb+^^^+ (promote above) operator forces the node to be
promoted so as to become the parent of the
current parent, that is it is inserted above the current parent rather than as a child of the
current parent. The resulting inserted node becomes the current parent for subsequent operations.
\subsection{Insert here (no promotion)} The \verb+^_+ (no promotion) operator forces
the node to be inserted under the current
parent in the usual way, that is the \verb+^_+ operator forces the rules described in
the previous section to be observed for the grammar element to which the operator is applied. The
current parent is unchanged. This operator is usually only used to apply the normal behaviour to
a nonterminal whose default behaviour has been overridden, as described in the next section.

\section{Valid contexts for promotion operators}
Promotion operators may be applied in four contexts: 
\begin{enumerate}
\item immediately after a terminal: \begin{quote}\verb|a::=b '+'^^ c.|\end{quote}
in which case it indicates that the
corresponding terminal node should be promoted,
\item immediately after a nonterminal on the right hand  side of a rule: \begin{quote}
\verb|a::=b^^ '+' c.|\end{quote} in which case
it indicates that the corresponding nonterminal node should be promoted,
\item immediately after a nonterminal on the left hand side of a rule \begin{quote}
\verb|a^^::=b '+' c.|\end{quote} in which
case it specifies that the default promotion for instances of that nonterminal on the right hand side
of rules should be changed from \verb+^_+ (the normal default) ,
\item in the default action clause of an optional phrase arising from \verb+[  ]+ or \verb+{  }+ brackets or
from an iterator with a low count of zero: \begin{quote}\verb|a::=[b '+' c]:^^.|\end{quote}
in which case it indicates that any epsilon
node created as a result of matching the optional phrase against the null string $\epsilon$ should be promoted.
\end{enumerate}

Each grammar element (terminal or nonterminal) in an \rdp\ grammar has an attached
promotion operator which specifies the way that the corresponding tree nodes will
be built into the tree during a parse. The default operation is \verb+^_+,
so in effect any grammar element without an explicit promotion operator attached has
an implicit \verb+^_+ operator following it, and such a node will be processed according to the rules
given in the previous section\footnote{For nonterminals only, new defaults may be established by
applying a promotion operator to the left hand side of the rule definition.}.


\section{A complete example}

In this section we show how to apply the promotion operators to the grammar
for a simple expression-based language.
The original grammar (without promotions) was given above and
generates trees of the form shown in Figure~\ref{second:tree}. This modified grammar was used to 
produce the much more space-efficient tree shown in Figure~\ref{third:tree}.
\begin{quote}
\small
\begin{verbatim}
TREE
program ::= { statement ';'^ }.
statement ::= ID '='^^ e1.
e1 ::= e2^^ { ('+'^^^ | '-'^^^) e2 }. (* Add or subtract (LA)    *)
e2 ::= e3^^ { ('*'^^^ | '/'^^^) e3 }. (* Multiply or divide (LA) *)
e3 ::= e4^^ | ('+'^^ | '-'^^) e3.     (* Monadic positive or negative (RA) *)
e4 ::= e5 [ '**'^^ e4 ]:^^.           (* Exponentiate (RA)       *)
e5::= ID^^                            (* Variable or ...         *)
      ['('^ (e1)@','^ ')'^ ] |        (* ... function call       *)
      INTEGER^^              |        (* Numeric literal         *)
      '('^ e1^^ ')'^.                 (* Bracketed subexpression *)
\end{verbatim}
\end{quote}

\subsection{Removing syntactic sugar}
The simplest application of the promotion operators is to simply remove
unnecessary tokens from the tree. The \verb+^+ operator has this effect
because it promotes the node up {\em under} the current parent. Since
the resulting node contains the label from the original parent, the
contents of the new node is effectively discarded. Using this operator, then, allows
syntactic sugar to be deleted from the language. In this grammar, the parenthesis tokens in rule
{\tt e5} have been treated this way. In essence, parentheses in a programming language are usually
used to represent {\em nesting} of some sort, and of course a tree allows nesting to be 
structurally shown simply by making the contents of a parenthesised expression into
a child node. There is no reason, therefore, for the parentheses to be retained in the tree.
Another example of redundant syntactic sugar is the semicolon used to terminate statements
and this is similarly deleted.

Here is a small example that shows the effect of promoting the parentheses up under
their parents:
\begin{quote}
\begin{verbatim}
s ::= e ['+' s].
e ::= t ['*' e].
t ::= INTEGER | '('^ s ')'^.
\end{verbatim}
\end{quote}
Figure~\ref{seventh:tree} shows the full tree that will be produced without the promotion
operators when parsing the string \verb|(2+3)*4|, and Figure~\ref{eighth:tree} shows the result of adding the promotions.
\begin{figure}
~\hspace*{4.5cm}
\epsfbox{seventht.ps}
\caption{Simple expression: full tree}
\label{seventh:tree}
\end{figure}

\begin{figure}
~\hspace*{4.5cm}
\epsfbox{eighthtr.ps}
\caption{Simple expression: result of adding promotion operators}
\label{eighth:tree}
\end{figure}


\subsection{Making operators parent nodes to their operands}
Classically, parse trees represent arithmetic expressions for diadic operators as
binary trees with each operator node having two children corresponding to its operands. We
get this effect in \rdp\ by promoting the operator node onto the parent nonterminal node using
the \verb+^^+ operator. This is illustrated in rule {\tt e4} which shows the implementation
of the right associative (RA) exponentiation operator {\tt **}. In detail, it turns out that the
$\epsilon$ node created at the end of a run of RA operators must be promoted too: hence the
default promotion in rule {\tt e4}.

Here is a simplified grammar illustrating the construction of a right associative operator
tree. The result of parsing the string \verb+2**3**4+ is shown if Figure~\ref{ninth:tree}.
\begin{quote}
\begin{verbatim}
s ::= e ['**'^^ s]:^^.
e ::= INTEGER^^ | '('^ s^^ ')'^.
\end{verbatim}
\end{quote}

\begin{figure}
~\hspace*{4.5cm}
\epsfbox{ninthtre.ps}
\caption{Right associative operator tree}
\label{ninth:tree}
\end{figure}

\subsection{Handling left associative operators}

Arithmetic expressions containing left associative (LA) operators
present a little more difficulty which is perhaps unfortunate since LA
operators are the norm. From the parsing point of view the  recursive
rules used to recognise a LA operator create their tree nodes in the
`wrong' order and simply promoting the operator token node onto its
parent yields a tree whose semantics do not match that of normal
algebraic usage. The correct solution is to promote the operator token
to the node {\em above} its parent, thus building that part of the tree
in what amounts to a bottom-up fashion. This approach is illustrated in
rules {\tt e1} and {\tt e2} above.

Here is a simplified grammar illustrating the construction of a left associative operator
tree. The result of parsing the string \verb+2-3-4+ is shown if Figure~\ref{tenth:tree}.
\begin{quote}
\begin{verbatim}
s ::= e^^ {'-'^^^ e}.
e ::= INTEGER^^ | '('^ s^^ ')'^.
\end{verbatim}
\end{quote}

\begin{figure}
~\hspace*{4.5cm}
\epsfbox{tenthtre.ps}
\caption{Left associative operator tree}
\label{tenth:tree}
\end{figure}

\chapter{Error and informational messages}

All \rdp\ error messages are issued {\em via} the \verb+text_message()+ routine
which is part of the {\tt textio} package described in \cite{rdp:supp:1.5}.
The routine supports four classes of message:
\begin{itemize}
\item {\em fatal errors} which cause
immediate termination of the run, 
\item {\em errors} which cause
termination of the run after grammar analysis unless the {\tt -F}
flag is set, 
\item {\em warnings} which may indicate a problem that
should be checked and 
\item {\em informational messages} which provide
feedback only and do not indicate a problem. 
\end{itemize}

In each case, a message may or may not cause an {\em echo} of the
current scanner input line, followed by an arrow indicating the current
position of the scanner.

A typical message looks like this:
\begin{verbatim}
33: Error 1 (zzz.bnf): unexpected character 0x2C ',' in source file
33: bad , syntax ,
33: ----1
\end{verbatim}

In this case an illegal character has been found in the source file. Up
to nine error messages {\em per} line of source code may be reported,
with the error messages themselves followed  by an echo of the line in
error and a marker line showing the location of the errors.

In detail, whenever \rdp\ detects a syntax error in the source IBNF it
prints out a line of the file with a digit marking the last character of
the first token {\em after} the token that caused the error. This can be
confusing if the error token is the last on a line, because the {\em
next} line will be printed with an arrow pointing to the start of the
line. 

Fatal, error and warning messages are preceded by the relevant message
severity. 
Informational messages are only preceded
by a space character. This makes it easier to spot the errors by
scanning the leftmost column of the output listing. 


The rest of this chapter lists all \rdp\ 
error messages in alphabetical order by
class. Some of these messages can also be reported by \rdp-generated
parsers.

\section{Fatal errors}

\errorsection{\tt errors detected in source file}

This message is issued at the end of syntax analysis if syntax
errors have been reported. It causes termination of the run before the
\verb+POST_PARSE+ routine is called.

\errorsection{\tt internal error - expecting alternate}

The internal data structures representing the grammar have become
corrupted. This error can only occur as a result of a programming
error within \rdp: please submit a bug report to {\tt
A.Johnstone@rhbnc.ac.uk} which includes an
example IBNF file that generates the error along with a note of your
computer model, operating system name and version and compiler
vendor and version.

\errorsection{\tt internal error - unexpected alternate in sequence}

The internal data structures representing the grammar have become
corrupted. This error can only occur as a result of a programming
error within \rdp: please submit a bug report to {\tt
A.Johnstone@rhbnc.ac.uk} which includes an
example IBNF file that generates the error along with a note of your
computer model, operating system name and version and compiler
vendor and version.

\errorsection{\tt internal error - unexpected kind found}

The internal data structures representing the grammar have become
corrupted. This error can only occur as a result of a programming
error within \rdp: please submit a bug report to {\tt
A.Johnstone@rhbnc.ac.uk} which includes an
example IBNF file that generates the error along with a note of your
computer model, operating system name and version and compiler
vendor and version.

\errorsection{\tt no rule definitions found}
The source files processed by \rdp\ did not contain any rule definitions, so there
is nothing to do.

\errorsection{\tt no source file specified}

No filename was found on the command line, and a {\tt -f} (filter
mode) flag had not been issued.
\rdp\ prints a summary help message after issuing this error. 


\errorsection{\tt run aborted without creating output files - rerun with -F to override}

Errors were detected during grammar analysis and so no output
files were created. Many languages (including C and Pascal)
contain at least one ambiguous rule (the {\tt if...then...else} 
problem) and so {\em when} you are sure that all other
problems in your grammar have been eradicated, rerun \rdp\ with a
{\tt -F} flag which will override this message and generate the
output files.
 
\errorsection{\tt source file not found}

The source file does not exist, or is read locked against
the user. \rdp\ and \rdp-generated parsers
print a summary help message after issuing this error. 

\errorsection{\tt unable to open header output file '{\em filename}' for writing}

\rdp\ was unable to open the named header file
 for writing. This may be because there is no disk
space left, or there may already exist a file of that name that
is write protected.

\errorsection{\tt unable to open parser file '{\em filename}' for writing}

\rdp\ was unable to open the named parser file
for writing. This may be because there is no disk
space left, or there may already exist a file of that name that
is write protected.

\errorsection{\tt unable to open VCG file '{\em filename}' for writing}

\rdp\ was unable to open the named VCG output file specified with a {\tt -V} switch
for writing. This may be because there is no disk
space left, or there may already exist a file of that name that
is write protected.

\errorsection{\tt unrecognised option -$c$}

\rdp\ or a generated parser  found a command line switch it did not
understand. After issuing this message \rdp\ prints out a summary help
page.

\section{Errors}

\errorsection{\tt comment delimiter tokens must be less than three characters long}

Due to the rather crude state machine used during comment parsing,
comment close delimiter tokens must be one or two characters
long, so the Algol-68 {\tt comment}\ldots{\tt tnemmoc} brackets
can not be handled (and quite right too in many people's opinion).

\errorsection{\tt doubly declared symbol '{\em name}'}

{\em name} appears more than once on the left hand side of a
rule definition. Merge the rules using alternates.

\errorsection{\tt empty tokens are not allowed: use [ ... ] instead}

\rdp\ does not allow use of the explicit null token \verb+''+.
Only the iteration operator \verb'@', the zero-or-more bracket \verb+{  }+
and optional bracket \verb+[  ]+ can introduce null rules into the grammar.

\errorsection{\tt identifier '{\em name}' begins with a reserved name}

All \rdp\ internal identifiers begin with one of a set of ten reserved prefixes listed in
Table~\ref{prefixes}. To avoid clashes between user identifiers and these internal
names, \rdp\ rejects any user defined identifiers that begin with one of those prefixes.

\errorsection{
\tt Error 1 ({\em filename}): expecting one of '{\em token1}', ...\\
{\em line containing an error}\\ 
-------1
}

This is the generic \rdp\ syntax error report. After printing the error
messages  the line containing the errors is echoed to the error stream
along with a pointer line. The pointer line contains up to nine digits
that each mark the token {\em after} the token that has generated an
error.

\errorsection{\tt identifier '{\em name}' is a C++ reserved word or library
identifier}

Surprising compile time errors would result from declaring a
rule called, for instance {\tt register} because {\tt
register} is, of course, a  C reserved word and may therefore not be
used as a function name. All identifiers in the IBNF file are
checked against a list of dangerous names which includes all C
keywords and a few of the more common library functions. 
You can add extra names to the list by
adding extending the definition of parameter \verb+RDP_RESERVED_WORDS+
in file \verb+rdp_aux.h+

\errorsection{\tt illegal grammar element: a colon may not appear here}

A syntax error in the \rdp\ source file has been detected.

\errorsection{\tt illegal grammar element: a real may not appear here}

A syntax error in the \rdp\ source file has been detected.

\errorsection{\tt illegal grammar element: an integer may not appear here}

A syntax error in the \rdp\ source file has been detected.

\errorsection{\tt illegal grammar element: expressions may not return values}
A syntax error in the \rdp\ source file has been detected

\errorsection{\tt illegal grammar element: perhaps you intended to write '{\em string}'}

A syntax error in the \rdp\ source file has been detected. A double quote delimited
string has been found where only a single quote delimited string is allowed.

\errorsection{\tt include file '{\em filename}' not found}

The named include file does not exist, or is read locked against
the user.

\errorsection{\tt iteration count too low} 

The \rdp\ rule \verb+example ::= ('a' 'b')4@6# 'z'+ matches the following strings:
\begin{quote}
\begin{verbatim}
ababababz
abababababz
ababababababz
\end{verbatim}
\end{quote}

\rdp\ performs this match by iterating in the \verb+('a' 'b')+ sub-rule
at least four and at most six times. In detail, \rdp\ iterates round the
body and then checks the number of times it matched \verb+('a' 'b')+
when it eventually finds a non-match in the input. If \rdp\ finds that
it went round less than four times, it issues this message. So, in
general, the message indicates that there were too few instances of the
sub-rule in the input to meet the iterator specification.

\errorsection{\tt iterator high count must be greater than low count}

An iterator of the form \verb+(body)5@3+ is illegal because it requires
\verb+body+ to be matched at least five, but no more than three, times
which is meaningless.

\errorsection{\tt LL(1) violation - rule '{\em name}' alternates\\
``{\em alternate}''\\and ``{\em alternate}''\\ share these start tokens:\\ {\em tokens}}

This is the most common LL(1) problem: a pair of alternates share
at least one start terminal and so cannot be disambiguated by the
parser. A simple example is 
\begin{quote}
\verb+bad_first ::= 'a' 'b' 'c' | 'a' 'd'.+
\end{quote}
The error can often be eliminated by factorising the grammar,
for example
\begin{quote}
\verb+good_first ::= 'a' ( 'b' 'c' | 'd' ).+
\end{quote}

\errorsection{\tt LL(1) violation - rule '{\em name1}' and '{\em name2}' are both nullable}

A construction like \verb+['a'] ['b']+ is ambiguous because \rdp\ could match either bracket
against a null input string. 

\errorsection{\tt LL(1) violation - rule '{\em  name}'\\ contains null but first and follow sets both include:\\ {\em tokens}}

When deciding whether to enter an iteration or optional bracket
the parser must be able to distinguish between tokens that belong
to the rules inside the bracket and those that belong to
the rules following the brackets. If there are any tokens
in both the {\em first} and {\em follow} sets for the
subrule then the parser cannot disambiguate the brackets.

A simple example is 
\begin{quote}
\verb+bad_null ::= 'x' {'a' 'b' 'c'} 'a'.+
\end{quote}
The error can sometimes be eliminated by refactorising the grammar,
for example
\begin{quote}
\verb+good_null ::= 'x' 'a' {'b' 'c' 'a'}.+
\end{quote}

\errorsection{\tt LL(1) violation - rule '{\em name}' is left recursive}

In top-down parsers, immediate or indirect left recursion creates
an infinite loop and must be eliminated.

\errorsection{\tt LL(1) violation - rule '{\em rule}' is nullable but contains the nullable subrule {\em rule}}

It is illegal to nest nullable sub-rules (constructs such as \verb+{ [ 'a' 'b' ] }+~) because \rdp\ 
generated parsers could match either the inner square brackets or the outer braces to a
null string. Rewrite as \verb+{ 'a' 'b' }+.

\errorsection{\tt LL(1) violation - subrule '{\em name}' is empty}

The IBNF syntax analyser will accept a rule of the form
\begin{quote}
\verb+bad ::= 'a' 'b' | [* semantic action *] | 'z'.+
\end{quote}
but this is not meaningful IBNF, because the middle alternate
will never be entered. In fact, this is effectively an empty
alternate as far as the parser is concerned which is also
illegal.

The only context in which alternates containing only semantic
actions are allowed is the special case of a {\em semantic
rule}. See section~\ref{semantic:rules} for details. 

\errorsection{\tt obsolete directive:}

\noindent\mbox{\tt obsolete directive: HASH\_\,PRIME replaced by SYMBOL\_\,TABLE at version 1.4}\\
\noindent\mbox{\tt obsolete directive: HASH\_\,SIZE replaced by SYMBOL\_\,TABLE at version 1.4}\\
\noindent{\tt obsolete directive: INTERPRETER mode deleted at version 1.4}\\
\noindent{\tt obsolete directive: POST\_\,PROCESS renamed POST\_\,PARSE at version 1.3}\\
\noindent{\tt obsolete directive: PRE\_\,PROCESS renamed PRE\_\,PARSE at version 1.3}\\
\noindent{\tt obsolete directive: SET\_\,SIZE deleted at version 1.4}\\
\noindent{\tt obsolete scanner primitive: ALT\_\,ID deleted at version 1.4}\\
\noindent{\tt obsolete scanner primitive: NEW\_\,ID deleted at version 1.4}\\
\noindent{\tt obsolete scanner primitive: NUMBER renamed INTEGER at version 1.3}\\

A grammar for a previous version of \rdp\ has been parsed. Replace
obsolete directives and primitives.

\errorsection{\tt rule {\em name} is empty}

A rule with no body has been declared.

\errorsection{\tt string delimiter tokens must be exactly one character long}

Due to the rather crude state machine used when parsing strings,
the close token must be exactly one character long. We would be
interested to hear if you have an application that requires
multi-character string delimiters.

\errorsection{\tt tokens must not contain spaces or control characters}

White space is stripped by the scanner, so a token definition in
the IBNF file that contained white space or non-printing characters
could never be matched by the scanner.

\errorsection{\tt undeclared symbol '{\em name}'}

A rule name has been referenced that is not defined elsewhere in
the current set of input files.

\section{Warnings}

\errorsection{\tt grammar is not LL(1) but -F switch set: writing files}

This message appears instead of the fatal abort message when the
{\tt -F} switch is used.

\errorsection{\tt rule '{\em name}' will not appear in the output file}

It is sometimes useful to define rules that are not
explicitly referenced in the grammar, typically to specify
comment and string definitions. \rdp\ searches the entire grammar
recursively from the start rule looking for unused
rules and marks them so that no equivalent code is produced
in the parser output files. This avoids warning messages from the
C compiler about the unused function definitions.

\section{Informational messages}

\errorsection{\tt {\em count} CPU seconds used}

In verbose mode all \rdp-generated parsers report CPU time consumption
with this message at the end of the run. Note that the figure is a
measure of mill time, not elapsed time. The accuracy of the figure
depends on your implementation of the ANSI C {\tt clock()} routine. Some
PC libraries are known to be a little unreliable on this score.

\errorsection{\tt {\em count} rules, {\em count} tokens, {\em count} actions and {\em count} subrules}

In verbose mode, \rdp\ reports summary grammar statistics with this
message. A {\em subrule} is the expansion of a grammar bracket.

\errorsection{\tt adding continuation token '{\em token}'}

The \rdp\ scanner matches {\em punctuation tokens} (i.e. tokens
made up of non-alphanumeric characters) by repeatedly looking in
the scanner symbol table and matching the longest token it can find. This
strategy  requires that all substrings of a token be in the
symbol table, so that the token {\tt ::=} requires that {\tt ::}
and {\tt :} are also loaded. A {\em continuation token} is any
token required for matching that has not already been declared by
the user.


\errorsection{\tt checking for clashes with reserved words}

\rdp\ checks all rule and attribute names to ensure that they are
valid C identifiers that do not clash with C reserved words or library
names. The list of names checked by \rdp\ is maintained in macro 
\verb+RDP_RESERVED_WORDS+ which is defined in
file \verb+\rdp_supp/rdp_aux.h+. You can add names to this list by
appending them to the macro definition. Note that the order of
definition is not significant.

\errorsection{\tt checking for continuation tokens}

The \rdp\ scanner matches {\em punctuation tokens} (i.e. tokens
made up of non-alphanumeric characters) by repeatedly looking in
the symbol table and matching the longest token it can find. This
strategy  requires that all substrings of a token be in the
symbol table, so that the token {\tt ::=} requires that {\tt ::}
and {\tt :} are also loaded. A {\em continuation token} is any
token required for matching that has not already been declared by
the user. This message is issued in verbose mode at the start of
continuation checking.

\errorsection{\tt checking for disjoint first sets}

\rdp\ checks that rules are LL(1) by ensuring that the start sets of
all alternates are disjoint for each rule in the grammar. 
This message is issued in verbose mode at the start of
disjoint set checking.

\errorsection{\tt checking for empty alternates}

Syntactically it is possible for an \rdp\ grammar to contain only
semantic actions even when it is not part of a semantic rule.
\rdp\ checks all alternates and reports this error whenever it finds a
rule that has no tokens in it. This message is issued in verbose mode at the start of
empty checking.

\errorsection{\tt checking for nested nullable rules}

\rdp\ checks that rules are not ambiguous as a result of nesting 
nullable subrules such as \verb+{body}+ or \verb+[body]+ within each
other. This message is issued in verbose mode at the start of null rule
checking.

\errorsection{\tt checking nullable rules}

\rdp\ checks that rules are LL(1) by ensuring that the first and
follow sets of each rule that can match the null token are disjoint.
This message is issued in verbose mode at the start of
null rule checking.

\errorsection{\tt dumping derivation tree to VCG file to '{\em filename}'}

This message is issued immediately before writing the VCG derivation tree file.

\errorsection{\tt dumping header file to '{\em filename}'}

This message is issued immediately before writing the header file.

\errorsection{\tt dumping parser file to '{\em filename}'}

This message is issued immediately before writing the main parser file.

\errorsection{\tt entered '{\em rule-name}'}

When an \rdp-generated parser is generated using the {\tt -R} option, the parser
is enhanced to output trace information when run. Each time a grammar
rule is activated, the parser prints out an entry and an exit message
which can be used to track the nesting of parser function calls during a run.

\errorsection{\tt exited '{\em rule-name}'}

When an \rdp-generated parser is generated using the {\tt -R} option, the parser
is enhanced to output trace information when run. Each time a grammar
rule is activated, the parser prints out an entry and an exit message
which can be used to track the nesting of parser function calls during a run.

\errorsection{\tt follow sets stabilised after {\em count} passes}

Follow set calculation usually requires a number of passes over
the whole grammar. The number of passes depends on both the
complexity of the grammar and the order in which the rules
are listed. We would be interested in receiving a copy of
any real grammar that requires more than twenty passes.


\errorsection{\tt generating first sets}

This message is issued immediately before the start of first set generation.


\errorsection{\tt generating follow sets}

This message is issued immediately before the start of follow set generation.


\errorsection{\tt no continuation tokens needed}

The \rdp\ scanner matches {\em punctuation tokens} (i.e. tokens
made up of non-alphanumeric characters) by repeatedly looking in
the symbol table and matching the longest token it can find. This
strategy  requires that all substrings of a token be in the
symbol table, so that the token {\tt ::=} requires that {\tt ::}
and {\tt :} are also loaded. A {\em continuation token} is any
token required for matching that has not already been declared by
the user. This message is issued in verbose mode at the end of
continuation checking if no such tokens were needed.

\errorsection{\tt updating follow sets}

After the main grammar analysis takes place, \rdp\ adds the first
sets to the follow sets for iteration brackets \verb+{...}+ which
aids error recovery. The follow sets then need to be recalculated.

\chapter{Understanding and debugging \rdp-generated parsers}

In this chapter we give a simplified overview of the structure of an
\rdp-generated parser along with some advice on using \rdp's facilities
to monitor the execution of a running parser.

\rdp\ writes out two files whenever it successfully generates a
parser\dash a {\em header} file with a suffix of {\tt .h} and a {\em
main} file with a suffix of {\tt .c}.  These files are designed to be
human-readable so that inserted semantic actions may be traced by
stepping through the parser with a conventional debugger. The purpose of
this section is to explain the basic techniques that are used within a
parser by looking at real \rdp-generated code. 

We shall begin by looking
at the parser generated by \rdp\ for this small grammar.
\begin{quote}
\begin{verbatim}
start ::= INTEGER '+' expr.
expr  ::= INTEGER '*' INTEGER.
\end{verbatim}
\end{quote}

\section{The header file}

The header file contains declarations for datatypes that might be needed
for use in semantic actions, such as any symbol table or tree data
fields declared in the user's {\tt .bnf} file. It also contains an {\tt enum}
declaration corresponding to the tokens declared in the grammar 
(described in more detail in the next section) and a macro which
expands to the number of passes used in this parser. The header file
for our example grammar is shown in Figure~\ref{extract1h}.

\begin{figure}
{\small
\begin{verbatim}

#include "scan.h"

/* Maximum number of passes */
#define RDP_PASSES 1

/* Token enumeration */
enum
{
RDP_T_17 /* * */ = SCAN_P_TOP, RDP_T_18 /* + */,
RDP_TT_TOP
};

/* Parser start production */
void start(void);
\end{verbatim}
}
\caption{Extracts from an \rdp-generated header file}
\label{extract1h}
\end{figure}

\section{The \rdp\ scanner}

Traditional parser generators work only at the level of language tokens,
and it is the user's responsibility to supply a suitable lexical
analyser that digests the source text into a stream of tokens for
consumption by the parser proper. One way of  providing this lexical
analysis function is to use a lexical analyser generator, which is
rather like a scaled down parser generator with features targeted
specifically at the construction of lexical analysis functions. \rdp\
does not need a separate lexical analyser generator: the parser
generator and the lexical analyser are integrated together under the
control of a single IBNF specification.

When analysing a grammar, \rdp\ extracts information about tokens and
uses it to parameterise the built-in scanner. This is convenient, but
you should be aware that the \rdp\ scanner is not completely
general\dash in many versions of the BASIC language, for instance,
string identifiers begin with a dollar sign and it is not
possible to write an \rdp\ grammar that enforces this rule
exactly\footnote{It is easy to define an identifier such as {\tt id ::=
'\$' ID.} but this will accept `identifiers' with a space between the
{\tt \$} sign and the rest of the identifier.}. The scanner itself is a
function called \verb+scan_()+ the source for which resides in
\verb+rdp_supp/scanner.c+. In principle new kinds of lexical structure
can be defined by adding in new sections of code, but this turns out to
require a good understanding of \rdp's internals so you might like to
contact the authors for advice before embarking on this course.

\subsection{The token enumeration}
\rdp\ makes a list of all the tokens used and
then writes out a C enumeration which has the effect of allocating a
unique integer value to represent each token. All grammars automatically
include  the scanner elements listed in Chapter~\ref{scanner:elements}
and so the first sixteen or so elements of the token enumeration are allocated
to the scanner primitives. The scanner element enumeration
\verb+enum scan_primitive_type+ is defined in \verb+rdp_supp\scan.h+: each element
name comprises the string \verb+SCAN_P_+ concatenated with the name of the scanner
element as used within the \rdp-IBNF language.

\begin{quote}
\begin{verbatim}
enum scan_primitive_type
{
  SCAN_P_IGNORE, SCAN_P_ID, SCAN_P_INTEGER, SCAN_P_REAL,
  SCAN_P_CHAR, SCAN_P_CHAR_ESC,
  SCAN_P_STRING, SCAN_P_STRING_ESC,
  SCAN_P_COMMENT, SCAN_P_COMMENT_VISIBLE,
  SCAN_P_COMMENT_NEST, SCAN_P_COMMENT_NEST_VISIBLE,
  SCAN_P_COMMENT_LINE, SCAN_P_COMMENT_LINE_VISIBLE,
  SCAN_P_EOF, SCAN_P_EOLN, SCAN_P_TOP
};
\end{verbatim}
\end{quote}

There are two elements in this enumeration which do not correspond with
real scanner elements. The first \verb+SCAN_P_IGNORE+ is used by the
scanner when it finds an illegal character or a comment in the source file.
It is a signal to the scanner to `go round again' and attempt
to find a new, valid, token. The parser proper will never see an
instance of this pseudo-token because the scanner will keep restarting until it
finds something other than an \verb+IGNORE+ element.

The second pseudo-element is \verb+SCAN_P_TOP+ which simply takes a value one more than
the highest real scanner element. Its value is then used to initialise the first element
of the user-defined token enumeration written to the header file:

\begin{quote}
\begin{verbatim}
enum {RDP_T_17 /* * */ = SCAN_P_TOP, RDP_T_18 /* + */, ...
\end{verbatim}
\end{quote}

This ensures that the scanner elements and the tokens from the grammar are mapped to a
contiguous sequence of integer values.

\subsection{Interaction between the scanner and the parser}

The parser calls the scanner function \verb+scan_()+ each time it needs
to read a new token from the input file. The scanner begins by reading
and discarding any whitespace characters (such as tabs, spaces and, for
parsers which do not use the {\tt EOLN} scanner element newline
characters). The scanner then reads characters until a complete lexeme
has been recognised. It loads a global variable called
\verb+text_scan_data+ with a string containing the lexeme itself and an
integer value from the token enumeration indicating which token the
scanner has recognised. In what follows we shall
refer to this global variable as the {\em scanner variable}. 

The scanner variable is a structure containing several fields, not all of
which are used by every token. The file {\tt scan.h} contains the
relevant definitions.  In the case of scanner elements such as {\tt
INTEGER} which can return a synthesized attribute value, the scanner is
also responsible for calculating the attribute and loading that into
the scanner variable.

The scanner itself makes use of the routines in 
the text handling library {\tt text.c} to read the source input file,
deal seamlessly with nested input files and handle the generation of an
output listing.

After the scanner variable has been loaded, the scanner returns control
to the parser which must decide which rule expansion to use next on the
basis of the contents of the scanner variable and the present state of
the derivation. The scanner variable effectively provides a single token
of lookahead, and as such must be loaded {\em before} a parser function
is started. In \rdp, as in most top-down parsers, the parser functions
assume that the scanner variable has been correctly initialised before
entry to the parser function and the function takes responsibility for
leaving the scanner variable correctly set up for the next parser
function. This leads to a somewhat counter-intuitive organisation in
which the scanner is called at the end of each parser function rather
than at the beginning. In the next section we shall look at the details
of a complete parser which will make this point clearer.

\section{The main file}

The \rdp-generated main file contains the parser proper.
Figure~\ref{extract1c} shows extracts from the main file for the grammar
given at the beginning of this chapter. The full file contains
declarations and initialisation code for the {\sc first} and {\sc stop}
sets for each parser function. You can read more about the calculation
of these sets in the tutorial manual~\cite{rdp:tut:1.5} or in most
standard compiler texts.


\begin{figure}
{\small
\begin{verbatim}
static void expr(void)
{
  {
    scan_test(NULL, SCAN_P_INTEGER, &expr_stop);
    scan_();
    scan_test(NULL, RDP_T_17 /* * */, &expr_stop);
    scan_();
    scan_test(NULL, SCAN_P_INTEGER, &expr_stop);
    scan_();
    scan_test_set(NULL, &expr_stop, &expr_stop);
  }
}

void start(void)
{
  {
    scan_test(NULL, SCAN_P_INTEGER, &start_stop);
    scan_();
    scan_test(NULL, RDP_T_18 /* + */, &start_stop);
    scan_();
    expr();
    scan_test_set(NULL, &start_stop, &start_stop);
  }
}

int main()
{

.....  /* Some initialisation code omitted */

  for (rdp_pass = 1; rdp_pass <= RDP_PASSES; rdp_pass++)
  {
.....  /* Pass level initialisation (including source file opening) omitted */

    scan_();
    start();            /* call parser at top level */
    if (text_total_errors() != 0)
      text_message(TEXT_FATAL, "error%s detected in source file\n", 
                                        text_total_errors() == 1 ? "" : "s"); 
  }
  text_print_total_errors();

.....  /* Clean up code omitted */

  return rdp_error_return;
}
\end{verbatim}
}
\caption{Extracts from an \rdp-generated parser main file}
\label{extract1c}
\end{figure}

Apart from the initialisation code, an \rdp-generated main file contains exactly one
function for each nonterminal declared in the grammar (called the parser function for
that nonterminal) plus a {\tt main()} function that
initialises the text and scanner subsystems before calling the function corresponding to the
start nonterminal. Each parser function must
\begin{itemize}
\item assume that a (possibly empty) section at the beginning of the input has already
been read by the scanner and matched against rules in the grammar by the parser functions,
\item assume that the scanner variable has already been loaded with the first token to be matched
against the current parser function's rule in the grammar,
\item by looking at the current contents of the scanner variable decide which of the alternate
productions within the rule is to be matched,
\item match the rule against the input, calling the scanner each time a token is successfully
matched so as to advance to the next token,
\item ensure that at the end of a successful match the scanner variable is loaded with the
first token to be matched by the succeeding parser function,
\item in the case of an unsuccessful match generate an error message and attempt to read tokens
from the input until the parser function sees a plausible place for parsing to continue.
\end{itemize}

\subsection{Implementing parser functions}
Parser functions make use of three functions from the scanner module:
\begin{itemize}
\item \verb+void scan_(void)+ the scanner function which has been described above,
\item \verb+int scan_test(const char *production, const int valid, set_ * stop)+ and
\item \verb+int scan_test_set(const char *production, set_ * valid, set_ * stop)+.
\end{itemize}

The two \verb+..._test+ functions check the contents of the scanner
variable against a supplied parameter called {\tt valid}. The only
difference between them is that \verb+scan_test+ checks against a single
valid token value and \verb+scan_test_set+ checks against a set of of
valid tokens. 

The two parameters {\tt production} and {\tt stop} are used to control
the generation of error messages in the case of a mismatch. If only a
simple test is required then both parameters will be set to {\tt NULL},
but if the {\tt stop} parameter is non-null then {\em when} the test
function finds a mismatch between the current token and the  {\tt valid}
token or token set it issues an error message before returning {\tt false}.
Immediately after issuing the error message an attempt is made to
resynchronise the input stream by using the scanner to read and discard
tokens until a token is found that is in the {\tt stop} set. All stop
sets are initialised to contain at least the end-of-file token so that
the synchroniser will not go into an infinite loop at the end of of the
source file. In detail, the stop set for a parser function is the follow
set for the corresponding grammar rule {\sc union} the end of file
token. You can use the {\tt -e} flag to instruct \rdp\ to display the
stop sets for each nonterminal of a grammar. The {\tt production}
parameter is a simple character string that \rdp\ uses to pass the name
of the currently executing parser function to the error handling
routine. It is always {\tt NULL} unless the {\tt -E} flag has been used
to ask \rdp\ to add the current rule name to error messages.

The body of the {\tt start} production shows how these routines are used
in practice. The corresponding grammar rule is
\begin{quote}
\begin{verbatim}
start ::= INTEGER '+' expr.
\end{verbatim}
\end{quote}
and \rdp\ writes out the following lines
\begin{quote}
\begin{verbatim}
scan_test(NULL, SCAN_P_INTEGER, &start_stop);
scan_();
scan_test(NULL, RDP_T_18 /* + */, &start_stop);
scan_();
expr();
scan_test_set(NULL, &start_stop, &start_stop);
\end{verbatim}
\end{quote}
The function call \verb+scan_test(NULL, SCAN_P_INTEGER, &start_stop)+
asks for the current scanner variable to be tested against \verb+SCAN_P_INTEGER+
and if a valid integer such as {\tt 23} or {\tt 0xFF} is {\em not} found then
orders an appropriate error message to be issued after which the input should
be resynchronised on the set of tokens \verb+start_stop+. Assuming the
test did succeed then the scanner is called to get the next token which
is tested against \verb+RDP_T_18+ (the token enumeration symbol
for the {\tt +} lexeme). If that succeeds then the {\tt expr()} parser
function is called. The last thing that each parser function does is to test
that the scanner variable has been loaded with a token that can validly
follow the corresponding nonterminal by testing against its \verb+_stop+ set.

\section{Selecting alternate productions}
If a grammar rule has more than one alternate production then the {\sc first} sets for the
productions are used to control the selection of a production for matching. Here is a small
grammar that illustrates the process:
\begin{quote}
\begin{verbatim}
multi ::= A 'b' 'c' | X 'y'.
A ::= 'a' | 'aa'.
X ::= 'x' | 'y'.
\end{verbatim}
\end{quote}

When \rdp\ processes a grammar rule with multiple alternate productions it gives
each of them a name comprising the prefix \verb+rdp_+ followed by the name of the rule followed
by an integer which is incremented after each use. The two alternate productions in rule 
{\tt multi} are therefore called \verb+rdp_multi_0+ and \verb+rdp_multi_1+. \rdp\ will
calculate {\sc first} sets  which it names \verb+rdp_multi_0_first+ and \verb+rdp_multi_1_first+.

The generated parser function for rule {\tt multi} is as follows.
\begin{quote}
\begin{verbatim}
void multi(void)
{
  {
    if (scan_test_set(NULL, &rdp_multi_0_first, NULL))
    {
      A();
      scan_test(NULL, RDP_T_b, &multi_stop);
      scan_();
      scan_test(NULL, RDP_T_c, &multi_stop);
      scan_();
    }
    else
    if (scan_test_set(NULL, &rdp_multi_1_first, NULL))
    {
      X();
      scan_test(NULL, RDP_T_y, &multi_stop);
      scan_();
    }
    else
      scan_test_set(NULL, &multi_first, &multi_stop)    ;
    scan_test_set(NULL, &multi_stop, &multi_stop);
   }
}
\end{verbatim}
\end{quote}

The {\tt if} statements here act as gateways to the different branches
of the the rule. If the current value of the scanner variable is a token
that is in \verb+rdp_multi_0_first+ then the first branch will be taken
and parser function \verb+A()+ will be called. If not, then the scanner
variable is tested against \verb+rdp_multi_1_first+ and if successful
then the second branch is taken. If neither branch is taken then an
error has occurred and the production of an error message is forced by
testing the scanner variable against the {\sc first} set for the whole
rule \verb+multi_first+. 

\section{Parsing iterators}
An iterator is created either explicitly by using the iterator operator \verb+@+ or by
using one of the four bracket forms \verb+(  )+, \verb+[  ]+, \verb+{  }+ and \verb+<  >+.
As for alternate productions, \rdp\ gives each a unique name and calculates a {\sc first}
set for it. The high and low iteration counts, the delimiter token and the {\sc first} set
for the iterator
are then used to control the parsing with the help of a {\tt while} loop. 
Here is an iterator rule that uses most of the features of the iterator operator:
\begin{quote}
\begin{verbatim}
iter ::= ('a')3@4 'b'.
\end{verbatim}
\end{quote}

The generated parser function for rule {\tt iter} is as follows.

\begin{quote}
\begin{verbatim}
void iter(void)
{
  {
    { /* Start of rdp_iter_1 */
      unsigned long rdp_count = 0;
      while (1)
      {
        {
          scan_test(NULL, RDP_T_a, &iter_stop);
          scan_();
        }
        rdp_count++;
        if (rdp_count == 4) break;
        if (SCAN_CAST->token != RDP_T_b) break;
        scan_();
      }
      if (rdp_count < 3)  text_message(TEXT_ERROR_ECHO, 
                            "iteration count too low\n");
    } /* end of rdp_iter_1 */
    scan_test_set(NULL, &iter_stop, &iter_stop);
   }
}
\end{verbatim}
\end{quote}

A local variable \verb+rdp_count+ is declared to keep a count of the number of times
the body of the iterator has been successfully matched. The iterator loop is implemented as an
`infinite' {\tt while (1)} loop which contains {\tt break} statements that can cause control
to be transferred out of the loop This rather inelegant arrangement is used because there are
several different conditions that can cause loop termination and it is more efficient to 
simply break out of the loop than to, say, set a flag to be tested at the bottom of the loop.

On entry to the iterator loop, the code performs a match against the body of the iterator rule:
in this case a simple match against the token {\tt a}. Upon successful matching, the counter
\verb+rdp_count+ is incremented and if its value exceeds the high limit for the iterator (4 in
this case) then the loop terminates. Otherwise a test is performed to see if the current scanner
symbol is the delimiter token for the iterator (\verb+b+ in this case). If not, the loop terminates
otherwise the iterator body is matched again.
Once the iterator loop does finally exit, a test is made to ensure that the loop counter 
exceeds the low value for the iterator, otherwise an error message is issued.

\rdp\ applies a series of optimisations to the generation of iterator
parser functions which are not documented in detail here. As a simple
example: if the iterator high and low values are integers in the range
of 0\ldots1 then it is never necessary to keep a track of the number of 
iterator loops so the code associated with the variable \verb+rdp_count+
is omitted. Although these optimised forms of the iterator 
template all differ from the version documented, each iterator function
follows the same general form and is flagged up in the code with a comment of
the form \verb+/* Start of rdp_... */+. You might find it interesting to
try different kinds of iterator and examine the generated code.

\section{Debugging \rdp-generated parsers}
Debugging a machine generated parser is always more challenging than debugging a normal
human-written program because of the multiple levels at which errors can be introduced and
the difficulty of distinguishing between an error in the grammar proper and an error
in the semantic actions inserted into the grammar. In this section we shall distinguish between
the different kinds of error that can arise in terms of the point within the process at which
the error will be detected and give advice on the use of \rdp's facilities to make the task
of diagnosing the cause of the error easier. Errors can be detected at the following times.
\begin{itemize}
\item During the initial parse of the
IBNF specification as a result of syntax
errors or because of illegal use of \rdp's features, such as requesting an iterator of
the form \verb+4@3+ in which the low bound is higher than the high bound.
\item During the grammar analysis phase, in which LL(1) violations of various forms
may be reported.

\item During string testing of the parser. The generated parser may turn
out to accept inputs that are not legal in the intended language or
reject inputs that are. In either case, this indicates a mismatch
between the language the designer had in mind and the language specified
by the grammar processed by \rdp. 

\item During testing of the semantic actions of a parser.
\end{itemize}

\section{Errors reported by \rdp\ when parsing a specification}
Syntax errors in the IBNF specification are detected by \rdp\ and reported using the
standard error reporting mechanism. New users are most often caught out by one of the
following common errors.
\begin{enumerate}
\item Using the Pascal-style assignment operator \verb+:=+ instead of the \rdp-IBNF `expands-to'
symbol \verb+::=+.
\item Omitting the full stop (period) at the end of each production.
\item Quoting nonterminals instead of terminals.
\item Quoting scanner elements. A grammar containing a rule of the form \verb+item ::= ID | 'INTEGER'.+
is perfectly acceptable to \rdp\ but will {\em not} match to integers: it will attempt
to match against the keyword {\tt INTEGER} instead.
\item Putting in superfluous commas within parameter lists and directives. \rdp-IBNF does not
use the comma in any context.
\end{enumerate}

\section{LL(1) errors reported by \rdp\ during the analysis phase}

\rdp\ will, of course, reject grammars that have empty alternates or that
make use of production rules that have not been declared since it
assumes that these grammars are incomplete. \rdp\ will also reject a
grammar that contains two or more definitions for the same rule. You
must combine such multiple rules together with the alternate operator
(\verb+|+).

There is a set of errors that \rdp\ may detect whilst analysing a
grammar. Even a well formed grammar (in the sense of the previous
paragraph) may be unacceptable because \rdp-generated parsers can only
handle grammars that may be parsed top-down using a single symbol of
lookahead. In practice this means that at every point in the grammar
where a running parser may have to choose between two or more courses of
action it must be able to make a decision simply by looking at the
single lookahead token held in the scanner variable. The three broad classes of problem and
the best approach to their correction are as follows.

\begin{itemize}
\item Left recursive rules, that is ones that may call themselves before consuming any input
tokens are not allowed. Many left recursive constructions can be recast as iterators
and thus converted to acceptable grammars. Left recursion removal is a common requirement if
you are adapting grammars that were developed for bottom up parser generators such as YACC, because
these tools do allow left recursive rules. 

There do exist standard algorithms for left recursion removal.
Unfortunately these algorithms in general remove the left recursion but
introduce other forms of LL(1) error into the resulting grammar so they
are not a panacea, in spite of the claims occasionally made in their
favour. In fact some left recursive grammars have no
simple counterpart which is LL(1) although in practice most grammars can
be massaged into the necessary form.

The most common source of such problems is in the description of operator expressions with
left and right associativity. We suggest that you study the examples in the tree generation
chapter of this manual and in the tutorial manuals, and copy the techniques used there.

\item Alternate productions within a rule must start with different tokens, that is their
{\sc first} sets must be disjoint. A rule such as
\begin{quote}
\begin{verbatim}
bad ::= 'a' 'b' 'c' | 'a' 'y' 'z'.
\end{verbatim}
\end{quote}
has two alternate productions both of which starts with the token \verb+a+. It can be recast
using left factorisation to be acceptable to \rdp\ as follows:
\begin{quote}
\begin{verbatim}
good ::= 'a' ('b' 'c' | 'y' 'z').
\end{verbatim}
\end{quote}

\item Iterators with a low bound of zero (and that includes the \verb+[ ]+ and 
\verb+{  }+ bracket shorthands) can match the empty string. If
the body of the iterator can start with tokens that  can also follow the
iterator then the parser cannot know, in general, whether the existence
of such a token on the input indicates that it should step into or step
over the iterator. As a result, for rules and iterators that can match
$\epsilon$, the {\sc first} and {\sc follow} sets must be disjoint.

\end{itemize}
\section{Refining a grammar}

Once you have a compiled parser, you may find that it does not behave as
you intended. If your parser rejects strings that it `ought' to accept, or accepts strings that
it should reject then
before tracing the code try checking that all alternates are correctly separated by
alternate operators (\verb+|+). In a long list of alternates it is easy to leave one
of the bars off:
\begin{quote}
\begin{verbatim}
alpha ::= 'a' |
          'b' 
          'c' |
          'd' .
\end{verbatim}
\end{quote}
This rule does not accept the language $\{$ {\tt a, b, c, d} $\}$ which is perhaps what was intended
but rather the language $\{$ {\tt a, bc, d} $\}$. 

Assuming that no typographic errors are found at this stage then it
will be necessary  to trace the behaviour of the parser. \rdp\ provides
a range of levels at which tracing may be performed.

\subsubsection{Examining scanner lexemes with the {\tt -s} flag}
If you run the generated parser with a {\tt -s} flag, the scanner will
report the value of every lexeme seen by the parser. This is particularly
useful if your commenting convention is causing the problem or if the
handling of newlines is suspect. We recommend that you
use the {\tt -l} option in tandem with {\tt -s} so as to generate a
line-by-line listing as well, otherwise it can become hard to follow the
output.

\subsubsection{Adding rule names to error messages with the {\tt -E} flag}

Just seeing the stream of lexemes processed by the parser gives little
information on the state of the parser at the point of error. If you
regenerate the parser with \rdp\ and add a {\tt -E} flag to the \rdp\
command line then all syntax error messages produced by the generated parser
will include the name of the rule that was being matched when the error
occurred. This can be a great help in tracking down the part of the
grammar that is in error. Note that the use of this flag is very
different to that of the {\tt -s} flag above: all \rdp-generated parsers
have the {\tt -s} flag built in but the {\tt -E} flag is a command to
\rdp\ that governs the way that it generates the parser, so you must
regenerate the parser from scratch to see its effect.

\subsubsection{Enabling a full parser trace with the {\tt -R} flag} If
all else fails, you can instruct \rdp\ to generate extremely verbose
parsers that issue a message every time a parser function is entered or
exited. This allows a complete parse to be traced, but can generate very
long listings. 

\subsubsection{Tracing with VCG} 
An alternative way of tracing a parse is to enable tree
generation using one of the directives described in Chapter~\ref{tree}
and examine the parse tree with VCG, although you will of course need to
be using a computer that supports VCG (such as a PC running Windows or
an X-windows Unix system).

\section{Debugging semantic actions}

\rdp\ blindly copies semantic actions in the IBNF specification into the
generated parser and does not attempt to check them for syntactic or
logical correctness. If you write a syntactically incorrect action, by
for instance omitting the semicolon at the end of a C-language statement
then it is only when you attempt to compile the generated parser that
you will receive an error message, and the details of the message you
receive depends on the particular compiler that you are using. 

\subsubsection{Inhibiting semantic actions with the {\tt -p} flag}
You are
strongly advised to check that your parser  is functioning correctly as
a standalone parser before attempting to check the semantics. To make
this easier, \rdp\ has an option to suppress the copying of semantic
actions into the generated parser main file: if you generate the parser
by running \rdp\ with the {\tt -p}  flag then all semantic actions in
the IBNF file will be ignored.

\subsubsection{Tracing parsers with a debugger}
Once the semantic actions have been introduced into the parser then it
is best to use the debugging facilities of your compiler to trace the
behaviour of the parser.  We have successfully used the Microsoft and
Borland integrated development environments and, on Unix, the {\tt gdb}
debugger with the GNU compilers. We suggest that you set a breakpoint on
the parser function corresponding to the start rule and then single step
through the parser whilst looking  at a short input string.

\subsubsection{Examining the contents of symbol tables with the {\tt -S}
flag} If your parser makes use of the built-in symbol table handler then
you can  order the parser to print out the contents of its hash-coded
symbol tables at the end of a run by adding a {\tt -S} flag to the
command line. This is useful for checking that identifiers are being
added correctly and also to ensure that the tables are not becoming
congested. We recommend that the length of each hash bucket is kept to 
around three--four on average. Longer chains indicate that the size of
the table should be increased, although the tables will operate
correctly even if they are overfull: there will simply be a performance
penalty.

\input{rdp_inst.tex}

\bibliographystyle{alpha}
\bibliography{adrian}
\end{document}
